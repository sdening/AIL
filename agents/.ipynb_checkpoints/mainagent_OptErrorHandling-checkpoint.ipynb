{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT SETUP\n",
    "NUM_ITERATIONS = 20\n",
    "DATASET_SIZE = 25\n",
    "DATASET_CAT = ['A', 'CH', 'CR', 'J', 'LAW', 'LTD', 'TER', 'USE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the LangChain directory to sys.path\n",
    "ail_path = Path().resolve().parent\n",
    "if str(ail_path) not in sys.path:\n",
    "    sys.path.append(str(ail_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' - Start with \"yes\" or \"no\"\\n - Justify response in no more than 50 words'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import pandas as pd\n",
    "import tools.paraphrase\n",
    "from tools.reformat import Reformat\n",
    "from tools.score_complete import score_prompt, score_prompt_01, score_prompt_11\n",
    "import tools.score_complete\n",
    "import tools.ShortenTool\n",
    "import tools.ExampleTool\n",
    "import tools.jump_iteration\n",
    "from tools.output_pipes import MultiLogger\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage\n",
    "import json\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_ids = pd.read_csv('../../dataset/claudette_train_merged.tsv', sep='\\t')['document'].unique()\n",
    "val_doc_ids = pd.read_csv('../../dataset/claudette_val_merged.tsv', sep='\\t')['document'].unique()\n",
    "test_doc_ids = pd.read_csv('../../dataset/claudette_test_merged.tsv', sep='\\t')['document'].unique()\n",
    "\n",
    "df = pd.read_csv('../../dataset/claudette_all_merged.tsv', sep='\\t').rename(columns={\"file_name\": \"document\"})\n",
    "df_train = df.loc[df['document'].isin(train_doc_ids)]\n",
    "#df_train_neg = df_train.loc[df_train['label'] == 0]\n",
    "#df_train_pos = df_train.loc[df_train['label'] == 1]\n",
    "df_val = df.loc[df['document'].isin(val_doc_ids)]\n",
    "df_test = df.loc[df['document'].isin(test_doc_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_98518/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_98518/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_98518/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_98518/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_98518/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_98518/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_98518/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_98518/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n"
     ]
    }
   ],
   "source": [
    "#df_train_pos_per_cat = {}\n",
    "for category in DATASET_CAT:\n",
    "    df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
    "    #df_train.loc[:, category] = df_train_pos.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
    "    #df_train_pos_per_cat[category] = df_train.loc[df_train[category] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_answer_instruction(n_words = 50):\n",
    "    return f'Start your answer with \"yes\" or \"no\" and then justify your response in no more than {n_words} words.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_equal_distribution(df, categories, sample_size, seed=123):\n",
    "    \n",
    "    per_category=int(sample_size/(len(categories)+1))\n",
    "    sample_df = None\n",
    "\n",
    "    for cat in categories:\n",
    "        temp_df = df[df[cat] == 1].sample(n=per_category, random_state=seed)\n",
    "        if type(sample_df) != None:\n",
    "            sample_df = pd.concat([sample_df, temp_df])\n",
    "        else:\n",
    "            sample_df=temp_df\n",
    "\n",
    "    temp_df = df[(df[categories] == 0).all(axis=1)].sample(n=int(sample_size/len(categories)), random_state=seed)\n",
    "    sample_df = pd.concat([sample_df, temp_df])\n",
    "\n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_short = sample_equal_distribution(df_train, DATASET_CAT, DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase = tools.paraphrase.ParaphrasePegasus()\n",
    "shorten = tools.ShortenTool.ShortenTool()\n",
    "reformat = tools.reformat.Reformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt_optimization(intro:str, initial_prompt, df, df_short, model, num_iterations, category, examples):\n",
    "    \"\"\"Optimizes the prompt using an LLM to choose the best edit operation.\"\"\"\n",
    "    ##For this.. online: <current clause, > <Legal Description, > <Examples, >\n",
    "    #optimization_history =  [{'iteration': 1, \"prompt\": part_of_prompt_to_modify, \"score\": 80, \"edit\": \"paraphrase\"}]\n",
    "    print(\"\\n ################################\")\n",
    "    print(\"Optimizing for category: \", category)\n",
    "\n",
    "    optimization_history = []  # Initialize as an empty list attribute\n",
    "    part_of_prompt_to_modify = initial_prompt\n",
    "    iteration = 0\n",
    "    while iteration < num_iterations:\n",
    "    #for iteration in range(num_iterations):  # Iterate for the specified number of times\n",
    "        # 1. Construct LLM Prompt\n",
    "        if iteration == 0:\n",
    "            # Special prompt for the first iteration (no history)\n",
    "            len_pos = len(examples.added_examples[\"positive\"])\n",
    "            len_neg = len(examples.added_examples[\"negative\"])\n",
    "            score_value, _ = score_prompt(intro, examples.added_examples['positive'], examples.added_examples['negative'], part_of_prompt_to_modify, initial_prompt, df_short, category, model, {'p':1, 'r':0, 'l':0}) \n",
    "            optimization_history.append(\n",
    "                {\"iteration\": 0, \"prompt\": part_of_prompt_to_modify, \"edit\": \"inital - no edit\", \"positive_examples_count\": len_pos, \"negative_examples_count\": len_neg, \"score\": score_value}  # Log 1-based iteration\n",
    "            )\n",
    "    \n",
    "            llm_prompt = (\n",
    "                f\"You are tasked with optimizing a prompt. This is the inital iteration (iteration 0).\\n\" \n",
    "                \"The prompt is scored in a scale of 0 - 100. Your goal is to get a score that is high as possible.\"\n",
    "                \"Full Prompt: <intro><current_clause><legal_description><examples><part_of_prompt_to_modify>\"\n",
    "                f\"<intro> is: {intro}\"\n",
    "                \"<current_clause> is the variable clause to be classified.\"\n",
    "                f\"<legal_description> is: Question helping to classify clauses\"\n",
    "                \"<examples> is: optional, example clauses that are either positive or negative to the classification\"\n",
    "                f\"<part_of_prompt_to_modify> is {part_of_prompt_to_modify}, you will only modify this part\\n\\n\"\n",
    "                f\"Your starting point: {optimization_history}\\n\\n\"\n",
    "                \"To optimize the prompt you can use various actions. These actions alter the prompt.\"\n",
    "                #\"To optimize the prompt you can only use one action. \"\n",
    "                \"Choose the most suitable action to improve the prompt:\\n\"\n",
    "                #\"- shorten: Shortens the prompt by removing stopwords from the prompt.\\n\"\n",
    "                \"- add_positive_example: Include a positive example.\\n\"\n",
    "                \"- add_negative_example: Include a negative example.\\n\"\n",
    "                \"- reword_prompt: Reword the <part_of_prompt_to_modify>.\\n\"\n",
    "                \"- to_bulletpoints: Formates the <part_of_prompt_to_modify> into bullet points. The output does not change if used twice in a row.\\n\"\n",
    "                #\"- grammar_adjustment: Fix any grammatical errors in the prompt.\\n\"\n",
    "                #\"- jump_back_to_iteration: Jump back to a specific iteration. Use the format 'jump_back_to_iteration <number> because: <reasoning>'.\\n\"\n",
    "                \"Your output should be of form: <chosen_action> because: <reasoning>\"\n",
    "            )\n",
    "        else:\n",
    "            # Prompt for subsequent iterations (with history)\n",
    "            llm_prompt = (\n",
    "                f\"You are tasked with optimizing a prompt used to conduct a classification task with another LLM. \" \n",
    "                \"The classification result using the prompt is scored on a scale of 0 - 100. Your goal is to find the best prompt and get a score as high as possible. \"\n",
    "                f\"The optimization process is done within {num_iterations} iterations the final iteration is expected to provide the optimal prompt. In every iteration, you can choose from a list of possible actions to alter the <part_of_prompt_to_modify>. Please make sure you achieve an optimal prompt until iteration {num_iterations}. This is iteration {iteration + 1}. \\n \"\n",
    "                \"This is the structure of the full prompt given to the classification LLM: <intro><current_clause><legal_description><examples><part_of_prompt_to_modify> \"\n",
    "                \"In the following, the single parts of the full prompt are described:\"\n",
    "                f\"<intro> is: {intro} \\n\"\n",
    "                \"<current_clause> is the variable clause to be classified.\\n\"\n",
    "                f\"<legal_description> is a question helping to classify clauses.\\n\"\n",
    "                \"<examples> is optional this is an example clause representing either a positive or negative clause. It is possible that both negative and positive are present.\\n\"\n",
    "                f\"<part_of_prompt_to_modify> is {part_of_prompt_to_modify}, only modify this part \\n\"\n",
    "                \"The output of the classification LLM is classified positive if the output starts with yes and negative if the output starts with no.\\n\"\n",
    "                \"To optimize the prompt, you can use various actions. \"\n",
    "                f\"This is the history of all conducted operations until now: {optimization_history}\\n\"\n",
    "                \"The history contains the following information: \\n\" \n",
    "                \"iteration: Number of iterations.\\n\"\n",
    "                \"prompt: The used <part_of_prompt_to_modify> so the optimized part of the prompt.\\n\"\n",
    "                \"edit: The action that is used in the regrading iteration.\\n\"\n",
    "                \"score: The achieved score of the prompt edited by the respective action.\\n\"\n",
    "                \"relative_improvement: The relative improvement in percent compared to the previous iteration.\\n\"\n",
    "                \"token_len: token length of the prompt given to the classification LLM.\\n\"\n",
    "                \"If an action did not lead to a higher score after two iterations, try a different action. \"\n",
    "                \"If you find that the score plateaus, it is always possible to return to a previous iteration by taking the respective action. \"\n",
    "                \"Try different actions to get a feeling which leads to a higher score. \\n\"\n",
    "                \" These are the actions you can choose from. Use the most suitable action to improve the prompt further :\\n\"\n",
    "                #\"- shorten: Shortens the prompt by removing stopwords from the prompt. The output does not change if used twice in a row.\\n\"\n",
    "                \"- reword_prompt: Reword the <part_of_prompt_to_modify>. \\n\"\n",
    "                \"- to_bulletpoints: Formates the <part_of_prompt_to_modify> into bullet points. The output does not change if used twice in a row.\\n\"\n",
    "                \"- add_positive_example: Include a positive example. A positive example is a clause that belongs to the same category and should be classified as true (a category of several unfairness categories).\\n\"\n",
    "                \"- add_negative_example: Include a negative example. A negative example is a clause that belongs to a different category and should be classified as false (a category of several unfairness categories).\\n\"\n",
    "                \"- remove_positive_example: Remove one of the positive examples previously added with the add_positive_example action.  A positive example is a clause that belongs to the same category and should be classified as true (a category of several unfairness categories).\\n\"\n",
    "                \"- remove_negative_example: Remove one of the negative examples previously added with the add_negative_example action. A negative example is a clause that belongs to a different category and should be classified as false (a category of several unfairness categories).\\n\"\n",
    "                \"- jump_back_to_iteration: Jump back to a previous iteration. If you realize previous actions led to a decrease in performance, you can always return to an iteration step that has been more promising. If you choose this action, your output should be of form: jump_back_to_iteration <number> because: <reasoning>'.\\n\"\n",
    "                    \n",
    "                #\"- grammar_adjustment: Fix any grammatical errors in the prompt.\\n\"\n",
    "                \"Your output should be of form: <chosen_action> because: <reasoning>\"\n",
    "            )\n",
    "\n",
    "        print(f\"\\nThis is iteration {iteration + 1}\")\n",
    "        try:\n",
    "            # 2. Get LLM's Decision\n",
    "            message = HumanMessage(content=llm_prompt)\n",
    "            response = model.invoke([message])\n",
    "            print(f\"Complete response: {response}\")\n",
    "            chosen_action = response.content.lower().split()[0]\n",
    "            #print(\"Response: \" + response)\n",
    "            print(\"Chosen Action: \" + chosen_action)\n",
    "\n",
    "            #if iteration == 1:\n",
    "            #    chosen_action = \"jump_back_to_iteration\"\n",
    "            #    iteration_number = 0\n",
    "            \n",
    "            # 3. Apply Chosen Action\n",
    "            for i in range(2):\n",
    "                if chosen_action == \"shorten\":\n",
    "                    part_of_prompt_to_modify = shorten.shorten_prompt(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"add_positive_example\":\n",
    "                    examples.add_positive_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"add_negative_example\":\n",
    "                    examples.add_negative_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"remove_positive_example\":\n",
    "                    examples.remove_positive_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"remove_negative_example\":\n",
    "                    examples.remove_negative_example(part_of_prompt_to_modify,category)\n",
    "                    break            \n",
    "                elif chosen_action == \"reword_prompt\":\n",
    "                    part_of_prompt_to_modify = paraphrase.paraphrase_pegasus(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"to_bulletpoints\":\n",
    "                    part_of_prompt_to_modify = reformat.reformat(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"jump_back_to_iteration\":\n",
    "                    match = re.search(r'jump_back_to_iteration (\\d+)', response.content.lower())\n",
    "                    if match:\n",
    "                        iteration_number = int(match.group(1))\n",
    "                    print(chosen_action, iteration_number)\n",
    "                    part_of_prompt_to_modify = jump_iteration.jump_back_to_iteration(iteration_number, optimization_history, category)\n",
    "                    print(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                #elif chosen_action == \"grammar_adjustment\":\n",
    "                #    grammarAdjustment = GrammarAdjustment()\n",
    "                #    part_of_prompt_to_modify = grammarAdjustment.grammar_adjustment(current_prompt)\n",
    "                else:\n",
    "                    keywords = [\n",
    "                        #\"shorten\", \n",
    "                        \"add_positive_example\", \n",
    "                        \"add_negative_example\", \n",
    "                        \"remove_positive_example\", \n",
    "                        \"remove_negative_example\", \n",
    "                        \"reword_prompt\",  \n",
    "                        \"to_bulletpoints\",\n",
    "                        \"jump_back_to_iteration\"\n",
    "                    ]\n",
    "                    pattern = r'jump_back_to_iteration (\\d+)'\n",
    "                    match = re.search(pattern, response.content.lower())\n",
    "                    if match:\n",
    "                        chosen_action=\"jump_back_to_iteration\"\n",
    "                    else:\n",
    "                        for keyword in keywords:\n",
    "                            if keyword in response.content.lower():\n",
    "                                chosen_action = keyword \n",
    "                                break\n",
    "                            else:\n",
    "                                chosen_action = \"\"\n",
    "                        if chosen_action == \"\":        \n",
    "                            raise ValueError(f\"Invalid action chosen by LLM: {chosen_action}\")\n",
    "                    print(f\"Invalid chosen action. New chosen action after error handling is: {chosen_action}\")\n",
    "\n",
    "            # 4. Score and Log (using self.optimization_history)\n",
    "            score_value, mean_token_len = score_prompt(intro, examples.added_examples['positive'], examples.added_examples['negative'], part_of_prompt_to_modify, initial_prompt, df_short, category, model, {'p':1, 'r':0, 'l':0}) # + legal description, df_test, category, intro \n",
    "            len_pos = len(examples.added_examples[\"positive\"])\n",
    "            len_neg = len(examples.added_examples[\"negative\"])\n",
    "            relative_improvment = str(((score_value/optimization_history[iteration]['score'])-1)*100) + '%'\n",
    "            optimization_history.append(\n",
    "                {\"iteration\": iteration + 1, \"prompt\": part_of_prompt_to_modify, \"edit\": chosen_action, \"positive_examples_count\": len_pos, \"negative_examples_count\": len_neg, \"score\": score_value, \"relative_improvement\": relative_improvment, \"token_len\": mean_token_len}  # Log 1-based iteration\n",
    "            )\n",
    "            iteration += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error during optimization  {e}\")\n",
    "            print(\"Retrying the iteration...\")\n",
    "            #break\n",
    "\n",
    "    return optimization_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ################################\n",
      "Optimizing for category:  TER\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................\n",
      "Performance score is: 50.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 1\n",
      "Complete response: content=\"reword_prompt because: The initial prompt is quite generic and doesn't provide clear guidance on what kind of justification is expected. Rewording the prompt can help to clarify the expectations and provide more specific instructions, which can lead to better responses and a higher score.\" response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 350, 'total_tokens': 403, 'completion_time': 0.170623694, 'prompt_time': 0.129753583, 'queue_time': None, 'total_time': 0.300377277}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-ff2996e6-47e0-403f-b3c3-d844b91cd36a-0' usage_metadata={'input_tokens': 350, 'output_tokens': 53, 'total_tokens': 403}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 50.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 2\n",
      "Complete response: content='add_positive_example because: I want to provide more context to the classification LLM by adding a positive example, which can help it better understand the classification task and improve the accuracy of the model.' response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 949, 'total_tokens': 989, 'completion_time': 0.131210116, 'prompt_time': 0.250743609, 'queue_time': None, 'total_time': 0.38195372499999997}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-6eafc3c3-ebcc-4a98-8d01-10054da5ef1d-0' usage_metadata={'input_tokens': 949, 'output_tokens': 40, 'total_tokens': 989}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 50.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 3\n",
      "Complete response: content=\"add_positive_example because: The previous iteration also added a positive example, and it didn't lead to an improvement in the score. However, I want to try adding another positive example to see if it can provide more context and help the classification LLM to better understand the task.\" response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 1038, 'total_tokens': 1095, 'completion_time': 0.18034002, 'prompt_time': 0.22899236, 'queue_time': None, 'total_time': 0.40933238}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-216d9048-7d71-488a-8fca-1e19ab0ea0cb-0' usage_metadata={'input_tokens': 1038, 'output_tokens': 57, 'total_tokens': 1095}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 50.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 4\n",
      "Complete response: content=\"to_bulletpoints because: The current prompt is still in a simple sentence structure, and formatting it into bullet points might make it clearer and more organized for the classification LLM to understand. Additionally, since the score has not improved in the previous iterations, it's a good time to try a different approach to see if it can lead to a higher score.\" response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 1127, 'total_tokens': 1201, 'completion_time': 0.246135119, 'prompt_time': 0.136088095, 'queue_time': None, 'total_time': 0.38222321400000003}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-41b961ec-47f9-439f-8b45-e9cd838616e5-0' usage_metadata={'input_tokens': 1127, 'output_tokens': 74, 'total_tokens': 1201}\n",
      "Chosen Action: to_bulletpoints\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 50.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 5\n",
      "Complete response: content=\"add_positive_example because: The score has been plateauing at 50.0 for the past 4 iterations, and adding more positive examples might help the classification LLM to better understand the context and improve the score. Additionally, the previous actions of rewording and formatting into bullet points did not lead to any improvement, so it's time to try a different approach.\" response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 1213, 'total_tokens': 1289, 'completion_time': 0.238388657, 'prompt_time': 0.100768484, 'queue_time': None, 'total_time': 0.339157141}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None} id='run-f6ee4d6a-8838-4e68-b4ec-c08fd0039971-0' usage_metadata={'input_tokens': 1213, 'output_tokens': 76, 'total_tokens': 1289}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 50.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 6\n",
      "Complete response: content=\"add_negative_example because: The prompt has been stuck at a score of 50.0 for 5 iterations, and we've only added positive examples so far. Adding a negative example can help the model learn to distinguish between different categories and improve the classification accuracy.\" response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 1299, 'total_tokens': 1353, 'completion_time': 0.171178508, 'prompt_time': 0.188129985, 'queue_time': None, 'total_time': 0.359308493}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-2fa972ef-6fd2-4267-85a6-15db07b7f9dc-0' usage_metadata={'input_tokens': 1299, 'output_tokens': 54, 'total_tokens': 1353}\n",
      "Chosen Action: add_negative_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 66.66666666666666\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 7\n",
      "Complete response: content=\"add_positive_example because: The score has improved significantly in the last iteration after adding a negative example, and I want to see if adding another positive example can further improve the score. Additionally, the number of positive examples is still relatively low compared to the number of iterations, so it's worth exploring this direction further.\" response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 1393, 'total_tokens': 1457, 'completion_time': 0.196874023, 'prompt_time': 0.152103642, 'queue_time': None, 'total_time': 0.34897766500000005}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-891fc2fe-4c38-4ab2-b4bb-b0fa78f74643-0' usage_metadata={'input_tokens': 1393, 'output_tokens': 64, 'total_tokens': 1457}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 40.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 8\n",
      "Complete response: content='add_negative_example because: The score decreased in the last iteration after adding a positive example, and the model has only seen one negative example so far. Adding another negative example might help the model to better distinguish between positive and negative clauses.' response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 1483, 'total_tokens': 1531, 'completion_time': 0.151332269, 'prompt_time': 0.510590173, 'queue_time': None, 'total_time': 0.6619224419999999}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-16829563-ae67-4be0-b2a6-55042c70edb6-0' usage_metadata={'input_tokens': 1483, 'output_tokens': 48, 'total_tokens': 1531}\n",
      "Chosen Action: add_negative_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 57.14285714285714\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 9\n",
      "Complete response: content=\"add_positive_example because: The score has been fluctuating, and adding a positive example might help to stabilize and improve the performance. Additionally, the number of positive examples is still relatively low compared to the number of iterations, so it's worth trying to add another one to see if it makes a difference.\" response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 1577, 'total_tokens': 1639, 'completion_time': 0.197164109, 'prompt_time': 0.170487013, 'queue_time': None, 'total_time': 0.367651122}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-980d33fe-120e-4db8-a99a-3d4d19cda019-0' usage_metadata={'input_tokens': 1577, 'output_tokens': 62, 'total_tokens': 1639}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 40.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 10\n",
      "Complete response: content='remove_positive_example because: The score has been decreasing in the last two iterations, and the number of positive examples has been increasing. I want to test if removing one of the positive examples will help to improve the score.' response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 1667, 'total_tokens': 1712, 'completion_time': 0.139186872, 'prompt_time': 0.205530986, 'queue_time': None, 'total_time': 0.344717858}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-11ab4a04-7802-48b2-a66e-bb8ec78599c4-0' usage_metadata={'input_tokens': 1667, 'output_tokens': 45, 'total_tokens': 1712}\n",
      "Chosen Action: remove_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 33.33333333333333\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 11\n",
      "Complete response: content='remove_positive_example because: The score has been decreasing in the last two iterations, and the number of positive examples has been increasing. Removing one of the positive examples might help to simplify the prompt and improve the score.' response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 1761, 'total_tokens': 1805, 'completion_time': 0.143837874, 'prompt_time': 0.344898171, 'queue_time': None, 'total_time': 0.488736045}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-e7ff9ee7-0cd9-4386-8613-5f7c3ae9ed9b-0' usage_metadata={'input_tokens': 1761, 'output_tokens': 44, 'total_tokens': 1805}\n",
      "Chosen Action: remove_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 66.66666666666666\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 12\n",
      "Complete response: content='remove_positive_example because: The score has been fluctuating, and the last two iterations have resulted in a decrease in score. Removing a positive example might help to simplify the prompt and improve the classification performance. Additionally, the token length has been increasing, and removing an example might help to reduce it.' response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 1851, 'total_tokens': 1912, 'completion_time': 0.186723303, 'prompt_time': 0.473790021, 'queue_time': None, 'total_time': 0.6605133240000001}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-47b3f43d-6821-41ac-b597-fd5d36fec693-0' usage_metadata={'input_tokens': 1851, 'output_tokens': 61, 'total_tokens': 1912}\n",
      "Chosen Action: remove_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 66.66666666666666\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 13\n",
      "Complete response: content='add_negative_example because: The score has plateaued in the last two iterations, and adding a negative example might help the model to better distinguish between positive and negative clauses. Additionally, the number of positive examples is higher than the number of negative examples, so adding another negative example could improve the balance and lead to a higher score.' response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 1941, 'total_tokens': 2008, 'completion_time': 0.218730712, 'prompt_time': 0.329382169, 'queue_time': None, 'total_time': 0.548112881}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-26a80f82-641c-48ef-b3e4-7a3be9e76ccd-0' usage_metadata={'input_tokens': 1941, 'output_tokens': 67, 'total_tokens': 2008}\n",
      "Chosen Action: add_negative_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 57.14285714285714\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 14\n",
      "Complete response: content=\"add_negative_example because: The score has been fluctuating, and the last iteration's score decreased. Adding a negative example might help the model to better distinguish between positive and negative clauses, leading to a higher score.\" response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 2035, 'total_tokens': 2079, 'completion_time': 0.144855099, 'prompt_time': 0.283034196, 'queue_time': None, 'total_time': 0.427889295}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-7080d529-5f35-4405-ad91-91247648284d-0' usage_metadata={'input_tokens': 2035, 'output_tokens': 44, 'total_tokens': 2079}\n",
      "Chosen Action: add_negative_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 66.66666666666666\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 15\n",
      "Complete response: content=\"add_negative_example because: The score has been plateauing around 66.66% for the last few iterations, and adding a negative example might help the model to better distinguish between positive and negative clauses. Additionally, the number of negative examples is currently 4, which is relatively low compared to the number of positive examples. Adding another negative example might improve the model's performance.\" response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 2129, 'total_tokens': 2206, 'completion_time': 0.255283249, 'prompt_time': 0.244013929, 'queue_time': None, 'total_time': 0.49929717799999995}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-7cb30608-ccf7-4c91-be43-6bd7028edd93-0' usage_metadata={'input_tokens': 2129, 'output_tokens': 77, 'total_tokens': 2206}\n",
      "Chosen Action: add_negative_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 57.14285714285714\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 16\n",
      "Complete response: content='add_negative_example because: The score has been fluctuating between 57.14 and 66.67 in the last few iterations, and adding a negative example might help to further clarify the classification task and improve the score. Additionally, the number of negative examples is currently higher than the number of positive examples, which might help to balance the classification task.' response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 2223, 'total_tokens': 2295, 'completion_time': 0.237677241, 'prompt_time': 0.322867067, 'queue_time': None, 'total_time': 0.560544308}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-66df345a-3fcf-46c2-b9f8-82074545be05-0' usage_metadata={'input_tokens': 2223, 'output_tokens': 72, 'total_tokens': 2295}\n",
      "Chosen Action: add_negative_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 57.14285714285714\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 17\n",
      "Complete response: content=\"reword_prompt because: The current prompt has been modified several times, and the score has plateaued. Rewording the prompt might help to refresh the language model's understanding and potentially improve the score. Additionally, the last few iterations have focused on adding or removing examples, so it's a good time to revisit the prompt itself.\" response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 2313, 'total_tokens': 2380, 'completion_time': 0.217187426, 'prompt_time': 0.638485191, 'queue_time': None, 'total_time': 0.855672617}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None} id='run-48bcedaa-7d9c-4c0a-9a45-43667d516422-0' usage_metadata={'input_tokens': 2313, 'output_tokens': 67, 'total_tokens': 2380}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt:  - Start with 'yes' or 'no' and justify in no more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 80.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 18\n",
      "Complete response: content=\"reword_prompt because: The previous rewording of the prompt in iteration 17 led to a significant improvement in the score (40% relative improvement). It's likely that further rewording could lead to additional improvements.\" response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 2398, 'total_tokens': 2444, 'completion_time': 0.141016698, 'prompt_time': 0.331616465, 'queue_time': None, 'total_time': 0.472633163}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-51190a51-2beb-47ec-8772-9504891ee38b-0' usage_metadata={'input_tokens': 2398, 'output_tokens': 46, 'total_tokens': 2444}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: Start with 'yes' or 'no' and justify in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 57.14285714285714\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 19\n",
      "Complete response: content='reword_prompt because: The previous rewording action in iteration 17 led to a significant improvement in score (40.0%), and the subsequent rewording action in iteration 18 resulted in a decrease in score. I want to try another rewording to see if it can further improve the score.' response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 2498, 'total_tokens': 2562, 'completion_time': 0.207739848, 'prompt_time': 0.765231225, 'queue_time': None, 'total_time': 0.972971073}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None} id='run-de4a690a-e84b-401f-83a7-c56382e8eaeb-0' usage_metadata={'input_tokens': 2498, 'output_tokens': 64, 'total_tokens': 2562}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you want to justify in 50 words or less, start with 'yes' or 'no'. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 57.14285714285714\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 20\n",
      "Complete response: content=\"reword_prompt because: The current prompt has been reworded several times, but the score has not improved significantly. I want to try a different rewording to see if it can lead to a higher score. Additionally, the previous rewording actions did not lead to a significant improvement, so it's worth trying again.\" response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 2590, 'total_tokens': 2658, 'completion_time': 0.221005215, 'prompt_time': 0.500390087, 'queue_time': None, 'total_time': 0.721395302}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None} id='run-c142891f-2510-47fd-b943-b7cdf8930b74-0' usage_metadata={'input_tokens': 2590, 'output_tokens': 68, 'total_tokens': 2658}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you want to justify in 50 words or less, start with 'yes' or 'no'. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 57.14285714285714\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "Total time of cat TER is 65 min and 11.250639915466309 sec.\n",
      "Positive example list: \n",
      " ['if you initiate a chargeback or otherwise reverse a payment made with your payment method , tinder may terminate your account immediately in its sole discretion .', 'both you and linkedin may terminate this contract at any time with notice to the other .']\n",
      "\n",
      "Negative example list: \n",
      " ['infringes any patent , trademark , trade secret , copyright , rights of privacy or publicity , or other proprietary rights of any party -lrb- e.g. , music , movies , images , e-books , or games you do not own the rights to -rrb- ;', '-lrb- if you live outside of the us -rrb-', 'we may ask you to agree to additional terms for certain of our services in the future , which will govern to the extent there is a conflict between our terms and such additional terms .', 'last modified : august 25 , 2016 -lrb- archived versions -rrb-', 'you may also delete your account or disable your application at any time .', 'nintendo account services may offer access to shopping services operated by third parties .']\n",
      "\n",
      "\n",
      "\n",
      "{'TER': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0}, {'iteration': 1, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 549.9473684210526}, {'iteration': 2, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 591.9473684210526}, {'iteration': 3, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 628.9473684210526}, {'iteration': 4, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'to_bulletpoints', 'positive_examples_count': 2, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 625.9473684210526}, {'iteration': 5, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 694.9473684210526}, {'iteration': 6, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '33.3333333333333%', 'token_len': 756.9473684210526}, {'iteration': 7, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 40.0, 'relative_improvement': '-39.99999999999999%', 'token_len': 786.9473684210526}, {'iteration': 8, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 4, 'negative_examples_count': 2, 'score': 57.14285714285714, 'relative_improvement': '42.85714285714284%', 'token_len': 798.9473684210526}, {'iteration': 9, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 5, 'negative_examples_count': 2, 'score': 40.0, 'relative_improvement': '-29.999999999999993%', 'token_len': 818.9473684210526}, {'iteration': 10, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 2, 'score': 33.33333333333333, 'relative_improvement': '-16.666666666666675%', 'token_len': 786.9473684210526}, {'iteration': 11, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 2, 'score': 66.66666666666666, 'relative_improvement': '100.0%', 'token_len': 749.9473684210526}, {'iteration': 12, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 2, 'score': 66.66666666666666, 'relative_improvement': '0.0%', 'token_len': 680.9473684210526}, {'iteration': 13, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 3, 'score': 57.14285714285714, 'relative_improvement': '-14.28571428571428%', 'token_len': 719.9473684210526}, {'iteration': 14, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 4, 'score': 66.66666666666666, 'relative_improvement': '16.66666666666665%', 'token_len': 733.9473684210526}, {'iteration': 15, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 5, 'score': 57.14285714285714, 'relative_improvement': '-14.28571428571428%', 'token_len': 750.9473684210526}, {'iteration': 16, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 767.9473684210526}, {'iteration': 17, 'prompt': \"Start with 'yes' or 'no' and justify in 50 words or less.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 80.0, 'relative_improvement': '40.000000000000014%', 'token_len': 765.9473684210526}, {'iteration': 18, 'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '-28.57142857142858%', 'token_len': 769.9473684210526}, {'iteration': 19, 'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 769.9473684210526}, {'iteration': 20, 'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 769.9473684210526}]}\n"
     ]
    }
   ],
   "source": [
    "# Define your model (using your actual API key/setup)\n",
    "model = ChatGroq(\n",
    "    model_name=\"llama3-70b-8192\",\n",
    "    groq_api_key=\"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\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Initial prompt to be optimized\n",
    "optimized_prompt_dict = {}\n",
    "#initial_prompt = \"Consider the following online terms of service clause: 'websites & communications terms of use'. Does this clause describe an arbitration dispute resolution process that is not fully optional to the consumer? Begin your answer with 'yes' or 'no' and then justify your response in no more than 50 words. For example, consider these example clauses: <positive, if you are not a consumer in the eea , the exclusive place of jurisdiction for all disputes arising from or in connection with this agreement is san francisco county , california , or the united states district court for the northern district of california and our dispute will bedetermined under california law .'>, <negative, you are prohibited from using any services or facilities provided in connection with this service to compromise security or tamper with system resources and/or accounts .>\"\n",
    "unfairness_categories = ['A', 'CH', 'CR', 'J', 'LAW', 'LTD', 'TER', 'USE']\n",
    "unfairness_categories_green = ['A', 'CH', 'CR', 'J']\n",
    "unfairness_categories_pink = ['USE']\n",
    "\n",
    "initial_prompt = \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\"\n",
    "intro_prompt = 'Consider the following online terms of service clause:'\n",
    "#cat_results = {}\n",
    "#df_train_sample = sample_equal_distribution(df_train, unfairness_categories, 100, 123)\n",
    "#score_set_df = sample_equal_distribution(df_train, unfairness_categories, 25, 234)\n",
    "output = ''\n",
    "\n",
    "filename = \"20240729_vanilla_categories_pink_f1_score_binary_newAPIKey_TER.txt\"\n",
    "output_dir = os.path.join('..', 'output')\n",
    "file_path = os.path.join(output_dir, filename)\n",
    "if os.path.exists(file_path):\n",
    "    raise FileExistsError(f\"Error: The file '{filename}' already exists in the 'output' directory. \"\n",
    "                            f\"It is not recommended to overwrite an output file. Please specify another name.\")\n",
    "\n",
    "# Create and open the file\n",
    "file_stream = open(file_path, 'w')\n",
    "\n",
    "# Buffer for capturing print output\n",
    "buffer = io.StringIO()\n",
    "\n",
    "# MultiLogger setup to write to stdout, buffer, and file\n",
    "multi_logger = MultiLogger(sys.stdout, buffer, file_stream)\n",
    "sys.stdout = multi_logger\n",
    "try:\n",
    "    for cat in unfairness_categories_pink:\n",
    "        examples_instance = tools.ExampleTool.ExampleTool(df_train)\n",
    "        jump_iteration = tools.jump_iteration.jump_iteration(examples_instance)\n",
    "        start_time = time.time()\n",
    "        optimized_prompt_dict[cat] = run_prompt_optimization(intro_prompt, initial_prompt, df_train, df_train_short, model, NUM_ITERATIONS, cat, examples_instance)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        elapse_time = end_time - start_time\n",
    "        elapse_minutes = int(elapse_time // 60)\n",
    "        elapse_seconds = elapse_time % 60\n",
    "\n",
    "        print(f\"Total time of cat {cat} is {elapse_minutes} min and {elapse_seconds} sec.\")\n",
    "        print(\"Positive example list: \\n\", examples_instance.added_examples[\"positive\"])\n",
    "        print(\"\\nNegative example list: \\n\",examples_instance.added_examples[\"negative\"])\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    print(optimized_prompt_dict)\n",
    "    # Cleanup\n",
    "    sys.stdout = sys.__stdout__  # Reset stdout to default\n",
    "    file_stream.close()\n",
    "\n",
    "    output = buffer.getvalue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAW & LTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LAW': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 33.33333333333333},\n",
       "  {'iteration': 1,\n",
       "   'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 36.36363636363637,\n",
       "   'relative_improvement': '9.090909090909104%',\n",
       "   'token_len': 548.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 33.33333333333333,\n",
       "   'relative_improvement': '-8.333333333333359%',\n",
       "   'token_len': 737.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.',\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 30.76923076923077,\n",
       "   'relative_improvement': '-7.692307692307676%',\n",
       "   'token_len': 784.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': 'You should justify your response in 50 words or less if you start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '62.5%',\n",
       "   'token_len': 782.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': ' - Justify response in 50 words or less\\n - Start with \"yes\" or \"no\"',\n",
       "   'edit': 'to_bulletpoints',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 28.57142857142857,\n",
       "   'relative_improvement': '-42.85714285714286%',\n",
       "   'token_len': 778.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': 'In 50 words or less, start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 26.666666666666668,\n",
       "   'relative_improvement': '-6.666666666666654%',\n",
       "   'token_len': 776.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': '-100.0%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 14,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 15,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 16,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 17,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 18,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 19,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 20,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526}],\n",
       " 'LTD': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0},\n",
       "  {'iteration': 1,\n",
       "   'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 542.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 586.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.',\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '14.28571428571428%',\n",
       "   'token_len': 620.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': 'Begin your answer with \"yes\" or \"no\" and then explain it in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 40.0,\n",
       "   'relative_improvement': '-29.999999999999993%',\n",
       "   'token_len': 619.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': ' - Answer with \"yes\" or \"no\"\\n - Explain in 50 words or less',\n",
       "   'edit': 'to_bulletpoints',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 36.36363636363637,\n",
       "   'relative_improvement': '-9.090909090909083%',\n",
       "   'token_len': 615.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '57.14285714285712%',\n",
       "   'token_len': 615.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 653.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 36.36363636363637,\n",
       "   'relative_improvement': '-36.36363636363635%',\n",
       "   'token_len': 699.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': 'If you have \"yes\" or \"no\", explain in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 40.0,\n",
       "   'relative_improvement': '9.999999999999986%',\n",
       "   'token_len': 700.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '66.66666666666666%',\n",
       "   'token_len': 696.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 696.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '-24.99999999999999%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 14,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 15,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 16,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 17,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 18,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 19,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 20,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526}],\n",
       " 'TER': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0},\n",
       "  {'iteration': 1,\n",
       "   'prompt': 'If you want to justify your response, start it with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '33.3333333333333%',\n",
       "   'token_len': 548.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.',\n",
       "   'edit': 'to_bulletpoints',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '-24.99999999999999%',\n",
       "   'token_len': 547.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 588.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.',\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 623.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '33.3333333333333%',\n",
       "   'token_len': 623.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '-24.99999999999999%',\n",
       "   'token_len': 676.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 696.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 716.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': 'Start with \"yes\" or \"no\" to justify your response.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': '-100.0%',\n",
       "   'token_len': 712.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': 'To justify your response, start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': 'inf%',\n",
       "   'token_len': 713.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': 'To justify your response, start with \"yes\" or \"no\".',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 5,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 827.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': 'To justify your response, start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 5,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 827.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': 'To justify your response, start with \"yes\" or \"no\".',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 6,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 874.9473684210526}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'LAW': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 33.33333333333333}, {'iteration': 1, 'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 36.36363636363637, 'relative_improvement': '9.090909090909104%', 'token_len': 548.9473684210526}, {'iteration': 2, 'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 33.33333333333333, 'relative_improvement': '-8.333333333333359%', 'token_len': 737.9473684210526}, {'iteration': 3, 'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.', 'edit': 'add_negative_example', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 30.76923076923077, 'relative_improvement': '-7.692307692307676%', 'token_len': 784.9473684210526}, {'iteration': 4, 'prompt': 'You should justify your response in 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '62.5%', 'token_len': 782.9473684210526}, {'iteration': 5, 'prompt': ' - Justify response in 50 words or less\\n - Start with \"yes\" or \"no\"', 'edit': 'to_bulletpoints', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 28.57142857142857, 'relative_improvement': '-42.85714285714286%', 'token_len': 778.9473684210526}, {'iteration': 6, 'prompt': 'In 50 words or less, start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 26.666666666666668, 'relative_improvement': '-6.666666666666654%', 'token_len': 776.9473684210526}, {'iteration': 7, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': '-100.0%', 'token_len': 770.9473684210526}, {'iteration': 8, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 9, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 10, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 11, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 12, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 13, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 14, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 15, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 16, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 17, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 18, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 19, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 20, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}], 'LTD': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0}, {'iteration': 1, 'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 542.9473684210526}, {'iteration': 2, 'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.', 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 586.9473684210526}, {'iteration': 3, 'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.', 'edit': 'add_negative_example', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 57.14285714285714, 'relative_improvement': '14.28571428571428%', 'token_len': 620.9473684210526}, {'iteration': 4, 'prompt': 'Begin your answer with \"yes\" or \"no\" and then explain it in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 40.0, 'relative_improvement': '-29.999999999999993%', 'token_len': 619.9473684210526}, {'iteration': 5, 'prompt': ' - Answer with \"yes\" or \"no\"\\n - Explain in 50 words or less', 'edit': 'to_bulletpoints', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 36.36363636363637, 'relative_improvement': '-9.090909090909083%', 'token_len': 615.9473684210526}, {'iteration': 6, 'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 57.14285714285714, 'relative_improvement': '57.14285714285712%', 'token_len': 615.9473684210526}, {'iteration': 7, 'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".', 'edit': 'add_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 1, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 653.9473684210526}, {'iteration': 8, 'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".', 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 36.36363636363637, 'relative_improvement': '-36.36363636363635%', 'token_len': 699.9473684210526}, {'iteration': 9, 'prompt': 'If you have \"yes\" or \"no\", explain in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 40.0, 'relative_improvement': '9.999999999999986%', 'token_len': 700.9473684210526}, {'iteration': 10, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '66.66666666666666%', 'token_len': 696.9473684210526}, {'iteration': 11, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '0.0%', 'token_len': 696.9473684210526}, {'iteration': 12, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '-24.99999999999999%', 'token_len': 813.9473684210526}, {'iteration': 13, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 14, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 15, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 16, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 17, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 18, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 19, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 20, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}], 'TER': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0}, {'iteration': 1, 'prompt': 'If you want to justify your response, start it with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 66.66666666666666, 'relative_improvement': '33.3333333333333%', 'token_len': 548.9473684210526}, {'iteration': 2, 'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.', 'edit': 'to_bulletpoints', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '-24.99999999999999%', 'token_len': 547.9473684210526}, {'iteration': 3, 'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.', 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 588.9473684210526}, {'iteration': 4, 'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.', 'edit': 'add_negative_example', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 623.9473684210526}, {'iteration': 5, 'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '33.3333333333333%', 'token_len': 623.9473684210526}, {'iteration': 6, 'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"', 'edit': 'add_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '-24.99999999999999%', 'token_len': 676.9473684210526}, {'iteration': 7, 'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"', 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 696.9473684210526}, {'iteration': 8, 'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"', 'edit': 'add_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 716.9473684210526}, {'iteration': 9, 'prompt': 'Start with \"yes\" or \"no\" to justify your response.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': '-100.0%', 'token_len': 712.9473684210526}, {'iteration': 10, 'prompt': 'To justify your response, start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': 'inf%', 'token_len': 713.9473684210526}, {'iteration': 11, 'prompt': 'To justify your response, start with \"yes\" or \"no\".', 'edit': 'add_positive_example', 'positive_examples_count': 5, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 827.9473684210526}, {'iteration': 12, 'prompt': 'To justify your response, start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 5, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 827.9473684210526}, {'iteration': 13, 'prompt': 'To justify your response, start with \"yes\" or \"no\".', 'edit': 'add_positive_example', 'positive_examples_count': 6, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 874.9473684210526}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TER': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0},\n",
       "  {'iteration': 1,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 549.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 591.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 628.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'to_bulletpoints',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 625.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 694.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '33.3333333333333%',\n",
       "   'token_len': 756.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 40.0,\n",
       "   'relative_improvement': '-39.99999999999999%',\n",
       "   'token_len': 786.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '42.85714285714284%',\n",
       "   'token_len': 798.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 5,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 40.0,\n",
       "   'relative_improvement': '-29.999999999999993%',\n",
       "   'token_len': 818.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'remove_positive_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 33.33333333333333,\n",
       "   'relative_improvement': '-16.666666666666675%',\n",
       "   'token_len': 786.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'remove_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '100.0%',\n",
       "   'token_len': 749.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'remove_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 680.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 3,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '-14.28571428571428%',\n",
       "   'token_len': 719.9473684210526},\n",
       "  {'iteration': 14,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 4,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '16.66666666666665%',\n",
       "   'token_len': 733.9473684210526},\n",
       "  {'iteration': 15,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 5,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '-14.28571428571428%',\n",
       "   'token_len': 750.9473684210526},\n",
       "  {'iteration': 16,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 767.9473684210526},\n",
       "  {'iteration': 17,\n",
       "   'prompt': \"Start with 'yes' or 'no' and justify in 50 words or less.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 80.0,\n",
       "   'relative_improvement': '40.000000000000014%',\n",
       "   'token_len': 765.9473684210526},\n",
       "  {'iteration': 18,\n",
       "   'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '-28.57142857142858%',\n",
       "   'token_len': 769.9473684210526},\n",
       "  {'iteration': 19,\n",
       "   'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 769.9473684210526},\n",
       "  {'iteration': 20,\n",
       "   'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 769.9473684210526}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'TER': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0}, {'iteration': 1, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 549.9473684210526}, {'iteration': 2, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 591.9473684210526}, {'iteration': 3, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 628.9473684210526}, {'iteration': 4, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'to_bulletpoints', 'positive_examples_count': 2, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 625.9473684210526}, {'iteration': 5, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 694.9473684210526}, {'iteration': 6, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '33.3333333333333%', 'token_len': 756.9473684210526}, {'iteration': 7, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 40.0, 'relative_improvement': '-39.99999999999999%', 'token_len': 786.9473684210526}, {'iteration': 8, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 4, 'negative_examples_count': 2, 'score': 57.14285714285714, 'relative_improvement': '42.85714285714284%', 'token_len': 798.9473684210526}, {'iteration': 9, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 5, 'negative_examples_count': 2, 'score': 40.0, 'relative_improvement': '-29.999999999999993%', 'token_len': 818.9473684210526}, {'iteration': 10, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 2, 'score': 33.33333333333333, 'relative_improvement': '-16.666666666666675%', 'token_len': 786.9473684210526}, {'iteration': 11, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 2, 'score': 66.66666666666666, 'relative_improvement': '100.0%', 'token_len': 749.9473684210526}, {'iteration': 12, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 2, 'score': 66.66666666666666, 'relative_improvement': '0.0%', 'token_len': 680.9473684210526}, {'iteration': 13, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 3, 'score': 57.14285714285714, 'relative_improvement': '-14.28571428571428%', 'token_len': 719.9473684210526}, {'iteration': 14, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 4, 'score': 66.66666666666666, 'relative_improvement': '16.66666666666665%', 'token_len': 733.9473684210526}, {'iteration': 15, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 5, 'score': 57.14285714285714, 'relative_improvement': '-14.28571428571428%', 'token_len': 750.9473684210526}, {'iteration': 16, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 767.9473684210526}, {'iteration': 17, 'prompt': \"Start with 'yes' or 'no' and justify in 50 words or less.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 80.0, 'relative_improvement': '40.000000000000014%', 'token_len': 765.9473684210526}, {'iteration': 18, 'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '-28.57142857142858%', 'token_len': 769.9473684210526}, {'iteration': 19, 'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 769.9473684210526}, {'iteration': 20, 'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 769.9473684210526}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
