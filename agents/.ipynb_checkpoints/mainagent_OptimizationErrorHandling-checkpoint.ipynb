{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT SETUP\n",
    "NUM_ITERATIONS = 20\n",
    "DATASET_SIZE = 25\n",
    "DATASET_CAT = ['A', 'CH', 'CR', 'J', 'LAW', 'LTD', 'TER', 'USE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the LangChain directory to sys.path\n",
    "ail_path = Path().resolve().parent\n",
    "if str(ail_path) not in sys.path:\n",
    "    sys.path.append(str(ail_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' - Start with \"yes\" or \"no\"\\n - Justify response in no more than 50 words'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import pandas as pd\n",
    "import tools.paraphrase\n",
    "from tools.reformat import Reformat\n",
    "from tools.score_complete import score_prompt, score_prompt_01, score_prompt_11\n",
    "import tools.score_complete\n",
    "import tools.ShortenTool\n",
    "import tools.ExampleTool\n",
    "import tools.jump_iteration\n",
    "from tools.output_pipes import MultiLogger\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage\n",
    "import json\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_ids = pd.read_csv('../../dataset/claudette_train_merged.tsv', sep='\\t')['document'].unique()\n",
    "val_doc_ids = pd.read_csv('../../dataset/claudette_val_merged.tsv', sep='\\t')['document'].unique()\n",
    "test_doc_ids = pd.read_csv('../../dataset/claudette_test_merged.tsv', sep='\\t')['document'].unique()\n",
    "\n",
    "df = pd.read_csv('../../dataset/claudette_all_merged.tsv', sep='\\t').rename(columns={\"file_name\": \"document\"})\n",
    "df_train = df.loc[df['document'].isin(train_doc_ids)]\n",
    "#df_train_neg = df_train.loc[df_train['label'] == 0]\n",
    "#df_train_pos = df_train.loc[df_train['label'] == 1]\n",
    "df_val = df.loc[df['document'].isin(val_doc_ids)]\n",
    "df_test = df.loc[df['document'].isin(test_doc_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_30317/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_30317/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_30317/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_30317/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_30317/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_30317/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_30317/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_30317/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n"
     ]
    }
   ],
   "source": [
    "#df_train_pos_per_cat = {}\n",
    "for category in DATASET_CAT:\n",
    "    df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
    "    #df_train.loc[:, category] = df_train_pos.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
    "    #df_train_pos_per_cat[category] = df_train.loc[df_train[category] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_answer_instruction(n_words = 50):\n",
    "    return f'Start your answer with \"yes\" or \"no\" and then justify your response in no more than {n_words} words.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_equal_distribution(df, categories, sample_size, seed=123):\n",
    "    \n",
    "    per_category=int(sample_size/(len(categories)+1))\n",
    "    sample_df = None\n",
    "\n",
    "    for cat in categories:\n",
    "        temp_df = df[df[cat] == 1].sample(n=per_category, random_state=seed)\n",
    "        if type(sample_df) != None:\n",
    "            sample_df = pd.concat([sample_df, temp_df])\n",
    "        else:\n",
    "            sample_df=temp_df\n",
    "\n",
    "    temp_df = df[(df[categories] == 0).all(axis=1)].sample(n=int(sample_size/len(categories)), random_state=seed)\n",
    "    sample_df = pd.concat([sample_df, temp_df])\n",
    "\n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_short = sample_equal_distribution(df_train, DATASET_CAT, DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase = tools.paraphrase.ParaphrasePegasus()\n",
    "shorten = tools.ShortenTool.ShortenTool()\n",
    "reformat = tools.reformat.Reformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt_optimization(intro:str, initial_prompt, df, df_short, model, num_iterations, category, examples):\n",
    "    \"\"\"Optimizes the prompt using an LLM to choose the best edit operation.\"\"\"\n",
    "    ##For this.. online: <current clause, > <Legal Description, > <Examples, >\n",
    "    #optimization_history =  [{'iteration': 1, \"prompt\": part_of_prompt_to_modify, \"score\": 80, \"edit\": \"paraphrase\"}]\n",
    "    print(\"\\n ################################\")\n",
    "    print(\"Optimizing for category: \", category)\n",
    "\n",
    "    optimization_history = []  # Initialize as an empty list attribute\n",
    "    part_of_prompt_to_modify = initial_prompt\n",
    "    iteration = 0\n",
    "    while iteration < num_iterations:\n",
    "    #for iteration in range(num_iterations):  # Iterate for the specified number of times\n",
    "        # 1. Construct LLM Prompt\n",
    "        if iteration == 0:\n",
    "            # Special prompt for the first iteration (no history)\n",
    "            len_pos = len(examples.added_examples[\"positive\"])\n",
    "            len_neg = len(examples.added_examples[\"negative\"])\n",
    "            score_value, _ = score_prompt(intro, examples.added_examples['positive'], examples.added_examples['negative'], part_of_prompt_to_modify, initial_prompt, df_short, category, model, {'p':1, 'r':0, 'l':0}) \n",
    "            optimization_history.append(\n",
    "                {\"iteration\": 0, \"prompt\": part_of_prompt_to_modify, \"edit\": \"inital - no edit\", \"positive_examples_count\": len_pos, \"negative_examples_count\": len_neg, \"score\": score_value}  # Log 1-based iteration\n",
    "            )\n",
    "    \n",
    "            llm_prompt = (\n",
    "                f\"You are tasked with optimizing a prompt. This is the inital iteration (iteration 0).\\n\" \n",
    "                \"The prompt is scored in a scale of 0 - 100. Your goal is to get a score that is high as possible.\"\n",
    "                \"Full Prompt: <intro><current_clause><legal_description><examples><part_of_prompt_to_modify>\"\n",
    "                f\"<intro> is: {intro}\"\n",
    "                \"<current_clause> is the variable clause to be classified.\"\n",
    "                f\"<legal_description> is: Question helping to classify clauses\"\n",
    "                \"<examples> is: optional, example clauses that are either positive or negative to the classification\"\n",
    "                f\"<part_of_prompt_to_modify> is {part_of_prompt_to_modify}, you will only modify this part\\n\\n\"\n",
    "                f\"Your starting point: {optimization_history}\\n\\n\"\n",
    "                \"To optimize the prompt you can use various actions. These actions alter the prompt.\"\n",
    "                #\"To optimize the prompt you can only use one action. \"\n",
    "                \"Choose the most suitable action to improve the prompt:\\n\"\n",
    "                \"- shorten: Shortens the prompt by removing stopwords from the prompt.\\n\"\n",
    "                \"- add_positive_example: Include a positive example.\\n\"\n",
    "                \"- add_negative_example: Include a negative example.\\n\"\n",
    "                \"- reword_prompt: Reword the <part_of_prompt_to_modify>.\\n\"\n",
    "                \"- to_bulletpoints: Formates the <part_of_prompt_to_modify> into bullet points. The output does not change if used twice in a row.\\n\"\n",
    "                #\"- grammar_adjustment: Fix any grammatical errors in the prompt.\\n\"\n",
    "                #\"- jump_back_to_iteration: Jump back to a specific iteration. Use the format 'jump_back_to_iteration <number> because: <reasoning>'.\\n\"\n",
    "                \"Your output should be of form: <chosen_action> because: <reasoning>\"\n",
    "            )\n",
    "        else:\n",
    "            # Prompt for subsequent iterations (with history)\n",
    "            llm_prompt = (\n",
    "                f\"You are tasked with optimizing a prompt used to conduct a classification task with another LLM. \" \n",
    "                \"The classification result using the prompt is scored on a scale of 0 - 100. Your goal is to find the best prompt and get a score as high as possible. \"\n",
    "                f\"The optimization process is done within {num_iterations} iterations the final iteration is expected to provide the optimal prompt. In every iteration, you can choose from a list of possible actions to alter the <part_of_prompt_to_modify>. Please make sure you achieve an optimal prompt until iteration {num_iterations}. This is iteration {iteration + 1}. \\n \"\n",
    "                \"This is the structure of the full prompt given to the classification LLM: <intro><current_clause><legal_description><examples><part_of_prompt_to_modify> \"\n",
    "                \"In the following, the single parts of the full prompt are described:\"\n",
    "                f\"<intro> is: {intro} \\n\"\n",
    "                \"<current_clause> is the variable clause to be classified.\\n\"\n",
    "                f\"<legal_description> is a question helping to classify clauses.\\n\"\n",
    "                \"<examples> is optional this is an example clause representing either a positive or negative clause. It is possible that both negative and positive are present.\\n\"\n",
    "                f\"<part_of_prompt_to_modify> is {part_of_prompt_to_modify}, only modify this part \\n\"\n",
    "                \"The output of the classification LLM is classified positive if the output starts with yes and negative if the output starts with no.\\n\"\n",
    "                \"To optimize the prompt, you can use various actions. \"\n",
    "                f\"This is the history of all conducted operations until now: {optimization_history}\\n\"\n",
    "                \"The history contains the following information: \\n\" \n",
    "                \"iteration: Number of iterations.\\n\"\n",
    "                \"prompt: The used <part_of_prompt_to_modify> so the optimized part of the prompt.\\n\"\n",
    "                \"edit: The action that is used in the regrading iteration.\\n\"\n",
    "                \"score: The achieved score of the prompt edited by the respective action.\\n\"\n",
    "                \"relative_improvement: The relative improvement in percent compared to the previous iteration.\\n\"\n",
    "                \"token_len: token length of the prompt given to the classification LLM.\\n\"\n",
    "                \"If an action did not lead to a higher score after two iterations, try a different action. \"\n",
    "                \"If you find that the score plateaus, it is always possible to return to a previous iteration by taking the respective action. \"\n",
    "                \"Try different actions to get a feeling which leads to a higher score. \\n\"\n",
    "                \" These are the actions you can choose from. Use the most suitable action to improve the prompt further :\\n\"\n",
    "                \"- shorten: Shortens the prompt by removing stopwords from the prompt. The output does not change if used twice in a row.\\n\"\n",
    "                \"- reword_prompt: Reword the <part_of_prompt_to_modify>. \\n\"\n",
    "                \"- to_bulletpoints: Formates the <part_of_prompt_to_modify> into bullet points. The output does not change if used twice in a row.\\n\"\n",
    "                \"- add_positive_example: Include a positive example. A positive example is a clause that belongs to the same category and should be classified as true (a category of several unfairness categories).\\n\"\n",
    "                \"- add_negative_example: Include a negative example. A negative example is a clause that belongs to a different category and should be classified as false (a category of several unfairness categories).\\n\"\n",
    "                \"- remove_positive_example: Remove one of the positive examples previously added with the add_positive_example action.  A positive example is a clause that belongs to the same category and should be classified as true (a category of several unfairness categories).\\n\"\n",
    "                \"- remove_negative_example: Remove one of the negative examples previously added with the add_negative_example action. A negative example is a clause that belongs to a different category and should be classified as false (a category of several unfairness categories).\\n\"\n",
    "                \"- jump_back_to_iteration: Jump back to a previous iteration. If you realize previous actions led to a decrease in performance, you can always return to an iteration step that has been more promising. If you choose this action, your output should be of form: jump_back_to_iteration <number> because: <reasoning>'.\\n\"\n",
    "                    \n",
    "                #\"- grammar_adjustment: Fix any grammatical errors in the prompt.\\n\"\n",
    "                \"Your output should be of form: <chosen_action> because: <reasoning>\"\n",
    "            )\n",
    "\n",
    "        print(f\"\\nThis is iteration {iteration + 1}\")\n",
    "        try:\n",
    "            # 2. Get LLM's Decision\n",
    "            message = HumanMessage(content=llm_prompt)\n",
    "            response = model.invoke([message])\n",
    "            print(f\"Complete response: {response}\")\n",
    "            chosen_action = response.content.lower().split()[0]\n",
    "            #print(\"Response: \" + response)\n",
    "            print(\"Chosen Action: \" + chosen_action)\n",
    "\n",
    "            #if iteration == 1:\n",
    "            #    chosen_action = \"jump_back_to_iteration\"\n",
    "            #    iteration_number = 0\n",
    "            \n",
    "            # 3. Apply Chosen Action\n",
    "            for i in range(2):\n",
    "                if chosen_action == \"shorten\":\n",
    "                    part_of_prompt_to_modify = shorten.shorten_prompt(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"add_positive_example\":\n",
    "                    examples.add_positive_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"add_negative_example\":\n",
    "                    examples.add_negative_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"remove_positive_example\":\n",
    "                    examples.remove_positive_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"remove_negative_example\":\n",
    "                    examples.remove_negative_example(part_of_prompt_to_modify,category)\n",
    "                    break            \n",
    "                elif chosen_action == \"reword_prompt\":\n",
    "                    part_of_prompt_to_modify = paraphrase.paraphrase_pegasus(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"to_bulletpoints\":\n",
    "                    part_of_prompt_to_modify = reformat.reformat(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"jump_back_to_iteration\":\n",
    "                    match = re.search(r'jump_back_to_iteration (\\d+)', response.content.lower())\n",
    "                    if match:\n",
    "                        iteration_number = int(match.group(1))\n",
    "                    print(chosen_action, iteration_number)\n",
    "                    part_of_prompt_to_modify = jump_iteration.jump_back_to_iteration(iteration_number, optimization_history, category)\n",
    "                    print(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                #elif chosen_action == \"grammar_adjustment\":\n",
    "                #    grammarAdjustment = GrammarAdjustment()\n",
    "                #    part_of_prompt_to_modify = grammarAdjustment.grammar_adjustment(current_prompt)\n",
    "                else:\n",
    "                    keywords = [\n",
    "                        \"shorten\", \n",
    "                        \"add_positive_example\", \n",
    "                        \"add_negative_example\", \n",
    "                        \"remove_positive_example\", \n",
    "                        \"remove_negative_example\", \n",
    "                        \"reword_prompt\",  \n",
    "                        \"to_bulletpoints\",\n",
    "                        \"jump_back_to_iteration\"\n",
    "                    ]\n",
    "                    pattern = r'jump_back_to_iteration (\\d+)'\n",
    "                    match = re.search(pattern, response.content.lower())\n",
    "                    if match:\n",
    "                        chosen_action=\"jump_back_to_iteration\"\n",
    "                    else:\n",
    "                        for keyword in keywords:\n",
    "                            if keyword in response.content.lower():\n",
    "                                chosen_action = keyword \n",
    "                                break\n",
    "                            else:\n",
    "                                chosen_action = \"\"\n",
    "                        if chosen_action == \"\":        \n",
    "                            raise ValueError(f\"Invalid action chosen by LLM: {chosen_action}\")\n",
    "                    print(f\"Invalid chosen action. New chosen action after error handling is: {chosen_action}\")\n",
    "\n",
    "            # 4. Score and Log (using self.optimization_history)\n",
    "            score_value, mean_token_len = score_prompt(intro, examples.added_examples['positive'], examples.added_examples['negative'], part_of_prompt_to_modify, initial_prompt, df_short, category, model, {'p':1, 'r':0, 'l':0}) # + legal description, df_test, category, intro \n",
    "            len_pos = len(examples.added_examples[\"positive\"])\n",
    "            len_neg = len(examples.added_examples[\"negative\"])\n",
    "            relative_improvment = str(((score_value/optimization_history[iteration]['score'])-1)*100) + '%'\n",
    "            optimization_history.append(\n",
    "                {\"iteration\": iteration + 1, \"prompt\": part_of_prompt_to_modify, \"edit\": chosen_action, \"positive_examples_count\": len_pos, \"negative_examples_count\": len_neg, \"score\": score_value, \"relative_improvement\": relative_improvment, \"token_len\": mean_token_len}  # Log 1-based iteration\n",
    "            )\n",
    "            iteration += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error during optimization  {e}\")\n",
    "            print(\"Retrying the iteration...\")\n",
    "            #break\n",
    "\n",
    "    return optimization_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ################################\n",
      "Optimizing for category:  LAW\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................\n",
      "Performance score is: 33.33333333333333\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 1\n",
      "Complete response: content='reword_prompt because: The initial score is relatively low, and rewording the prompt can help to clarify the instructions and make them more concise, which can improve the response quality.' response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 354, 'total_tokens': 392, 'completion_time': 0.115628278, 'prompt_time': 0.026942832, 'queue_time': None, 'total_time': 0.14257111}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None} id='run-27fa1f25-8b62-48ff-820a-ff9d89281cae-0' usage_metadata={'input_tokens': 354, 'output_tokens': 38, 'total_tokens': 392}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 28.57142857142857\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 2\n",
      "Complete response: content=\"add_positive_example because: The current score is relatively low, and adding a positive example might help the classification LLM to better understand the context and improve the classification accuracy. Additionally, since no examples have been added yet, it's a good starting point to introduce a positive example to guide the model's learning.\" response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 967, 'total_tokens': 1030, 'completion_time': 0.193881141, 'prompt_time': 0.093704439, 'queue_time': None, 'total_time': 0.28758558}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-3b432676-00a5-4481-9f9d-f380a8fb1e04-0' usage_metadata={'input_tokens': 967, 'output_tokens': 63, 'total_tokens': 1030}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 50.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 3\n",
      "Complete response: content=\"add_positive_example because: The previous iteration's score improved significantly after adding a positive example, and I want to continue exploring the effect of adding more positive examples to the prompt. Additionally, the current score is still relatively low, and I believe adding more context through examples can help the classification LLM better understand the task.\" response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 1063, 'total_tokens': 1128, 'completion_time': 0.201015012, 'prompt_time': 0.084785854, 'queue_time': None, 'total_time': 0.285800866}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-d5c3e626-004b-47cb-96fd-815b10dcabca-0' usage_metadata={'input_tokens': 1063, 'output_tokens': 65, 'total_tokens': 1128}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 40.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 4\n",
      "Complete response: content='add_negative_example because: The current prompt has only positive examples, and adding a negative example can help the classification LLM to better understand the contrast between positive and negative clauses, leading to a more accurate classification.' response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 1159, 'total_tokens': 1202, 'completion_time': 0.131593448, 'prompt_time': 0.085987586, 'queue_time': None, 'total_time': 0.217581034}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-058cc9c9-ff40-4549-8b0c-04f958305ba9-0' usage_metadata={'input_tokens': 1159, 'output_tokens': 43, 'total_tokens': 1202}\n",
      "Chosen Action: add_negative_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 28.57142857142857\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 5\n",
      "Complete response: content='to_bulletpoints because: The current prompt is still in a simple sentence structure, and formatting it into bullet points might make it clearer and more organized for the classification LLM. This could potentially improve the score by making the instructions more concise and easy to follow.' response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 1259, 'total_tokens': 1314, 'completion_time': 0.170173588, 'prompt_time': 0.123344897, 'queue_time': None, 'total_time': 0.293518485}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-3d893b53-300b-40f3-b2cf-182360d09a77-0' usage_metadata={'input_tokens': 1259, 'output_tokens': 55, 'total_tokens': 1314}\n",
      "Chosen Action: to_bulletpoints\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 25.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 6\n",
      "Complete response: content='add_positive_example because: The score has been decreasing in the last two iterations, and adding a positive example might help to improve the classification accuracy. Additionally, the current prompt is in a bulletpoint format, which might make it easier to add an example.' response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 1362, 'total_tokens': 1416, 'completion_time': 0.167053741, 'prompt_time': 0.101065203, 'queue_time': None, 'total_time': 0.268118944}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-1227435c-134b-478d-9c40-4eb78a03f8fe-0' usage_metadata={'input_tokens': 1362, 'output_tokens': 54, 'total_tokens': 1416}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 20.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 7\n",
      "Complete response: content='remove_positive_example because: The score has been decreasing in the last two iterations, and the addition of positive examples in iterations 2, 3, and 6 did not lead to a significant improvement. Removing one of the positive examples might help to simplify the prompt and improve the score.' response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 1461, 'total_tokens': 1520, 'completion_time': 0.183563345, 'prompt_time': 0.267001248, 'queue_time': None, 'total_time': 0.450564593}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-34349fd6-b912-42c3-a5ff-823229aebcc5-0' usage_metadata={'input_tokens': 1461, 'output_tokens': 59, 'total_tokens': 1520}\n",
      "Chosen Action: remove_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 22.22222222222222\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 8\n",
      "Complete response: content=\"I choose: reword_prompt because: The current prompt is in a bulletpoint format, and the score has been plateauing. Rewording the prompt might help to improve the clarity and coherence of the instructions, which could lead to a higher score. Additionally, the last time reword_prompt was used, it resulted in a decrease in score, but it's worth trying again to see if it can have a positive impact this time around.\" response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 1564, 'total_tokens': 1655, 'completion_time': 0.28956584, 'prompt_time': 0.146393468, 'queue_time': None, 'total_time': 0.43595930800000005}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-832cb171-1f76-4bc9-bf3b-07c96b8e0212-0' usage_metadata={'input_tokens': 1564, 'output_tokens': 91, 'total_tokens': 1655}\n",
      "Chosen Action: i\n",
      "Invalid chosen action. New chosen action after error handling is: reword_prompt\n",
      "Starting to paraphrase the following prompt:  - nSummary:\n",
      " - Start answer with 'yes' or 'no'\n",
      " - Justify response with no more than 50 words \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 50.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 9\n",
      "Complete response: content=\"add_positive_example because: The previous iteration's score was 50.0, which is a significant improvement. I want to build on this success by adding another positive example to see if it can further improve the score.\" response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 1626, 'total_tokens': 1671, 'completion_time': 0.139232139, 'prompt_time': 0.130523447, 'queue_time': None, 'total_time': 0.269755586}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None} id='run-bdc8d80f-ca82-4860-ba36-890cdf64e660-0' usage_metadata={'input_tokens': 1626, 'output_tokens': 45, 'total_tokens': 1671}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 50.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 10\n",
      "Complete response: content=\"reword_prompt because: The current prompt is quite simple and direct, and rewording it might help to make it more clear and concise, which could lead to a higher score. Additionally, the last time reword_prompt was used, it led to a significant improvement in score, so it's worth trying again.\" response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 1704, 'total_tokens': 1769, 'completion_time': 0.20238075, 'prompt_time': 0.143658098, 'queue_time': None, 'total_time': 0.346038848}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-00a9960c-08a8-4bca-a05d-69789339e309-0' usage_metadata={'input_tokens': 1704, 'output_tokens': 65, 'total_tokens': 1769}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: Justify the response with no more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 36.36363636363637\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 11\n",
      "Complete response: content='add_positive_example because: The score has decreased in the last iteration, and adding a positive example might help to improve the performance of the classification LLM. Additionally, the history shows that adding positive examples has led to improvements in the past (iterations 2 and 9).' response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1786, 'total_tokens': 1842, 'completion_time': 0.171390382, 'prompt_time': 0.135488742, 'queue_time': None, 'total_time': 0.306879124}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-c2d37df9-1354-4f33-aee1-cec37e03d040-0' usage_metadata={'input_tokens': 1786, 'output_tokens': 56, 'total_tokens': 1842}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 33.33333333333333\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 12\n",
      "Complete response: content='reword_prompt because: The current score is 33.33333333333333, which is a decrease from the previous iteration. I want to try rewording the prompt to see if it can improve the score. Additionally, the previous rewording action in iteration 10 led to a decrease in score, so I want to try a different rewording approach.' response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 1870, 'total_tokens': 1947, 'completion_time': 0.24206253, 'prompt_time': 0.148458705, 'queue_time': None, 'total_time': 0.390521235}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None} id='run-b5642d82-24c9-43c7-af20-3e6da0276bb1-0' usage_metadata={'input_tokens': 1870, 'output_tokens': 77, 'total_tokens': 1947}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: Give the response no more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 28.57142857142857\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 13\n",
      "Complete response: content='add_positive_example because: The score has been decreasing in the last few iterations, and adding a positive example might help to improve the classification accuracy. Additionally, the current prompt is quite concise, and adding an example might provide more context for the classification LLM.' response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 1956, 'total_tokens': 2009, 'completion_time': 0.164184523, 'prompt_time': 0.127960452, 'queue_time': None, 'total_time': 0.29214497500000003}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None} id='run-9859e4fc-8e28-4ec2-b0f0-4d361c3673fe-0' usage_metadata={'input_tokens': 1956, 'output_tokens': 53, 'total_tokens': 2009}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 36.36363636363637\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 14\n",
      "Complete response: content='reword_prompt because: The current prompt \"The response should be no more than 50 words.\" is quite straightforward, but rewording it might help to make it more concise and clear. Additionally, the score has been fluctuating in the last few iterations, so trying a different approach might help to stabilize the performance.' response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 2041, 'total_tokens': 2107, 'completion_time': 0.204005187, 'prompt_time': 0.14499565, 'queue_time': None, 'total_time': 0.349000837}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-0890f874-45e5-4a77-a6ec-b9b11acc4d60-0' usage_metadata={'input_tokens': 2041, 'output_tokens': 66, 'total_tokens': 2107}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: The response should be no more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 44.44444444444444\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 15\n",
      "Complete response: content='reword_prompt because: The current score is 44.44, which is an improvement from the previous iteration. However, I want to try rewording the prompt to see if it can further improve the score. The current prompt is \"The response should not be more than 50 words.\" and I want to try rephrasing it to see if it can make the instruction clearer and more concise.' response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 2126, 'total_tokens': 2209, 'completion_time': 0.25923959, 'prompt_time': 0.215026961, 'queue_time': None, 'total_time': 0.47426655100000004}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None} id='run-0681ec86-bf7c-419e-88d6-b5d2d6eb69db-0' usage_metadata={'input_tokens': 2126, 'output_tokens': 83, 'total_tokens': 2209}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: The response should not be more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 44.44444444444444\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 16\n",
      "Complete response: content='add_positive_example because: The score has plateaued in the last two iterations, and adding a positive example might help to improve the classification accuracy. Additionally, the positive examples count is 5, which is a relatively small number, and adding more examples might provide more context for the classification LLM to learn from.' response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 2207, 'total_tokens': 2271, 'completion_time': 0.196230871, 'prompt_time': 0.22138075, 'queue_time': None, 'total_time': 0.417611621}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-c302e0f9-df3f-4fee-b3b7-1aba2e9000f3-0' usage_metadata={'input_tokens': 2207, 'output_tokens': 64, 'total_tokens': 2271}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 57.14285714285714\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 17\n",
      "Complete response: content='reword_prompt because: The current score is 57.14285714285714, which is a significant improvement from the previous iterations. However, I want to explore the possibility of further improvement by rewording the prompt. The current prompt is \"The response should not be more than 50 words.\" which is concise and clear, but maybe a slight rewording can make it even more effective.' response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 2292, 'total_tokens': 2375, 'completion_time': 0.255588672, 'prompt_time': 0.334372439, 'queue_time': None, 'total_time': 0.589961111}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-886b2c46-9b59-46d6-8b99-d49a9bf726ef-0' usage_metadata={'input_tokens': 2292, 'output_tokens': 83, 'total_tokens': 2375}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: The response should not be more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 66.66666666666666\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 18\n",
      "Complete response: content='reword_prompt because: The current score is 66.66666666666666, which is a significant improvement from the previous iterations. However, I want to try rewording the prompt to see if I can further improve the score. The current prompt is \"The response should be 50 words or less.\" and I want to try to rephrase it to make it more concise and clear.' response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 2375, 'total_tokens': 2457, 'completion_time': 0.252273993, 'prompt_time': 0.320834893, 'queue_time': None, 'total_time': 0.573108886}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-1ed7fa2b-fb2b-477c-bc21-9ef54bb1bee7-0' usage_metadata={'input_tokens': 2375, 'output_tokens': 82, 'total_tokens': 2457}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: The response should be 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 100.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 19\n",
      "Complete response: content=\"reword_prompt because: The current prompt has achieved a perfect score of 100, but I want to try to reword it to see if it can be further optimized or if there's a slight variation that can maintain the high score.\" response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 2457, 'total_tokens': 2506, 'completion_time': 0.157425749, 'prompt_time': 0.446306053, 'queue_time': None, 'total_time': 0.603731802}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None} id='run-2f9d7309-3192-43ec-8969-455a6c71dcd5-0' usage_metadata={'input_tokens': 2457, 'output_tokens': 49, 'total_tokens': 2506}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: The response needs to be 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 66.66666666666666\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 20\n",
      "Complete response: content='reword_prompt because: The current prompt has already achieved a high score of 100.0 in iteration 18, and rewording the prompt might help to further refine it and maintain the high score. Additionally, rewording the prompt can help to avoid overfitting to a specific wording and make the model more robust.' response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 2540, 'total_tokens': 2608, 'completion_time': 0.215631734, 'prompt_time': 0.323726321, 'queue_time': None, 'total_time': 0.539358055}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-edb18bf4-df32-4841-933e-d35aebcc37bf-0' usage_metadata={'input_tokens': 2540, 'output_tokens': 68, 'total_tokens': 2608}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: The response should be 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 66.66666666666666\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "Total time of cat LAW is 65 min and 11.501418828964233 sec.\n",
      "Positive example list: \n",
      " ['this agreement , and any dispute between you and the company , shall be governed by the laws of the state of texas without regard to principles of conflicts of law , provided that this arbitration agreement shall be governed by the federal arbitration act .', 'if your country of residence is australia , these terms and the relationship between you and weebly shall be governed by the laws of victoria .', 'such body of law will apply regardless of your residence or the location of where you use the grindr services .', '14.2 the relationship between you and noe , in particular when acquiring digital products via the nintendo shopping services from noe , shall be governed by the laws of germany , to the exclusion of the un sales convention on contracts for the international sale of goods .', 'if you are paying a reservation by credit card or debit card processed by enett international -lrb- uk -rrb- limited , the transaction shall be governed by the laws of england and wales , to the extent permitted by applicable laws .', 'these terms are governed by california law , excluding its conflicts of law principles , and if there is a lawsuit between you and imgur , jurisdiction and venue will lie exclusively in the state where the defendant is located , if within the united states , or in santa clara county , california otherwise .']\n",
      "\n",
      "Negative example list: \n",
      " [\"however , match will not be liable for damage which the member or subscriber could have avoided by following match 's advice to apply an update offered to him/her free of charge or for damage which was caused by him/her failing to correctly follow installation instructions or to have in place the minimum system requirements advised by match .\"]\n",
      "\n",
      "\n",
      "\n",
      "{'LAW': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 33.33333333333333}, {'iteration': 1, 'prompt': \"If you start your answer with 'yes' or 'no', you can justify your response with no more than 50 words.\", 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 28.57142857142857, 'relative_improvement': '-14.28571428571428%', 'token_len': 548.9473684210526}, {'iteration': 2, 'prompt': \"If you start your answer with 'yes' or 'no', you can justify your response with no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '75.00000000000003%', 'token_len': 580.9473684210526}, {'iteration': 3, 'prompt': \"If you start your answer with 'yes' or 'no', you can justify your response with no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 0, 'score': 40.0, 'relative_improvement': '-19.999999999999996%', 'token_len': 629.9473684210526}, {'iteration': 4, 'prompt': \"If you start your answer with 'yes' or 'no', you can justify your response with no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 1, 'score': 28.57142857142857, 'relative_improvement': '-28.57142857142858%', 'token_len': 703.9473684210526}, {'iteration': 5, 'prompt': \" - nSummary:\\n - Start answer with 'yes' or 'no'\\n - Justify response with no more than 50 words\", 'edit': 'to_bulletpoints', 'positive_examples_count': 2, 'negative_examples_count': 1, 'score': 25.0, 'relative_improvement': '-12.49999999999999%', 'token_len': 699.9473684210526}, {'iteration': 6, 'prompt': \" - nSummary:\\n - Start answer with 'yes' or 'no'\\n - Justify response with no more than 50 words\", 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 20.0, 'relative_improvement': '-19.999999999999996%', 'token_len': 728.9473684210526}, {'iteration': 7, 'prompt': \" - nSummary:\\n - Start answer with 'yes' or 'no'\\n - Justify response with no more than 50 words\", 'edit': 'remove_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 1, 'score': 22.22222222222222, 'relative_improvement': '11.111111111111116%', 'token_len': 706.9473684210526}, {'iteration': 8, 'prompt': 'Justify the response with no more than 50 words.', 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '125.0%', 'token_len': 696.9473684210526}, {'iteration': 9, 'prompt': 'Justify the response with no more than 50 words.', 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 720.9473684210526}, {'iteration': 10, 'prompt': 'Give the response no more than 50 words.', 'edit': 'reword_prompt', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 36.36363636363637, 'relative_improvement': '-27.27272727272727%', 'token_len': 719.9473684210526}, {'iteration': 11, 'prompt': 'Give the response no more than 50 words.', 'edit': 'add_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 33.33333333333333, 'relative_improvement': '-8.333333333333359%', 'token_len': 770.9473684210526}, {'iteration': 12, 'prompt': 'The response should be no more than 50 words.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 28.57142857142857, 'relative_improvement': '-14.28571428571428%', 'token_len': 771.9473684210526}, {'iteration': 13, 'prompt': 'The response should be no more than 50 words.', 'edit': 'add_positive_example', 'positive_examples_count': 5, 'negative_examples_count': 1, 'score': 36.36363636363637, 'relative_improvement': '27.272727272727295%', 'token_len': 816.9473684210526}, {'iteration': 14, 'prompt': 'The response should not be more than 50 words.', 'edit': 'reword_prompt', 'positive_examples_count': 5, 'negative_examples_count': 1, 'score': 44.44444444444444, 'relative_improvement': '22.22222222222221%', 'token_len': 816.9473684210526}, {'iteration': 15, 'prompt': 'The response should not be more than 50 words.', 'edit': 'reword_prompt', 'positive_examples_count': 5, 'negative_examples_count': 1, 'score': 44.44444444444444, 'relative_improvement': '0.0%', 'token_len': 816.9473684210526}, {'iteration': 16, 'prompt': 'The response should not be more than 50 words.', 'edit': 'add_positive_example', 'positive_examples_count': 6, 'negative_examples_count': 1, 'score': 57.14285714285714, 'relative_improvement': '28.57142857142856%', 'token_len': 875.9473684210526}, {'iteration': 17, 'prompt': 'The response should be 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 6, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '16.66666666666665%', 'token_len': 874.9473684210526}, {'iteration': 18, 'prompt': 'The response needs to be 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 6, 'negative_examples_count': 1, 'score': 100.0, 'relative_improvement': '50.00000000000002%', 'token_len': 875.9473684210526}, {'iteration': 19, 'prompt': 'The response should be 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 6, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '-33.33333333333335%', 'token_len': 874.9473684210526}, {'iteration': 20, 'prompt': 'The response should be 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 6, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '0.0%', 'token_len': 874.9473684210526}]}\n"
     ]
    }
   ],
   "source": [
    "# Define your model (using your actual API key/setup)\n",
    "model = ChatGroq(\n",
    "    model_name=\"llama3-70b-8192\",\n",
    "    groq_api_key=\"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\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Initial prompt to be optimized\n",
    "optimized_prompt_dict = {}\n",
    "#initial_prompt = \"Consider the following online terms of service clause: 'websites & communications terms of use'. Does this clause describe an arbitration dispute resolution process that is not fully optional to the consumer? Begin your answer with 'yes' or 'no' and then justify your response in no more than 50 words. For example, consider these example clauses: <positive, if you are not a consumer in the eea , the exclusive place of jurisdiction for all disputes arising from or in connection with this agreement is san francisco county , california , or the united states district court for the northern district of california and our dispute will bedetermined under california law .'>, <negative, you are prohibited from using any services or facilities provided in connection with this service to compromise security or tamper with system resources and/or accounts .>\"\n",
    "unfairness_categories = ['A', 'CH', 'CR', 'J', 'LAW', 'LTD', 'TER', 'USE']\n",
    "unfairness_categories_green = ['A', 'CH', 'CR', 'J']\n",
    "unfairness_categories_pink = ['LAW', 'LTD', 'TER', 'USE']\n",
    "\n",
    "initial_prompt = \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\"\n",
    "intro_prompt = 'Consider the following online terms of service clause:'\n",
    "#cat_results = {}\n",
    "#df_train_sample = sample_equal_distribution(df_train, unfairness_categories, 100, 123)\n",
    "#score_set_df = sample_equal_distribution(df_train, unfairness_categories, 25, 234)\n",
    "output = ''\n",
    "\n",
    "filename = \"20240801_vanilla_withshorten_f1_score_binary_newAPIKey_A_NEW.txt\"\n",
    "output_dir = os.path.join('..', 'output')\n",
    "file_path = os.path.join(output_dir, filename)\n",
    "if os.path.exists(file_path):\n",
    "    raise FileExistsError(f\"Error: The file '{filename}' already exists in the 'output' directory. \"\n",
    "                            f\"It is not recommended to overwrite an output file. Please specify another name.\")\n",
    "\n",
    "# Create and open the file\n",
    "file_stream = open(file_path, 'w')\n",
    "\n",
    "# Buffer for capturing print output\n",
    "buffer = io.StringIO()\n",
    "\n",
    "# MultiLogger setup to write to stdout, buffer, and file\n",
    "multi_logger = MultiLogger(sys.stdout, buffer, file_stream)\n",
    "sys.stdout = multi_logger\n",
    "try:\n",
    "    for cat in [\"LAW\"]:\n",
    "        examples_instance = tools.ExampleTool.ExampleTool(df_train)\n",
    "        jump_iteration = tools.jump_iteration.jump_iteration(examples_instance)\n",
    "        start_time = time.time()\n",
    "        optimized_prompt_dict[cat] = run_prompt_optimization(intro_prompt, initial_prompt, df_train, df_train_short, model, NUM_ITERATIONS, cat, examples_instance)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        elapse_time = end_time - start_time\n",
    "        elapse_minutes = int(elapse_time // 60)\n",
    "        elapse_seconds = elapse_time % 60\n",
    "\n",
    "        print(f\"Total time of cat {cat} is {elapse_minutes} min and {elapse_seconds} sec.\")\n",
    "        print(\"Positive example list: \\n\", examples_instance.added_examples[\"positive\"])\n",
    "        print(\"\\nNegative example list: \\n\",examples_instance.added_examples[\"negative\"])\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    print(optimized_prompt_dict)\n",
    "    # Cleanup\n",
    "    sys.stdout = sys.__stdout__  # Reset stdout to default\n",
    "    file_stream.close()\n",
    "\n",
    "    output = buffer.getvalue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAW & LTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LAW': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 33.33333333333333},\n",
       "  {'iteration': 1,\n",
       "   'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 36.36363636363637,\n",
       "   'relative_improvement': '9.090909090909104%',\n",
       "   'token_len': 548.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 33.33333333333333,\n",
       "   'relative_improvement': '-8.333333333333359%',\n",
       "   'token_len': 737.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.',\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 30.76923076923077,\n",
       "   'relative_improvement': '-7.692307692307676%',\n",
       "   'token_len': 784.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': 'You should justify your response in 50 words or less if you start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '62.5%',\n",
       "   'token_len': 782.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': ' - Justify response in 50 words or less\\n - Start with \"yes\" or \"no\"',\n",
       "   'edit': 'to_bulletpoints',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 28.57142857142857,\n",
       "   'relative_improvement': '-42.85714285714286%',\n",
       "   'token_len': 778.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': 'In 50 words or less, start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 26.666666666666668,\n",
       "   'relative_improvement': '-6.666666666666654%',\n",
       "   'token_len': 776.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': '-100.0%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 14,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 15,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 16,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 17,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 18,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 19,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 20,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526}],\n",
       " 'LTD': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0},\n",
       "  {'iteration': 1,\n",
       "   'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 542.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 586.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.',\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '14.28571428571428%',\n",
       "   'token_len': 620.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': 'Begin your answer with \"yes\" or \"no\" and then explain it in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 40.0,\n",
       "   'relative_improvement': '-29.999999999999993%',\n",
       "   'token_len': 619.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': ' - Answer with \"yes\" or \"no\"\\n - Explain in 50 words or less',\n",
       "   'edit': 'to_bulletpoints',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 36.36363636363637,\n",
       "   'relative_improvement': '-9.090909090909083%',\n",
       "   'token_len': 615.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '57.14285714285712%',\n",
       "   'token_len': 615.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 653.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 36.36363636363637,\n",
       "   'relative_improvement': '-36.36363636363635%',\n",
       "   'token_len': 699.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': 'If you have \"yes\" or \"no\", explain in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 40.0,\n",
       "   'relative_improvement': '9.999999999999986%',\n",
       "   'token_len': 700.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '66.66666666666666%',\n",
       "   'token_len': 696.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 696.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '-24.99999999999999%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 14,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 15,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 16,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 17,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 18,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 19,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 20,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526}],\n",
       " 'TER': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0},\n",
       "  {'iteration': 1,\n",
       "   'prompt': 'If you want to justify your response, start it with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '33.3333333333333%',\n",
       "   'token_len': 548.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.',\n",
       "   'edit': 'to_bulletpoints',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '-24.99999999999999%',\n",
       "   'token_len': 547.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 588.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.',\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 623.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '33.3333333333333%',\n",
       "   'token_len': 623.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '-24.99999999999999%',\n",
       "   'token_len': 676.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 696.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 716.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': 'Start with \"yes\" or \"no\" to justify your response.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': '-100.0%',\n",
       "   'token_len': 712.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': 'To justify your response, start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': 'inf%',\n",
       "   'token_len': 713.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': 'To justify your response, start with \"yes\" or \"no\".',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 5,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 827.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': 'To justify your response, start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 5,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 827.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': 'To justify your response, start with \"yes\" or \"no\".',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 6,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 874.9473684210526}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'LAW': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 33.33333333333333}, {'iteration': 1, 'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 36.36363636363637, 'relative_improvement': '9.090909090909104%', 'token_len': 548.9473684210526}, {'iteration': 2, 'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 33.33333333333333, 'relative_improvement': '-8.333333333333359%', 'token_len': 737.9473684210526}, {'iteration': 3, 'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.', 'edit': 'add_negative_example', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 30.76923076923077, 'relative_improvement': '-7.692307692307676%', 'token_len': 784.9473684210526}, {'iteration': 4, 'prompt': 'You should justify your response in 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '62.5%', 'token_len': 782.9473684210526}, {'iteration': 5, 'prompt': ' - Justify response in 50 words or less\\n - Start with \"yes\" or \"no\"', 'edit': 'to_bulletpoints', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 28.57142857142857, 'relative_improvement': '-42.85714285714286%', 'token_len': 778.9473684210526}, {'iteration': 6, 'prompt': 'In 50 words or less, start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 26.666666666666668, 'relative_improvement': '-6.666666666666654%', 'token_len': 776.9473684210526}, {'iteration': 7, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': '-100.0%', 'token_len': 770.9473684210526}, {'iteration': 8, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 9, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 10, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 11, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 12, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 13, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 14, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 15, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 16, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 17, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 18, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 19, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 20, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}], 'LTD': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0}, {'iteration': 1, 'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 542.9473684210526}, {'iteration': 2, 'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.', 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 586.9473684210526}, {'iteration': 3, 'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.', 'edit': 'add_negative_example', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 57.14285714285714, 'relative_improvement': '14.28571428571428%', 'token_len': 620.9473684210526}, {'iteration': 4, 'prompt': 'Begin your answer with \"yes\" or \"no\" and then explain it in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 40.0, 'relative_improvement': '-29.999999999999993%', 'token_len': 619.9473684210526}, {'iteration': 5, 'prompt': ' - Answer with \"yes\" or \"no\"\\n - Explain in 50 words or less', 'edit': 'to_bulletpoints', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 36.36363636363637, 'relative_improvement': '-9.090909090909083%', 'token_len': 615.9473684210526}, {'iteration': 6, 'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 57.14285714285714, 'relative_improvement': '57.14285714285712%', 'token_len': 615.9473684210526}, {'iteration': 7, 'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".', 'edit': 'add_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 1, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 653.9473684210526}, {'iteration': 8, 'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".', 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 36.36363636363637, 'relative_improvement': '-36.36363636363635%', 'token_len': 699.9473684210526}, {'iteration': 9, 'prompt': 'If you have \"yes\" or \"no\", explain in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 40.0, 'relative_improvement': '9.999999999999986%', 'token_len': 700.9473684210526}, {'iteration': 10, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '66.66666666666666%', 'token_len': 696.9473684210526}, {'iteration': 11, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '0.0%', 'token_len': 696.9473684210526}, {'iteration': 12, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '-24.99999999999999%', 'token_len': 813.9473684210526}, {'iteration': 13, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 14, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 15, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 16, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 17, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 18, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 19, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 20, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}], 'TER': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0}, {'iteration': 1, 'prompt': 'If you want to justify your response, start it with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 66.66666666666666, 'relative_improvement': '33.3333333333333%', 'token_len': 548.9473684210526}, {'iteration': 2, 'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.', 'edit': 'to_bulletpoints', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '-24.99999999999999%', 'token_len': 547.9473684210526}, {'iteration': 3, 'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.', 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 588.9473684210526}, {'iteration': 4, 'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.', 'edit': 'add_negative_example', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 623.9473684210526}, {'iteration': 5, 'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '33.3333333333333%', 'token_len': 623.9473684210526}, {'iteration': 6, 'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"', 'edit': 'add_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '-24.99999999999999%', 'token_len': 676.9473684210526}, {'iteration': 7, 'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"', 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 696.9473684210526}, {'iteration': 8, 'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"', 'edit': 'add_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 716.9473684210526}, {'iteration': 9, 'prompt': 'Start with \"yes\" or \"no\" to justify your response.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': '-100.0%', 'token_len': 712.9473684210526}, {'iteration': 10, 'prompt': 'To justify your response, start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': 'inf%', 'token_len': 713.9473684210526}, {'iteration': 11, 'prompt': 'To justify your response, start with \"yes\" or \"no\".', 'edit': 'add_positive_example', 'positive_examples_count': 5, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 827.9473684210526}, {'iteration': 12, 'prompt': 'To justify your response, start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 5, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 827.9473684210526}, {'iteration': 13, 'prompt': 'To justify your response, start with \"yes\" or \"no\".', 'edit': 'add_positive_example', 'positive_examples_count': 6, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 874.9473684210526}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TER': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0},\n",
       "  {'iteration': 1,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 549.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 591.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 628.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'to_bulletpoints',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 625.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 694.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '33.3333333333333%',\n",
       "   'token_len': 756.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 40.0,\n",
       "   'relative_improvement': '-39.99999999999999%',\n",
       "   'token_len': 786.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '42.85714285714284%',\n",
       "   'token_len': 798.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 5,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 40.0,\n",
       "   'relative_improvement': '-29.999999999999993%',\n",
       "   'token_len': 818.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'remove_positive_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 33.33333333333333,\n",
       "   'relative_improvement': '-16.666666666666675%',\n",
       "   'token_len': 786.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'remove_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '100.0%',\n",
       "   'token_len': 749.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'remove_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 680.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 3,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '-14.28571428571428%',\n",
       "   'token_len': 719.9473684210526},\n",
       "  {'iteration': 14,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 4,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '16.66666666666665%',\n",
       "   'token_len': 733.9473684210526},\n",
       "  {'iteration': 15,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 5,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '-14.28571428571428%',\n",
       "   'token_len': 750.9473684210526},\n",
       "  {'iteration': 16,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 767.9473684210526},\n",
       "  {'iteration': 17,\n",
       "   'prompt': \"Start with 'yes' or 'no' and justify in 50 words or less.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 80.0,\n",
       "   'relative_improvement': '40.000000000000014%',\n",
       "   'token_len': 765.9473684210526},\n",
       "  {'iteration': 18,\n",
       "   'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '-28.57142857142858%',\n",
       "   'token_len': 769.9473684210526},\n",
       "  {'iteration': 19,\n",
       "   'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 769.9473684210526},\n",
       "  {'iteration': 20,\n",
       "   'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 769.9473684210526}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'TER': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0}, {'iteration': 1, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 549.9473684210526}, {'iteration': 2, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 591.9473684210526}, {'iteration': 3, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 628.9473684210526}, {'iteration': 4, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'to_bulletpoints', 'positive_examples_count': 2, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 625.9473684210526}, {'iteration': 5, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 694.9473684210526}, {'iteration': 6, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '33.3333333333333%', 'token_len': 756.9473684210526}, {'iteration': 7, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 40.0, 'relative_improvement': '-39.99999999999999%', 'token_len': 786.9473684210526}, {'iteration': 8, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 4, 'negative_examples_count': 2, 'score': 57.14285714285714, 'relative_improvement': '42.85714285714284%', 'token_len': 798.9473684210526}, {'iteration': 9, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 5, 'negative_examples_count': 2, 'score': 40.0, 'relative_improvement': '-29.999999999999993%', 'token_len': 818.9473684210526}, {'iteration': 10, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 2, 'score': 33.33333333333333, 'relative_improvement': '-16.666666666666675%', 'token_len': 786.9473684210526}, {'iteration': 11, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 2, 'score': 66.66666666666666, 'relative_improvement': '100.0%', 'token_len': 749.9473684210526}, {'iteration': 12, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 2, 'score': 66.66666666666666, 'relative_improvement': '0.0%', 'token_len': 680.9473684210526}, {'iteration': 13, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 3, 'score': 57.14285714285714, 'relative_improvement': '-14.28571428571428%', 'token_len': 719.9473684210526}, {'iteration': 14, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 4, 'score': 66.66666666666666, 'relative_improvement': '16.66666666666665%', 'token_len': 733.9473684210526}, {'iteration': 15, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 5, 'score': 57.14285714285714, 'relative_improvement': '-14.28571428571428%', 'token_len': 750.9473684210526}, {'iteration': 16, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 767.9473684210526}, {'iteration': 17, 'prompt': \"Start with 'yes' or 'no' and justify in 50 words or less.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 80.0, 'relative_improvement': '40.000000000000014%', 'token_len': 765.9473684210526}, {'iteration': 18, 'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '-28.57142857142858%', 'token_len': 769.9473684210526}, {'iteration': 19, 'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 769.9473684210526}, {'iteration': 20, 'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 769.9473684210526}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
