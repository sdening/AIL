{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT SETUP\n",
    "NUM_ITERATIONS = 20\n",
    "DATASET_SIZE = 25\n",
    "DATASET_CAT = ['A', 'CH', 'CR', 'J', 'LAW', 'LTD', 'TER', 'USE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the LangChain directory to sys.path\n",
    "ail_path = Path().resolve().parent\n",
    "if str(ail_path) not in sys.path:\n",
    "    sys.path.append(str(ail_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' - Start with \"yes\" or \"no\"\\n - Justify response in no more than 50 words'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sandradening/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import pandas as pd\n",
    "import tools.paraphrase\n",
    "from tools.reformat import Reformat\n",
    "from tools.score_complete import score_prompt, score_prompt_01, score_prompt_11\n",
    "import tools.score_complete\n",
    "import tools.ShortenTool\n",
    "import tools.ExampleTool\n",
    "import tools.jump_iteration\n",
    "from tools.output_pipes import MultiLogger\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage\n",
    "import json\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_ids = pd.read_csv('../../dataset/claudette_train_merged.tsv', sep='\\t')['document'].unique()\n",
    "val_doc_ids = pd.read_csv('../../dataset/claudette_val_merged.tsv', sep='\\t')['document'].unique()\n",
    "test_doc_ids = pd.read_csv('../../dataset/claudette_test_merged.tsv', sep='\\t')['document'].unique()\n",
    "\n",
    "df = pd.read_csv('../../dataset/claudette_all_merged.tsv', sep='\\t').rename(columns={\"file_name\": \"document\"})\n",
    "df_train = df.loc[df['document'].isin(train_doc_ids)]\n",
    "#df_train_neg = df_train.loc[df_train['label'] == 0]\n",
    "#df_train_pos = df_train.loc[df_train['label'] == 1]\n",
    "df_val = df.loc[df['document'].isin(val_doc_ids)]\n",
    "df_test = df.loc[df['document'].isin(test_doc_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_56035/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_56035/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_56035/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_56035/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_56035/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_56035/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_56035/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_56035/95851583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n"
     ]
    }
   ],
   "source": [
    "#df_train_pos_per_cat = {}\n",
    "for category in DATASET_CAT:\n",
    "    df_train.loc[:, category] = df_train.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
    "    #df_train.loc[:, category] = df_train_pos.loc[:, 'label_type'].apply(lambda cats: int(category.upper() in cats))\n",
    "    #df_train_pos_per_cat[category] = df_train.loc[df_train[category] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_answer_instruction(n_words = 50):\n",
    "    return f'Start your answer with \"yes\" or \"no\" and then justify your response in no more than {n_words} words.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_equal_distribution(df, categories, sample_size, seed=123):\n",
    "    \n",
    "    per_category=int(sample_size/(len(categories)+1))\n",
    "    sample_df = None\n",
    "\n",
    "    for cat in categories:\n",
    "        temp_df = df[df[cat] == 1].sample(n=per_category, random_state=seed)\n",
    "        if type(sample_df) != None:\n",
    "            sample_df = pd.concat([sample_df, temp_df])\n",
    "        else:\n",
    "            sample_df=temp_df\n",
    "\n",
    "    temp_df = df[(df[categories] == 0).all(axis=1)].sample(n=int(sample_size/len(categories)), random_state=seed)\n",
    "    sample_df = pd.concat([sample_df, temp_df])\n",
    "\n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_short = sample_equal_distribution(df_train, DATASET_CAT, DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase = tools.paraphrase.ParaphrasePegasus()\n",
    "shorten = tools.ShortenTool.ShortenTool()\n",
    "reformat = tools.reformat.Reformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt_optimization(intro:str, initial_prompt, df, df_short, model, num_iterations, category, examples):\n",
    "    \"\"\"Optimizes the prompt using an LLM to choose the best edit operation.\"\"\"\n",
    "    ##For this.. online: <current clause, > <Legal Description, > <Examples, >\n",
    "    #optimization_history =  [{'iteration': 1, \"prompt\": part_of_prompt_to_modify, \"score\": 80, \"edit\": \"paraphrase\"}]\n",
    "    print(\"\\n ################################\")\n",
    "    print(\"Optimizing for category: \", category)\n",
    "\n",
    "    optimization_history = []  # Initialize as an empty list attribute\n",
    "    part_of_prompt_to_modify = initial_prompt\n",
    "    iteration = 0\n",
    "    while iteration < num_iterations:\n",
    "    #for iteration in range(num_iterations):  # Iterate for the specified number of times\n",
    "        # 1. Construct LLM Prompt\n",
    "        if iteration == 0:\n",
    "            # Special prompt for the first iteration (no history)\n",
    "            len_pos = len(examples.added_examples[\"positive\"])\n",
    "            len_neg = len(examples.added_examples[\"negative\"])\n",
    "            score_value, _ = score_prompt(intro, examples.added_examples['positive'], examples.added_examples['negative'], part_of_prompt_to_modify, initial_prompt, df_short, category, model, {'p':1, 'r':0, 'l':0}) \n",
    "            optimization_history.append(\n",
    "                {\"iteration\": 0, \"prompt\": part_of_prompt_to_modify, \"edit\": \"inital - no edit\", \"positive_examples_count\": len_pos, \"negative_examples_count\": len_neg, \"score\": score_value}  # Log 1-based iteration\n",
    "            )\n",
    "    \n",
    "            llm_prompt = (\n",
    "                \"You are tasked with optimizing a prompt which is used to conduct a classification task with another LLM on a test set. The classification task is to classify legal clauses either as fair or unfair clauses of different legal unfairness categories by doing it via one vs. all classification. An unfair clause is either in a specific unfairness category or not (fair or another unfairness category).\"\n",
    "                \"The classification result using the prompt is scored based on recall, focusing on capturing as many true positive unfair clauses as possible. The goal is to achieve a high recall score while maintaining the specificity of the model’s classification.\"\n",
    "                f\"The optimization process is done within 20 iterations. The final iteration is expected to provide the optimal prompt. In every iteration, you can choose from a list of possible actions to alter the <part_of_prompt_to_modify>. Please ensure you achieve an optimal prompt by iteration 20. This is iteration {iteration + 1}. \\n\"\n",
    "                \"The optimized prompt will be later used on another bigger unseen test set to test generalized performance. It is crucial that the classification output of the LLM starts with 'yes' for positive (unfair) classifications and 'no' for negative (fair or other category) classifications, as only the first word will determine true/false positives/negatives.\"\n",
    "                \"This is the structure of the full prompt given to the classification LLM: <intro><current_clause><legal_description><examples><part_of_prompt_to_modify>.\"\n",
    "                \"In the following, the single parts of the full prompt are described:\"\n",
    "                f\"<intro> is: {intro} \\n\"\n",
    "                \"<current_clause>: the variable clause to be classified.\\n\"\n",
    "                \"<legal_description>: a question aiding in classifying clauses, consistent across all clauses per unfairness category.\\n\"\n",
    "                \"<examples>: Optional. Includes example clauses representing either a positive or negative clause. It is possible that both negative and positive examples are present.\\n\"\n",
    "                f\"<part_of_prompt_to_modify>: which is currently {part_of_prompt_to_modify}, and only this part should be modified in order to optimize performance.\\n\"\n",
    "                \n",
    "                \"Your optimization should emphasize achieving high recall, which means capturing as many true positives as possible. Since the classification depends on the first word, ensure that the output begins with 'yes' for positives and 'no' for negatives.\"\n",
    "\n",
    "                \"In every iteration, choose from the following actions to improve the prompt. Aim for high recall, ensuring the prompt captures the maximum number of true positives.\"\n",
    "\n",
    "                \"The history contains the following information:\"\n",
    "                \"iteration: Number of iteration.\\n\"\n",
    "                \"prompt: The used <part_of_prompt_to_modify> optimized using the actions\\n\"\n",
    "                \"edit: The action used in the respective iteration.\\n\"\n",
    "                \"score: The recall score of the prompt, representing the number of true positives correctly identified.\\n\"\n",
    "                \"relative_improvement: The relative improvement in percent compared to the previous iteration.\\n\"\n",
    "                \"token_len: Token length of the prompt given to the classification LLM.\\n\"\n",
    "    \n",
    "                \"If an action does not lead to a higher score after two iterations, try a different action. If the score plateaus, return to a previous iteration by taking the respective action 'jump_back_to_iteration <number of iteration>'. Try different actions to gauge which leads to improved scores.\"\n",
    "                \"Select the most suitable action to enhance the prompt and achieve the highest recall score by iteration 20:\"\n",
    "                \"- shorten: Shortens the prompt by removing stopwords. The output does not change if used twice consecutively.\\n\"\n",
    "                \"- reword_prompt: Reword the <part_of_prompt_to_modify> using the 'PegasusTokenizer'.\\n\"\n",
    "                \"- to_bulletpoints: Formats the <part_of_prompt_to_modify> into bullet points. The output does not change if used twice consecutively.\\n\"\n",
    "                \"- add_positive_example: Include a positive example. A positive example is a clause that belongs to the same category and should be classified as 'yes'.\\n\"\n",
    "                \"- add_negative_example: Include a negative example. A negative example is a clause that belongs to a different category and should be classified as 'no'.\\n\"\n",
    "                \"- remove_positive_example: Remove one of the positive examples previously added with the add_positive_example action. A positive example is a clause that belongs to the same category and should be classified as 'yes'.\\n\"\n",
    "                \"- remove_negative_example: Remove one of the negative examples previously added with the add_negative_example action. A negative example is a clause that belongs to a different category and should be classified as 'no'.\\n\"\n",
    "                   \n",
    "                \"Your output should be formatted as: <chosen_action> because: <reasoning>\"\n",
    "            )\n",
    "        else:\n",
    "            # Prompt for subsequent iterations (with history)\n",
    "            llm_prompt = (\n",
    "                \"You are tasked with optimizing a prompt which is used to conduct a classification task with another LLM on a test set. The classification task is to classify legal clauses either as fair or unfair clauses of different legal unfairness categories by doing it via one vs. all classification. An unfair clause is either in a specific unfairness category or not (fair or another unfairness category).\"\n",
    "                \"The classification result using the prompt is scored based on recall, focusing on capturing as many true positive unfair clauses as possible. The goal is to achieve a high recall score while maintaining the specificity of the model’s classification.\"\n",
    "                f\"The optimization process is done within 20 iterations. The final iteration is expected to provide the optimal prompt. In every iteration, you can choose from a list of possible actions to alter the <part_of_prompt_to_modify>. Please ensure you achieve an optimal prompt by iteration 20. This is iteration {iteration + 1}. \\n\"\n",
    "                \"The optimized prompt will be later used on another bigger unseen test set to test generalized performance. It is crucial that the classification output of the LLM starts with 'yes' for positive (unfair) classifications and 'no' for negative (fair or other category) classifications, as only the first word will determine true/false positives/negatives.\"\n",
    "                \"This is the structure of the full prompt given to the classification LLM: <intro><current_clause><legal_description><examples><part_of_prompt_to_modify>.\"\n",
    "                \"In the following, the single parts of the full prompt are described:\"\n",
    "                f\"<intro> is: {intro} \\n\"\n",
    "                \"<current_clause>: the variable clause to be classified.\\n\"\n",
    "                \"<legal_description>: a question aiding in classifying clauses, consistent across all clauses per unfairness category.\\n\"\n",
    "                \"<examples>: Optional. Includes example clauses representing either a positive or negative clause. It is possible that both negative and positive examples are present.\\n\"\n",
    "                f\"<part_of_prompt_to_modify>: which is currently {part_of_prompt_to_modify}, and only this part should be modified in order to optimize performance.\\n\"\n",
    "                \n",
    "                \"Your optimization should emphasize achieving high recall, which means capturing as many true positives as possible. Since the classification depends on the first word, ensure that the output begins with 'yes' for positives and 'no' for negatives.\"\n",
    "\n",
    "                \"In every iteration, choose from the following actions to improve the prompt. Aim for high recall, ensuring the prompt captures the maximum number of true positives.\"\n",
    "\n",
    "                \"The history contains the following information:\"\n",
    "                \"iteration: Number of iteration.\\n\"\n",
    "                \"prompt: The used <part_of_prompt_to_modify> optimized using the actions\\n\"\n",
    "                \"edit: The action used in the respective iteration.\\n\"\n",
    "                \"score: The recall score of the prompt, representing the number of true positives correctly identified.\\n\"\n",
    "                \"relative_improvement: The relative improvement in percent compared to the previous iteration.\\n\"\n",
    "                \"token_len: Token length of the prompt given to the classification LLM.\\n\"\n",
    "    \n",
    "                \"If an action does not lead to a higher score after two iterations, try a different action. If the score plateaus, return to a previous iteration by taking the respective action 'jump_back_to_iteration <number of iteration>'. Try different actions to gauge which leads to improved scores.\"\n",
    "                \"Select the most suitable action to enhance the prompt and achieve the highest recall score by iteration 20:\"\n",
    "                \"- shorten: Shortens the prompt by removing stopwords. The output does not change if used twice consecutively.\\n\"\n",
    "                \"- reword_prompt: Reword the <part_of_prompt_to_modify> using the 'PegasusTokenizer'.\\n\"\n",
    "                \"- to_bulletpoints: Formats the <part_of_prompt_to_modify> into bullet points. The output does not change if used twice consecutively.\\n\"\n",
    "                \"- add_positive_example: Include a positive example. A positive example is a clause that belongs to the same category and should be classified as 'yes'.\\n\"\n",
    "                \"- add_negative_example: Include a negative example. A negative example is a clause that belongs to a different category and should be classified as 'no'.\\n\"\n",
    "                \"- remove_positive_example: Remove one of the positive examples previously added with the add_positive_example action. A positive example is a clause that belongs to the same category and should be classified as 'yes'.\\n\"\n",
    "                \"- remove_negative_example: Remove one of the negative examples previously added with the add_negative_example action. A negative example is a clause that belongs to a different category and should be classified as 'no'.\\n\"\n",
    "                \"- jump_back_to_iteration: Revert to a previous iteration's <part_of_prompt_to_modify> and number of examples if earlier actions led to better performance. Format: 'jump_back_to_iteration <number>' because: <reasoning>'\\n\"\n",
    "                \n",
    "                \"Your output should be formatted as: <chosen_action> because: <reasoning>\"\n",
    "\n",
    "                #\"You are tasked with optimizing a prompt which is used to conduct a classification task with another LLM on a test set. The classification task is to classify legal clauses either fair or unfair clauses of different legal unfairness categories by doing it via one vs. all classification. An unfair clause is either in a specific unfairness category or not (fair or another unfairness category).\" \n",
    "                #\"The classification result using the prompt is scored on a scale of 0 - 100 (F1 Score times 100). Your goal is to find the best prompt and get a score as high as possible.\"\n",
    "                #f\"The optimization process is done within {num_iterations} iterations the final iteration is expected to provide the optimal prompt. In every iteration, you can choose from a list of possible actions to alter the <part_of_prompt_to_modify>. Please make sure you achieve an optimal prompt until iteration {num_iterations}. This is iteration {iteration + 1}. \\n \"\n",
    "                #\"The optimized prompt will be later used on another bigger unseen test set to test generalized performance.\"\n",
    "                #\"This is the structure of the full prompt given to the classification LLM: <intro><current_clause><legal_description><examples><part_of_prompt_to_modify> \"\n",
    "                #\"In the following, the single parts of the full prompt are described:\"\n",
    "                #f\"<intro> is: {intro} \\n\"\n",
    "                #\"<current_clause> is the variable clause to be classified.\\n\"\n",
    "                #\"<legal_description> is a question helping to classify clauses and is the same for all clauses per unfairness category.\\n\"\n",
    "                #\"<examples> is optional this is an example clause representing either a positive or negative clause. It is possible that both negative and positive are present.\\n\"\n",
    "                #f\"<part_of_prompt_to_modify> is {part_of_prompt_to_modify}, only modify this part \\n\"\n",
    "                #\"Your optimization should consider how the classification performance is measured: The output of the classification LLM is classified positive if the output starts with 'yes' and negative if the output starts with 'no', so only the first word will be considered when determining true / false positives / negatives.\\n\"\n",
    "                #\"To optimize the prompt, you can use various actions. \"\n",
    "                #f\"This is the history of all conducted operations until now: {optimization_history}\\n\"\n",
    "                #\"The history contains the following information: \\n\" \n",
    "                #\"iteration: Number of iteration.\\n\"\n",
    "                #\"prompt: The used <part_of_prompt_to_modify> which is the part of the prompt which you can optimize using the actions.\\n\"\n",
    "                #\"edit: The action that is used in the respective iteration.\\n\"\n",
    "                #\"score: The achieved score of the prompt which was edited using the respective action.\\n\"\n",
    "                #\"relative_improvement: The relative improvement in percent compared to the previous iteration.\\n\"\n",
    "                #\"token_len: token length of the prompt given to the classification LLM.\\n\"\n",
    "                #\"If an action did not lead to a higher score after two iterations, try a different action. \"\n",
    "                #\"If you find that the score plateaus, it is always possible to return to a previous iteration by taking the respective action 'jump_back_to_iteration <number of iteration>'. \"\n",
    "                #\"Try different actions to get a feeling which leads to a improving scores. \\n\"\n",
    "                #f\"These are the actions you can choose from - use the most suitable action to further improve the prompt and achieve the highest score by iteration {num_iterations}:\\n\"\n",
    "                #\"- shorten: Shortens the prompt by removing stopwords from the prompt. The output does not change if used twice in a row.\\n\"\n",
    "                #\"- reword_prompt: Reword the <part_of_prompt_to_modify> using the 'PegasusTokenizer'.\\n\"\n",
    "                #\"- to_bulletpoints: Formates the <part_of_prompt_to_modify> into bullet points. The output does not change if used twice in a row.\\n\"\n",
    "                #\"- add_positive_example: Include a positive example. A positive example is a clause that belongs to the same category and should be classified as true (a category of several unfairness categories).\\n\"\n",
    "                #\"- add_negative_example: Include a negative example. A negative example is a clause that belongs to a different category and should be classified as false (a category of several unfairness categories).\\n\"\n",
    "                #\"- remove_positive_example: Remove one of the positive examples previously added with the add_positive_example action.  A positive example is a clause that belongs to the same category and should be classified as true (a category of several unfairness categories).\\n\"\n",
    "                #\"- remove_negative_example: Remove one of the negative examples previously added with the add_negative_example action. A negative example is a clause that belongs to a different category and should be classified as false (a category of several unfairness categories).\\n\"\n",
    "                #\"- jump_back_to_iteration: Jump back to the <part_of_prompt_to_modify> and number of positive and negative examples of any previous iteration. If you realize previous actions led to a decrease in performance, you can always return to an iteration step that has been more promising. If you choose this action, your output should be of form: jump_back_to_iteration <number> because: <reasoning>'.\\n\"\n",
    "                    \n",
    "                #\"Your output should be of form: <chosen_action> because: <reasoning>\"\n",
    "            )\n",
    "\n",
    "        print(f\"\\nThis is iteration {iteration + 1}\")\n",
    "        try:\n",
    "            # 2. Get LLM's Decision\n",
    "            message = HumanMessage(content=llm_prompt)\n",
    "            response = model.invoke([message])\n",
    "            print(f\"Complete response: {response}\")\n",
    "            chosen_action = response.content.lower().split()[0]\n",
    "            #print(\"Response: \" + response)\n",
    "            print(\"Chosen Action: \" + chosen_action)\n",
    "            print(\"Optimizing the current <part_of_prompt_to_modify>: \\n\\t\", part_of_prompt_to_modify)\n",
    "\n",
    "            #if iteration == 1:\n",
    "            #    chosen_action = \"jump_back_to_iteration\"\n",
    "            #    iteration_number = 0\n",
    "            \n",
    "            # 3. Apply Chosen Action\n",
    "            for i in range(2):\n",
    "                if chosen_action == \"shorten\":\n",
    "                    part_of_prompt_to_modify = shorten.shorten_prompt(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"add_positive_example\":\n",
    "                    examples.add_positive_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"add_negative_example\":\n",
    "                    examples.add_negative_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"remove_positive_example\":\n",
    "                    examples.remove_positive_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"remove_negative_example\":\n",
    "                    examples.remove_negative_example(part_of_prompt_to_modify,category)\n",
    "                    break            \n",
    "                elif chosen_action == \"reword_prompt\":\n",
    "                    part_of_prompt_to_modify = paraphrase.paraphrase_pegasus(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"to_bulletpoints\":\n",
    "                    part_of_prompt_to_modify = reformat.reformat(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"jump_back_to_iteration\":\n",
    "                    match = re.search(r'jump_back_to_iteration (\\d+)', response.content.lower())\n",
    "                    if match:\n",
    "                        iteration_number = int(match.group(1))\n",
    "                    print(chosen_action, iteration_number)\n",
    "                    part_of_prompt_to_modify = jump_iteration.jump_back_to_iteration(iteration_number, optimization_history, category)\n",
    "                    print(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                #elif chosen_action == \"grammar_adjustment\":\n",
    "                #    grammarAdjustment = GrammarAdjustment()\n",
    "                #    part_of_prompt_to_modify = grammarAdjustment.grammar_adjustment(current_prompt)\n",
    "                else:\n",
    "                    keywords = [\n",
    "                        \"shorten\", \n",
    "                        \"add_positive_example\", \n",
    "                        \"add_negative_example\", \n",
    "                        \"remove_positive_example\", \n",
    "                        \"remove_negative_example\", \n",
    "                        \"reword_prompt\",  \n",
    "                        \"to_bulletpoints\",\n",
    "                        \"jump_back_to_iteration\"\n",
    "                    ]\n",
    "                    pattern = r'jump_back_to_iteration (\\d+)'\n",
    "                    match = re.search(pattern, response.content.lower())\n",
    "                    if match:\n",
    "                        chosen_action=\"jump_back_to_iteration\"\n",
    "                    else:\n",
    "                        for keyword in keywords:\n",
    "                            if keyword in response.content.lower():\n",
    "                                chosen_action = keyword \n",
    "                                break\n",
    "                            else:\n",
    "                                chosen_action = \"\"\n",
    "                        if chosen_action == \"\":        \n",
    "                            raise ValueError(f\"Invalid action chosen by LLM: {chosen_action}\")\n",
    "                    print(f\"Invalid chosen action. New chosen action after error handling is: {chosen_action}\")\n",
    "\n",
    "            # 4. Score and Log (using self.optimization_history)\n",
    "            score_value, mean_token_len = score_prompt(intro, examples.added_examples['positive'], examples.added_examples['negative'], part_of_prompt_to_modify, initial_prompt, df_short, category, model, {'p':1, 'r':0, 'l':0}) # + legal description, df_test, category, intro \n",
    "            len_pos = len(examples.added_examples[\"positive\"])\n",
    "            len_neg = len(examples.added_examples[\"negative\"])\n",
    "            relative_improvment = str(((score_value/optimization_history[iteration]['score'])-1)*100) + '%'\n",
    "            optimization_history.append(\n",
    "                {\"iteration\": iteration + 1, \"prompt\": part_of_prompt_to_modify, \"edit\": chosen_action, \"positive_examples_count\": len_pos, \"negative_examples_count\": len_neg, \"score\": score_value, \"relative_improvement\": relative_improvment, \"token_len\": mean_token_len}  # Log 1-based iteration\n",
    "            )\n",
    "            \n",
    "            if score_value >= 100:\n",
    "                print(\"Early stopping: Recall has reached 100%\")\n",
    "                return optimization_history\n",
    "            \n",
    "            iteration += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error during optimization  {e}\")\n",
    "            print(\"Retrying the iteration...\")\n",
    "            #break\n",
    "\n",
    "    return optimization_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt_optimization_CH(intro:str, initial_prompt, df, df_short, model, num_iterations, category, examples):\n",
    "    \"\"\"Optimizes the prompt using an LLM to choose the best edit operation.\"\"\"\n",
    "    ##For this.. online: <current clause, > <Legal Description, > <Examples, >\n",
    "    #optimization_history =  [{'iteration': 1, \"prompt\": part_of_prompt_to_modify, \"score\": 80, \"edit\": \"paraphrase\"}]\n",
    "    print(\"\\n ################################\")\n",
    "    print(\"Optimizing for category: \", category)\n",
    "\n",
    "    optimization_history = []  # Initialize as an empty list attribute\n",
    "    part_of_prompt_to_modify = initial_prompt\n",
    "    iteration = 0\n",
    "    while iteration < num_iterations:\n",
    "    #for iteration in range(num_iterations):  # Iterate for the specified number of times\n",
    "        # 1. Construct LLM Prompt\n",
    "        if iteration == 0:\n",
    "            # Special prompt for the first iteration (no history)\n",
    "            len_pos = len(examples.added_examples[\"positive\"])\n",
    "            len_neg = len(examples.added_examples[\"negative\"])\n",
    "            score_value, _ = score_prompt(intro, examples.added_examples['positive'], examples.added_examples['negative'], part_of_prompt_to_modify, initial_prompt, df_short, category, model, {'p':1, 'r':0, 'l':0}) \n",
    "            optimization_history.append(\n",
    "                {\"iteration\": 0, \"prompt\": part_of_prompt_to_modify, \"edit\": \"inital - no edit\", \"positive_examples_count\": len_pos, \"negative_examples_count\": len_neg, \"score\": score_value}  # Log 1-based iteration\n",
    "            )\n",
    "    \n",
    "            llm_prompt = (\n",
    "                f\"You are tasked with optimizing a prompt used to conduct a classification task with another LLM. \" \n",
    "                \"The classification result using the prompt is scored on a scale of 0 - 100. Your goal is to find the best prompt and get a score as high as possible. \"\n",
    "                f\"The optimization process is done within {num_iterations} iterations the final iteration is expected to provide the optimal prompt. In every iteration, you can choose from a list of possible actions to alter the <part_of_prompt_to_modify>. Please make sure you achieve an optimal prompt until iteration {num_iterations}. This is iteration {iteration + 1}. \\n \"\n",
    "                \"This is the structure of the full prompt given to the classification LLM: <intro><current_clause><legal_description><examples><part_of_prompt_to_modify> \"\n",
    "                \"In the following, the single parts of the full prompt are described:\"\n",
    "                f\"<intro> is: {intro} \\n\"\n",
    "                \"<current_clause> is the variable clause to be classified.\\n\"\n",
    "                f\"<legal_description> is a question helping to classify clauses.\\n\"\n",
    "                \"<examples> is optional this is an example clause representing either a positive or negative clause. It is possible that both negative and positive are present.\\n\"\n",
    "                f\"<part_of_prompt_to_modify> is {part_of_prompt_to_modify}, only modify this part \\n\"\n",
    "                \"The output of the classification LLM is classified positive if the output starts with yes and negative if the output starts with no.\\n\"\n",
    "                \"To optimize the prompt, you can use various actions. \"\n",
    "                f\"This is the history of all conducted operations until now: {optimization_history}\\n\"\n",
    "                \"The history contains the following information: \\n\" \n",
    "                \"iteration: Number of iterations.\\n\"\n",
    "                \"prompt: The used <part_of_prompt_to_modify> so the optimized part of the prompt.\\n\"\n",
    "                \"edit: The action that is used in the regrading iteration.\\n\"\n",
    "                \"score: The achieved score of the prompt edited by the respective action.\\n\"\n",
    "                \"relative_improvement: The relative improvement in percent compared to the previous iteration.\\n\"\n",
    "                \"token_len: token length of the prompt given to the classification LLM.\\n\"\n",
    "                \"If an action did not lead to a higher score after two iterations, try a different action. \"\n",
    "                \"If you find that the score plateaus, it is always possible to return to a previous iteration by taking the respective action. \"\n",
    "                \"Try different actions to get a feeling which leads to a higher score. \\n\"\n",
    "                \" These are the actions you can choose from. Use the most suitable action to improve the prompt further :\\n\"\n",
    "                \"- action_1: Shortens the prompt by removing stopwords from the prompt. The output does not change if used twice in a row.\\n\"\n",
    "                \"- action_6: Reword the <part_of_prompt_to_modify>. \\n\"\n",
    "                \"- action_7: Formates the <part_of_prompt_to_modify> into bullet points. The output does not change if used twice in a row.\\n\"\n",
    "                \"- action_2: Include a positive example. A positive example is a clause that belongs to the same category and should be classified as true (a category of several unfairness categories).\\n\"\n",
    "                \"- action_3: Include a negative example. A negative example is a clause that belongs to a different category and should be classified as false (a category of several unfairness categories).\\n\"\n",
    "                \"- action_4: Remove one of the positive examples previously added with the add_positive_example action.  A positive example is a clause that belongs to the same category and should be classified as true (a category of several unfairness categories).\\n\"\n",
    "                \"- action_5: Remove one of the negative examples previously added with the add_negative_example action. A negative example is a clause that belongs to a different category and should be classified as false (a category of several unfairness categories).\\n\"\n",
    "                \"Your output should be of form: <chosen_action> because: <reasoning>\"\n",
    "            )\n",
    "        else:\n",
    "            # Prompt for subsequent iterations (with history)\n",
    "            llm_prompt = (\n",
    "                f\"You are tasked with optimizing a prompt used to conduct a classification task with another LLM. \" \n",
    "                \"The classification result using the prompt is scored on a scale of 0 - 100. Your goal is to find the best prompt and get a score as high as possible. \"\n",
    "                f\"The optimization process is done within {num_iterations} iterations the final iteration is expected to provide the optimal prompt. In every iteration, you can choose from a list of possible actions to alter the <part_of_prompt_to_modify>. Please make sure you achieve an optimal prompt until iteration {num_iterations}. This is iteration {iteration + 1}. \\n \"\n",
    "                \"This is the structure of the full prompt given to the classification LLM: <intro><current_clause><legal_description><examples><part_of_prompt_to_modify> \"\n",
    "                \"In the following, the single parts of the full prompt are described:\"\n",
    "                f\"<intro> is: {intro} \\n\"\n",
    "                \"<current_clause> is the variable clause to be classified.\\n\"\n",
    "                f\"<legal_description> is a question helping to classify clauses.\\n\"\n",
    "                \"<examples> is optional this is an example clause representing either a positive or negative clause. It is possible that both negative and positive are present.\\n\"\n",
    "                f\"<part_of_prompt_to_modify> is {part_of_prompt_to_modify}, only modify this part \\n\"\n",
    "                \"The output of the classification LLM is classified positive if the output starts with yes and negative if the output starts with no.\\n\"\n",
    "                \"To optimize the prompt, you can use various actions. \"\n",
    "                f\"This is the history of all conducted operations until now: {optimization_history}\\n\"\n",
    "                \"The history contains the following information: \\n\" \n",
    "                \"iteration: Number of iterations.\\n\"\n",
    "                \"prompt: The used <part_of_prompt_to_modify> so the optimized part of the prompt.\\n\"\n",
    "                \"edit: The action that is used in the regrading iteration.\\n\"\n",
    "                \"score: The achieved score of the prompt edited by the respective action.\\n\"\n",
    "                \"relative_improvement: The relative improvement in percent compared to the previous iteration.\\n\"\n",
    "                \"token_len: token length of the prompt given to the classification LLM.\\n\"\n",
    "                \"If an action did not lead to a higher score after two iterations, try a different action. \"\n",
    "                \"If you find that the score plateaus, it is always possible to return to a previous iteration by taking the respective action. \"\n",
    "                \"Try different actions to get a feeling which leads to a higher score. \\n\"\n",
    "                \" These are the actions you can choose from. Use the most suitable action to improve the prompt further :\\n\"\n",
    "                \"- action_1: Shortens the prompt by removing stopwords from the prompt. The output does not change if used twice in a row.\\n\"\n",
    "                \"- action_6: Reword the <part_of_prompt_to_modify>. \\n\"\n",
    "                \"- action_7: Formates the <part_of_prompt_to_modify> into bullet points. The output does not change if used twice in a row.\\n\"\n",
    "                \"- action_2: Include a positive example. A positive example is a clause that belongs to the same category and should be classified as true (a category of several unfairness categories).\\n\"\n",
    "                \"- action_3: Include a negative example. A negative example is a clause that belongs to a different category and should be classified as false (a category of several unfairness categories).\\n\"\n",
    "                \"- action_4: Remove one of the positive examples previously added with the add_positive_example action.  A positive example is a clause that belongs to the same category and should be classified as true (a category of several unfairness categories).\\n\"\n",
    "                \"- action_5: Remove one of the negative examples previously added with the add_negative_example action. A negative example is a clause that belongs to a different category and should be classified as false (a category of several unfairness categories).\\n\"\n",
    "                \"- action_8: Jump back to a previous iteration. If you realize previous actions led to a decrease in performance, you can always return to an iteration step that has been more promising. If you choose this action, your output should be of form: jump_back_to_iteration <number> because: <reasoning>'.\\n\"\n",
    "                    \n",
    "                #\"- grammar_adjustment: Fix any grammatical errors in the prompt.\\n\"\n",
    "                \"Your output should be of form: <chosen_action> because: <reasoning>\"\n",
    "            )\n",
    "\n",
    "        print(f\"\\nThis is iteration {iteration + 1}\")\n",
    "        try:\n",
    "            # 2. Get LLM's Decision\n",
    "            message = HumanMessage(content=llm_prompt)\n",
    "            response = model.invoke([message])\n",
    "            print(f\"Complete response: {response}\")\n",
    "            chosen_action = response.content.lower().split()[0]\n",
    "            #print(\"Response: \" + response)\n",
    "            print(\"Chosen Action: \" + chosen_action)\n",
    "\n",
    "            #if iteration == 1:\n",
    "            #    chosen_action = \"jump_back_to_iteration\"\n",
    "            #    iteration_number = 0\n",
    "            \n",
    "            # 3. Apply Chosen Action\n",
    "            for i in range(2):\n",
    "                if chosen_action == \"action_1\":\n",
    "                    part_of_prompt_to_modify = shorten.shorten_prompt(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"action_2\":\n",
    "                    examples.add_positive_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"action_3\":\n",
    "                    examples.add_negative_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"action_4\":\n",
    "                    examples.remove_positive_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"action_5\":\n",
    "                    examples.remove_negative_example(part_of_prompt_to_modify,category)\n",
    "                    break            \n",
    "                elif chosen_action == \"action_6\":\n",
    "                    part_of_prompt_to_modify = paraphrase.paraphrase_pegasus(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"action_7\":\n",
    "                    part_of_prompt_to_modify = reformat.reformat(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"action_8\":\n",
    "                    match = re.search(r'jump_back_to_iteration (\\d+)', response.content.lower())\n",
    "                    if match:\n",
    "                        iteration_number = int(match.group(1))\n",
    "                    print(chosen_action, iteration_number)\n",
    "                    part_of_prompt_to_modify = jump_iteration.jump_back_to_iteration(iteration_number, optimization_history, category)\n",
    "                    print(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                #elif chosen_action == \"grammar_adjustment\":\n",
    "                #    grammarAdjustment = GrammarAdjustment()\n",
    "                #    part_of_prompt_to_modify = grammarAdjustment.grammar_adjustment(current_prompt)\n",
    "                else:\n",
    "                    keywords = [\n",
    "                        \"action_1\", \n",
    "                        \"action_2\", \n",
    "                        \"action_3\", \n",
    "                        \"action_4\", \n",
    "                        \"action_5\", \n",
    "                        \"action_6\",  \n",
    "                        \"action_7\",\n",
    "                        \"action_8\"\n",
    "                    ]\n",
    "                    pattern = r'jump_back_to_iteration (\\d+)'\n",
    "                    match = re.search(pattern, response.content.lower())\n",
    "                    if match:\n",
    "                        chosen_action=\"jump_back_to_iteration\"\n",
    "                    else:\n",
    "                        for keyword in keywords:\n",
    "                            if keyword in response.content.lower():\n",
    "                                chosen_action = keyword \n",
    "                                break\n",
    "                            else:\n",
    "                                chosen_action = \"\"\n",
    "                        if chosen_action == \"\":        \n",
    "                            raise ValueError(f\"Invalid action chosen by LLM: {chosen_action}\")\n",
    "                    print(f\"Invalid chosen action. New chosen action after error handling is: {chosen_action}\")\n",
    "\n",
    "            # 4. Score and Log (using self.optimization_history)\n",
    "            score_value, mean_token_len = score_prompt(intro, examples.added_examples['positive'], examples.added_examples['negative'], part_of_prompt_to_modify, initial_prompt, df_short, category, model, {'p':1, 'r':0, 'l':0}) # + legal description, df_test, category, intro \n",
    "            len_pos = len(examples.added_examples[\"positive\"])\n",
    "            len_neg = len(examples.added_examples[\"negative\"])\n",
    "            relative_improvment = str(((score_value/optimization_history[iteration]['score'])-1)*100) + '%'\n",
    "            optimization_history.append(\n",
    "                {\"iteration\": iteration + 1, \"prompt\": part_of_prompt_to_modify, \"edit\": chosen_action, \"positive_examples_count\": len_pos, \"negative_examples_count\": len_neg, \"score\": score_value, \"relative_improvement\": relative_improvment, \"token_len\": mean_token_len}  # Log 1-based iteration\n",
    "            )\n",
    "            iteration += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error during optimization  {e}\")\n",
    "            print(\"Retrying the iteration...\")\n",
    "            #break\n",
    "\n",
    "    return optimization_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt_optimization(intro:str, initial_prompt, df, df_short, model, num_iterations, category, examples):\n",
    "    \"\"\"Optimizes the prompt using an LLM to choose the best edit operation.\"\"\"\n",
    "    ##For this.. online: <current clause, > <Legal Description, > <Examples, >\n",
    "    #optimization_history =  [{'iteration': 1, \"prompt\": part_of_prompt_to_modify, \"score\": 80, \"edit\": \"paraphrase\"}]\n",
    "    print(\"\\n ################################\")\n",
    "    print(\"Optimizing for category: \", category)\n",
    "\n",
    "    optimization_history = []  # Initialize as an empty list attribute\n",
    "    part_of_prompt_to_modify = initial_prompt\n",
    "    iteration = 0\n",
    "    while iteration < num_iterations:\n",
    "    #for iteration in range(num_iterations):  # Iterate for the specified number of times\n",
    "        # 1. Construct LLM Prompt\n",
    "        if iteration == 0:\n",
    "            # Special prompt for the first iteration (no history)\n",
    "            len_pos = len(examples.added_examples[\"positive\"])\n",
    "            len_neg = len(examples.added_examples[\"negative\"])\n",
    "            score_value, _ = score_prompt(intro, examples.added_examples['positive'], examples.added_examples['negative'], part_of_prompt_to_modify, initial_prompt, df_short, category, model, {'p':1, 'r':0, 'l':0}) \n",
    "            optimization_history.append(\n",
    "                {\"iteration\": 0, \"prompt\": part_of_prompt_to_modify, \"edit\": \"inital - no edit\", \"positive_examples_count\": len_pos, \"negative_examples_count\": len_neg, \"score\": score_value}  # Log 1-based iteration\n",
    "            )\n",
    "    \n",
    "            llm_prompt = (\n",
    "                f\"You are tasked with optimizing a prompt. This is the inital iteration (iteration 0).\\n\" \n",
    "                \"The prompt is scored in a scale of 0 - 100. Your goal is to get a score that is high as possible.\"\n",
    "                \"Full Prompt: <intro><current_clause><legal_description><examples><part_of_prompt_to_modify>\"\n",
    "                f\"<intro> is: {intro}\"\n",
    "                \"<current_clause> is the variable clause to be classified.\"\n",
    "                f\"<legal_description> is: Question helping to classify clauses\"\n",
    "                \"<examples> is: optional, example clauses that are either positive or negative to the classification\"\n",
    "                f\"<part_of_prompt_to_modify> is {part_of_prompt_to_modify}, you will only modify this part\\n\\n\"\n",
    "                f\"Your starting point: {optimization_history}\\n\\n\"\n",
    "                \"To optimize the prompt you can use various actions. These actions alter the prompt.\"\n",
    "                #\"To optimize the prompt you can only use one action. \"\n",
    "                \"Choose the most suitable action to improve the prompt:\\n\"\n",
    "                \"- shorten: Shortens the prompt by removing stopwords from the prompt.\\n\"\n",
    "                \"- add_positive_example: Include a positive example.\\n\"\n",
    "                \"- add_negative_example: Include a negative example.\\n\"\n",
    "                \"- reword_prompt: Reword the <part_of_prompt_to_modify>.\\n\"\n",
    "                \"- to_bulletpoints: Formates the <part_of_prompt_to_modify> into bullet points. The output does not change if used twice in a row.\\n\"\n",
    "                #\"- grammar_adjustment: Fix any grammatical errors in the prompt.\\n\"\n",
    "                #\"- jump_back_to_iteration: Jump back to a specific iteration. Use the format 'jump_back_to_iteration <number> because: <reasoning>'.\\n\"\n",
    "                \"Your output should be of form: <chosen_action> because: <reasoning>\"\n",
    "            )\n",
    "        else:\n",
    "            # Prompt for subsequent iterations (with history)\n",
    "            llm_prompt = (\n",
    "                f\"You are tasked with optimizing a prompt used to conduct a classification task with another LLM. \" \n",
    "                \"The classification result using the prompt is scored on a scale of 0 - 100. Your goal is to find the best prompt and get a score as high as possible. \"\n",
    "                f\"The optimization process is done within {num_iterations} iterations the final iteration is expected to provide the optimal prompt. In every iteration, you can choose from a list of possible actions to alter the <part_of_prompt_to_modify>. Please make sure you achieve an optimal prompt until iteration {num_iterations}. This is iteration {iteration + 1}. \\n \"\n",
    "                \"This is the structure of the full prompt given to the classification LLM: <intro><current_clause><legal_description><examples><part_of_prompt_to_modify> \"\n",
    "                \"In the following, the single parts of the full prompt are described:\"\n",
    "                f\"<intro> is: {intro} \\n\"\n",
    "                \"<current_clause> is the variable clause to be classified.\\n\"\n",
    "                f\"<legal_description> is a question helping to classify clauses.\\n\"\n",
    "                \"<examples> is optional this is an example clause representing either a positive or negative clause. It is possible that both negative and positive are present.\\n\"\n",
    "                f\"<part_of_prompt_to_modify> is {part_of_prompt_to_modify}, only modify this part \\n\"\n",
    "                \"The output of the classification LLM is classified positive if the output starts with yes and negative if the output starts with no.\\n\"\n",
    "                \"To optimize the prompt, you can use various actions. \"\n",
    "                f\"This is the history of all conducted operations until now: {optimization_history}\\n\"\n",
    "                \"The history contains the following information: \\n\" \n",
    "                \"iteration: Number of iterations.\\n\"\n",
    "                \"prompt: The used <part_of_prompt_to_modify> so the optimized part of the prompt.\\n\"\n",
    "                \"edit: The action that is used in the regrading iteration.\\n\"\n",
    "                \"score: The achieved score of the prompt edited by the respective action.\\n\"\n",
    "                \"relative_improvement: The relative improvement in percent compared to the previous iteration.\\n\"\n",
    "                \"token_len: token length of the prompt given to the classification LLM.\\n\"\n",
    "                \"If an action did not lead to a higher score after two iterations, try a different action. \"\n",
    "                \"If you find that the score plateaus, it is always possible to return to a previous iteration by taking the respective action. \"\n",
    "                \"Try different actions to get a feeling which leads to a higher score. \\n\"\n",
    "                \" These are the actions you can choose from. Use the most suitable action to improve the prompt further :\\n\"\n",
    "                \"- shorten: Shortens the prompt by removing stopwords from the prompt. The output does not change if used twice in a row.\\n\"\n",
    "                \"- reword_prompt: Reword the <part_of_prompt_to_modify>. \\n\"\n",
    "                \"- to_bulletpoints: Formates the <part_of_prompt_to_modify> into bullet points. The output does not change if used twice in a row.\\n\"\n",
    "                \"- add_positive_example: Include a positive example. A positive example is a clause that belongs to the same category and should be classified as true (a category of several unfairness categories).\\n\"\n",
    "                \"- add_negative_example: Include a negative example. A negative example is a clause that belongs to a different category and should be classified as false (a category of several unfairness categories).\\n\"\n",
    "                \"- remove_positive_example: Remove one of the positive examples previously added with the add_positive_example action.  A positive example is a clause that belongs to the same category and should be classified as true (a category of several unfairness categories).\\n\"\n",
    "                \"- remove_negative_example: Remove one of the negative examples previously added with the add_negative_example action. A negative example is a clause that belongs to a different category and should be classified as false (a category of several unfairness categories).\\n\"\n",
    "                \"- jump_back_to_iteration: Jump back to a previous iteration. If you realize previous actions led to a decrease in performance, you can always return to an iteration step that has been more promising. If you choose this action, your output should be of form: jump_back_to_iteration <number> because: <reasoning>'.\\n\"\n",
    "                \n",
    "                #\"- grammar_adjustment: Fix any grammatical errors in the prompt.\\n\"\n",
    "                \"Your output should be of form: <chosen_action> because: <reasoning>\"\n",
    "            )\n",
    "\n",
    "        print(f\"\\nThis is iteration {iteration + 1}\")\n",
    "        try:\n",
    "            # 2. Get LLM's Decision\n",
    "            message = HumanMessage(content=llm_prompt)\n",
    "            response = model.invoke([message])\n",
    "            print(f\"Complete response: {response}\")\n",
    "            chosen_action = response.content.lower().split()[0]\n",
    "            #print(\"Response: \" + response)\n",
    "            print(\"Chosen Action: \" + chosen_action)\n",
    "\n",
    "            #if iteration == 1:\n",
    "            #    chosen_action = \"jump_back_to_iteration\"\n",
    "            #    iteration_number = 0\n",
    "            \n",
    "            # 3. Apply Chosen Action\n",
    "            for i in range(2):\n",
    "                if chosen_action == \"shorten\":\n",
    "                    part_of_prompt_to_modify = shorten.shorten_prompt(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"add_positive_example\":\n",
    "                    examples.add_positive_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"add_negative_example\":\n",
    "                    examples.add_negative_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"remove_positive_example\":\n",
    "                    examples.remove_positive_example(part_of_prompt_to_modify,category)\n",
    "                    break\n",
    "                elif chosen_action == \"remove_negative_example\":\n",
    "                    examples.remove_negative_example(part_of_prompt_to_modify,category)\n",
    "                    break            \n",
    "                elif chosen_action == \"reword_prompt\":\n",
    "                    part_of_prompt_to_modify = paraphrase.paraphrase_pegasus(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"to_bulletpoints\":\n",
    "                    part_of_prompt_to_modify = reformat.reformat(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                elif chosen_action == \"jump_back_to_iteration\":\n",
    "                    match = re.search(r'jump_back_to_iteration (\\d+)', response.content.lower())\n",
    "                    if match:\n",
    "                        iteration_number = int(match.group(1))\n",
    "                    print(chosen_action, iteration_number)\n",
    "                    part_of_prompt_to_modify = jump_iteration.jump_back_to_iteration(iteration_number, optimization_history, category)\n",
    "                    print(part_of_prompt_to_modify)\n",
    "                    break\n",
    "                #elif chosen_action == \"grammar_adjustment\":\n",
    "                #    grammarAdjustment = GrammarAdjustment()\n",
    "                #    part_of_prompt_to_modify = grammarAdjustment.grammar_adjustment(current_prompt)\n",
    "                else:\n",
    "                    keywords = [\n",
    "                        \"shorten\", \n",
    "                        \"add_positive_example\", \n",
    "                        \"add_negative_example\", \n",
    "                        \"remove_positive_example\", \n",
    "                        \"remove_negative_example\", \n",
    "                        \"reword_prompt\",  \n",
    "                        \"to_bulletpoints\",\n",
    "                        \"jump_back_to_iteration\"\n",
    "                    ]\n",
    "                    pattern = r'jump_back_to_iteration (\\d+)'\n",
    "                    match = re.search(pattern, response.content.lower())\n",
    "                    if match:\n",
    "                        chosen_action=\"jump_back_to_iteration\"\n",
    "                    else:\n",
    "                        for keyword in keywords:\n",
    "                            if keyword in response.content.lower():\n",
    "                                chosen_action = keyword \n",
    "                                break\n",
    "                            else:\n",
    "                                chosen_action = \"\"\n",
    "                        if chosen_action == \"\":        \n",
    "                            raise ValueError(f\"Invalid action chosen by LLM: {chosen_action}\")\n",
    "                    print(f\"Invalid chosen action. New chosen action after error handling is: {chosen_action}\")\n",
    "\n",
    "            # 4. Score and Log (using self.optimization_history)\n",
    "            score_value, mean_token_len = score_prompt(intro, examples.added_examples['positive'], examples.added_examples['negative'], part_of_prompt_to_modify, initial_prompt, df_short, category, model, {'p':1, 'r':0, 'l':0}) # + legal description, df_test, category, intro \n",
    "            len_pos = len(examples.added_examples[\"positive\"])\n",
    "            len_neg = len(examples.added_examples[\"negative\"])\n",
    "            relative_improvment = str(((score_value/optimization_history[iteration]['score'])-1)*100) + '%'\n",
    "            optimization_history.append(\n",
    "                {\"iteration\": iteration + 1, \"prompt\": part_of_prompt_to_modify, \"edit\": chosen_action, \"positive_examples_count\": len_pos, \"negative_examples_count\": len_neg, \"score\": score_value, \"relative_improvement\": relative_improvment, \"token_len\": mean_token_len}  # Log 1-based iteration\n",
    "            )\n",
    "            iteration += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error during optimization  {e}\")\n",
    "            print(\"Retrying the iteration...\")\n",
    "            #break\n",
    "\n",
    "    return optimization_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "++++++++++++++ This is RUN 5 of volatility analysis ++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " ################################\n",
      "Optimizing for category:  CH\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 1\n",
      "Complete response: content='reword_prompt because: The initial prompt is quite direct and concise, but rewording it could make it clearer and more specific, which might improve the score.' response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 368, 'total_tokens': 402, 'completion_time': 0.103732485, 'prompt_time': 0.040918781, 'queue_time': None, 'total_time': 0.144651266}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-9f79bf61-3fae-4c4c-b712-50c82f660734-0' usage_metadata={'input_tokens': 368, 'output_tokens': 34, 'total_tokens': 402}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 13.333333333333334\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 2\n",
      "Complete response: content=\"reword_prompt because: The previous rewording action led to a 20% relative improvement, and it's likely that further rewording can continue to improve the prompt. Additionally, rewording can help to clarify the instructions and make them more concise, which can lead to better performance from the classification LLM.\" response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 993, 'total_tokens': 1059, 'completion_time': 0.208138334, 'prompt_time': 0.218555848, 'queue_time': None, 'total_time': 0.426694182}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-2e8625f3-4c03-4933-a063-80d9b84bc9f0-0' usage_metadata={'input_tokens': 993, 'output_tokens': 66, 'total_tokens': 1059}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start your answer with \"yes\" or \"no\", you can justify your response in no more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 3\n",
      "Complete response: content=\"reword_prompt because: The previous rewording action in iteration 2 led to a decrease in score, so I want to try another rewording to see if it can improve the prompt. Additionally, the score is still relatively low, and rewording the prompt has shown some improvement in the past, so it's worth trying again.\" response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 1089, 'total_tokens': 1160, 'completion_time': 0.221221271, 'prompt_time': 0.093694683, 'queue_time': None, 'total_time': 0.314915954}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-3bd87416-2834-487a-b419-2eda865f3447-0' usage_metadata={'input_tokens': 1089, 'output_tokens': 71, 'total_tokens': 1160}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You can justify your response with no more than 50 words if you start with \"yes\" or \"no\". \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.76470588235294\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 4\n",
      "Complete response: content=\"reword_prompt because: The previous rewording actions have led to improvements in the score, and it's worth trying another rewording to see if it can further improve the prompt. Additionally, the current score is still relatively low, and rewording the prompt may help to clarify the instructions and improve the classification performance.\" response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 1185, 'total_tokens': 1252, 'completion_time': 0.23581503, 'prompt_time': 0.106836245, 'queue_time': None, 'total_time': 0.34265127500000003}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-d8e93fb6-b6af-4422-9797-96499245ec70-0' usage_metadata={'input_tokens': 1185, 'output_tokens': 67, 'total_tokens': 1252}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start with \"yes\" or \"no\", you can justify your response with 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.76470588235294\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 5\n",
      "Complete response: content='reword_prompt because: The previous rewording actions have led to slight improvements in the score, and I want to explore more variations of the prompt to see if it can lead to a higher score. Additionally, the current score has plateaued, and rewording the prompt might help to break through this plateau.' response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 1278, 'total_tokens': 1343, 'completion_time': 0.204358549, 'prompt_time': 0.09810028, 'queue_time': None, 'total_time': 0.302458829}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-379cf6b7-71f1-4de7-91c1-77841ce76b66-0' usage_metadata={'input_tokens': 1278, 'output_tokens': 65, 'total_tokens': 1343}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You can justify your response with 50 words or less if you start with \"yes\" or \"no\". \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.76470588235294\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 6\n",
      "Complete response: content=\"reword_prompt because: The previous iterations have shown that rewording the prompt can lead to improvements in the score, and we haven't tried a new rewording in the last two iterations. Additionally, the score has plateaued, and rewording might help to break this plateau.\" response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 1371, 'total_tokens': 1431, 'completion_time': 0.210678975, 'prompt_time': 0.175889668, 'queue_time': None, 'total_time': 0.386568643}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-ae256b67-d5a2-4d26-906a-cc2cb707a502-0' usage_metadata={'input_tokens': 1371, 'output_tokens': 60, 'total_tokens': 1431}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start with \"yes\" or \"no\", you can justify your response with 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.76470588235294\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 7\n",
      "Complete response: content='add_positive_example because: The current prompt has not included any examples, and adding a positive example can help the classification LLM better understand the context and improve the classification accuracy. Additionally, the score has been plateauing for the past few iterations, and introducing a positive example can provide a new perspective and potentially break the plateau.' response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 1464, 'total_tokens': 1530, 'completion_time': 0.228598397, 'prompt_time': 0.189160613, 'queue_time': None, 'total_time': 0.41775901000000004}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-2adc6a8a-8175-4569-8dfd-dd087d0f927a-0' usage_metadata={'input_tokens': 1464, 'output_tokens': 66, 'total_tokens': 1530}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 12.5\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 8\n",
      "Complete response: content='add_negative_example because: The current prompt has only one positive example, and adding a negative example can help the classification LLM to better distinguish between positive and negative clauses. This can lead to a more accurate classification and a higher score.' response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 1553, 'total_tokens': 1601, 'completion_time': 0.149590128, 'prompt_time': 0.118489535, 'queue_time': None, 'total_time': 0.26807966299999997}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-0f7a10e6-5370-4985-bf55-b6d10e01ddf9-0' usage_metadata={'input_tokens': 1553, 'output_tokens': 48, 'total_tokens': 1601}\n",
      "Chosen Action: add_negative_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 15.384615384615385\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 9\n",
      "Complete response: content=\"reword_prompt because: The previous iteration's score improved significantly after adding a negative example, and rewording the prompt might help to further clarify the instructions and potentially increase the score. Additionally, rewording the prompt has shown to be effective in previous iterations, and it's worth trying again to see if it can lead to further improvement.\" response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 1650, 'total_tokens': 1720, 'completion_time': 0.221202313, 'prompt_time': 0.120074936, 'queue_time': None, 'total_time': 0.341277249}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-b6762025-0925-45e9-84da-20fbf0499e6f-0' usage_metadata={'input_tokens': 1650, 'output_tokens': 70, 'total_tokens': 1720}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start with \"yes\" or \"no\", you can justify your response with 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 15.384615384615385\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 10\n",
      "Complete response: content=\"reword_prompt because: The previous iteration's score did not improve, and rewording the prompt has shown to be a effective action in the past (iterations 1, 3, and 5). It's possible that a slight rewording can help the classification LLM better understand the prompt and improve the score.\" response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 1743, 'total_tokens': 1810, 'completion_time': 0.224021343, 'prompt_time': 0.152206166, 'queue_time': None, 'total_time': 0.376227509}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-ec61d466-e042-47c0-b550-10066ad0e095-0' usage_metadata={'input_tokens': 1743, 'output_tokens': 67, 'total_tokens': 1810}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You can justify your response with 50 words or less if you start with \"yes\" or \"no\". \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 15.384615384615385\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 11\n",
      "Complete response: content='add_positive_example because: The score has plateaued in the last few iterations, and adding a positive example might help the model to better understand the context and improve the classification accuracy. Additionally, the number of positive examples is currently only 1, which might not be sufficient to provide a clear understanding of the category.' response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 1836, 'total_tokens': 1900, 'completion_time': 0.203909893, 'prompt_time': 0.157964916, 'queue_time': None, 'total_time': 0.361874809}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-4ab48b77-2949-4fbb-b04a-13e1e29b2e78-0' usage_metadata={'input_tokens': 1836, 'output_tokens': 64, 'total_tokens': 1900}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 15.384615384615385\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 12\n",
      "Complete response: content='add_positive_example because: The score has plateaued in the last few iterations, and adding a positive example might help the model to better understand the context and improve the classification accuracy. Additionally, the number of positive examples is still relatively low compared to the number of iterations, so adding another one might be beneficial.' response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 1929, 'total_tokens': 1992, 'completion_time': 0.198302396, 'prompt_time': 0.249532277, 'queue_time': None, 'total_time': 0.447834673}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-e0ed47e2-31b4-4a53-807d-f3665eeaebd5-0' usage_metadata={'input_tokens': 1929, 'output_tokens': 63, 'total_tokens': 1992}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 16.666666666666664\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 13\n",
      "Complete response: content='add_positive_example because: The score has been improving with the addition of positive examples, and I want to continue this trend to see if it leads to further improvement.' response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 2026, 'total_tokens': 2060, 'completion_time': 0.105275608, 'prompt_time': 0.173919621, 'queue_time': None, 'total_time': 0.279195229}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-243c52d4-c7a1-469a-affc-0664e2ae574c-0' usage_metadata={'input_tokens': 2026, 'output_tokens': 34, 'total_tokens': 2060}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 20.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 14\n",
      "Complete response: content=\"add_positive_example because: The score has been increasing with the addition of positive examples, and it's likely that adding another positive example will continue to improve the performance of the prompt.\" response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 2119, 'total_tokens': 2156, 'completion_time': 0.115587637, 'prompt_time': 0.336269173, 'queue_time': None, 'total_time': 0.45185681}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-2dcd9718-6021-46e9-aaef-59f8565284bf-0' usage_metadata={'input_tokens': 2119, 'output_tokens': 37, 'total_tokens': 2156}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 20.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 15\n",
      "Complete response: content='add_positive_example because: The score has been plateauing at 20.0 for the last two iterations, and adding more positive examples has been shown to improve the score in previous iterations.' response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 2208, 'total_tokens': 2247, 'completion_time': 0.12235211, 'prompt_time': 0.154730141, 'queue_time': None, 'total_time': 0.277082251}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-c7a66880-d196-4ad0-be5e-3b329460a3ea-0' usage_metadata={'input_tokens': 2208, 'output_tokens': 39, 'total_tokens': 2247}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 20.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 16\n",
      "Complete response: content='add_positive_example because: The score has plateaued at 20.0 for the last few iterations, and adding more positive examples has been a successful strategy in the past to improve the score.' response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 2297, 'total_tokens': 2337, 'completion_time': 0.127513402, 'prompt_time': 0.291540938, 'queue_time': None, 'total_time': 0.41905434}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-08c5c4a7-39ae-468b-abcf-cd93c0905bef-0' usage_metadata={'input_tokens': 2297, 'output_tokens': 40, 'total_tokens': 2337}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 20.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 17\n",
      "Complete response: content=\"reword_prompt because: The score has plateaued at 20.0 for the last 4 iterations, and rewording the prompt might help to break this plateau and improve the score further. Additionally, rewording the prompt has led to improvements in previous iterations, so it's worth trying again.\" response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 2386, 'total_tokens': 2449, 'completion_time': 0.219222239, 'prompt_time': 0.245154391, 'queue_time': None, 'total_time': 0.46437663}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-12ff573d-e1e7-4a7b-9ec2-9820b1f2639b-0' usage_metadata={'input_tokens': 2386, 'output_tokens': 63, 'total_tokens': 2449}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start with \"yes\" or \"no\", you can justify your response with 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 14.285714285714285\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 18\n",
      "Complete response: content=\"reword_prompt because: The current prompt has a relatively low score compared to previous iterations, and rewording the prompt might help to improve the clarity and coherence of the prompt, leading to a higher score. Additionally, rewording the prompt has been a successful action in previous iterations, and it's worth trying again to see if it can improve the score.\" response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 2483, 'total_tokens': 2557, 'completion_time': 0.229782978, 'prompt_time': 0.197328283, 'queue_time': None, 'total_time': 0.42711126099999996}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-28078415-eda6-4d87-a231-fec523da50c2-0' usage_metadata={'input_tokens': 2483, 'output_tokens': 74, 'total_tokens': 2557}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You can justify your response with 50 words or less if you start with \"yes\" or \"no\". \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 28.57142857142857\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 19\n",
      "Complete response: content=\"reword_prompt because: The previous iteration's score was significantly higher than the previous ones, and rewording the prompt might help to further improve the score. Additionally, rewording the prompt can help to clarify the instructions and make them more concise, which might lead to better performance.\" response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 2576, 'total_tokens': 2635, 'completion_time': 0.182281024, 'prompt_time': 0.306382967, 'queue_time': None, 'total_time': 0.488663991}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-3be8f646-6beb-419d-93ee-f6e697628024-0' usage_metadata={'input_tokens': 2576, 'output_tokens': 59, 'total_tokens': 2635}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start with \"yes\" or \"no\" you can justify your response in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 14.285714285714285\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 20\n",
      "Complete response: content='jump_back_to_iteration 18 because: The score in iteration 18 was the highest so far, and the rewording in iteration 19 led to a decrease in performance. I want to go back to the prompt that achieved the highest score and try a different action to further improve it.' response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 2669, 'total_tokens': 2729, 'completion_time': 0.196163589, 'prompt_time': 1.2095444, 'queue_time': None, 'total_time': 1.405707989}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-bcd1ef42-c8dd-4cf6-89fb-a9c0dd0000b6-0' usage_metadata={'input_tokens': 2669, 'output_tokens': 60, 'total_tokens': 2729}\n",
      "Chosen Action: jump_back_to_iteration\n",
      "jump_back_to_iteration 18\n",
      "Jumped back to the following 'part_of_prompt_to_modify':  If you start with \"yes\" or \"no\" you can justify your response in 50 words or less.\n",
      "If you start with \"yes\" or \"no\" you can justify your response in 50 words or less.\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 28.57142857142857\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "Total time of cat CH is 64 min and 21.00602912902832 sec.\n",
      "Positive example list: \n",
      " ['we may revise these terms from time to time without notice .', 'we may change , suspend or discontinue any aspect of shazam at any time , including the availability of any feature , database and / or content .', 'where we consider that any changes to wechat or any services or features accessible within wechat are reasonably material , we will -lrb- where reasonably practicable -rrb- notify you -lrb- via http://www.wechat.com , direct communication to you , on this page or the relevant page for the relevant additional terms or policy , or other means -rrb- , prior to such changes becoming effective .', 'where we consider that any changes to wechat or any services or features accessible within wechat are reasonably material , we will -lrb- where reasonably practicable -rrb- notify you -lrb- via http://www.wechat.com , direct communication to you , on this page or the relevant page for the relevant additional terms or policy , or other means -rrb- , prior to such changes becoming effective .', 'we will try to notify you of material revisions , for example via a service notification or an email to the email associated with your account .', 'uber may amend the terms related to the services from time to time .', 'we may amend or update these terms .']\n",
      "\n",
      "Negative example list: \n",
      " ['we are not responsible for any damage , loss of data , customer information or vendor data , revenue , or other harm to business arising out of delays , misdelivery or nondelivery of information , restriction or loss of access , bugs or other errors , unauthorized use due to your sharing of access to the service , or other interaction with the service .']\n",
      "\n",
      "\n",
      "\n",
      "{'CH': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111}, {'iteration': 1, 'prompt': 'If you start your answer with \"yes\" or \"no\", you can justify your response in no more than 50 words.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 13.333333333333334, 'relative_improvement': '20.000000000000018%', 'token_len': 552.9473684210526}, {'iteration': 2, 'prompt': 'You can justify your response with no more than 50 words if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '-16.666666666666675%', 'token_len': 549.9473684210526}, {'iteration': 3, 'prompt': 'If you start with \"yes\" or \"no\", you can justify your response with 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.76470588235294, 'relative_improvement': '5.882352941176472%', 'token_len': 549.9473684210526}, {'iteration': 4, 'prompt': 'You can justify your response with 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.76470588235294, 'relative_improvement': '0.0%', 'token_len': 548.9473684210526}, {'iteration': 5, 'prompt': 'If you start with \"yes\" or \"no\", you can justify your response with 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.76470588235294, 'relative_improvement': '0.0%', 'token_len': 549.9473684210526}, {'iteration': 6, 'prompt': 'If you start with \"yes\" or \"no\", you can justify your response with 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.76470588235294, 'relative_improvement': '0.0%', 'token_len': 549.9473684210526}, {'iteration': 7, 'prompt': 'If you start with \"yes\" or \"no\", you can justify your response with 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 12.5, 'relative_improvement': '6.25%', 'token_len': 574.9473684210526}, {'iteration': 8, 'prompt': 'If you start with \"yes\" or \"no\", you can justify your response with 50 words or less.', 'edit': 'add_negative_example', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 15.384615384615385, 'relative_improvement': '23.076923076923084%', 'token_len': 655.9473684210526}, {'iteration': 9, 'prompt': 'You can justify your response with 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 15.384615384615385, 'relative_improvement': '0.0%', 'token_len': 654.9473684210526}, {'iteration': 10, 'prompt': 'If you start with \"yes\" or \"no\", you can justify your response with 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 15.384615384615385, 'relative_improvement': '0.0%', 'token_len': 655.9473684210526}, {'iteration': 11, 'prompt': 'If you start with \"yes\" or \"no\", you can justify your response with 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 1, 'score': 15.384615384615385, 'relative_improvement': '0.0%', 'token_len': 686.9473684210526}, {'iteration': 12, 'prompt': 'If you start with \"yes\" or \"no\", you can justify your response with 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 16.666666666666664, 'relative_improvement': '8.333333333333325%', 'token_len': 756.9473684210526}, {'iteration': 13, 'prompt': 'If you start with \"yes\" or \"no\", you can justify your response with 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 20.0, 'relative_improvement': '20.000000000000018%', 'token_len': 826.9473684210526}, {'iteration': 14, 'prompt': 'If you start with \"yes\" or \"no\", you can justify your response with 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 5, 'negative_examples_count': 1, 'score': 20.0, 'relative_improvement': '0.0%', 'token_len': 856.9473684210526}, {'iteration': 15, 'prompt': 'If you start with \"yes\" or \"no\", you can justify your response with 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 6, 'negative_examples_count': 1, 'score': 20.0, 'relative_improvement': '0.0%', 'token_len': 873.9473684210526}, {'iteration': 16, 'prompt': 'If you start with \"yes\" or \"no\", you can justify your response with 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 7, 'negative_examples_count': 1, 'score': 20.0, 'relative_improvement': '0.0%', 'token_len': 884.9473684210526}, {'iteration': 17, 'prompt': 'You can justify your response with 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 7, 'negative_examples_count': 1, 'score': 14.285714285714285, 'relative_improvement': '-28.57142857142858%', 'token_len': 883.9473684210526}, {'iteration': 18, 'prompt': 'If you start with \"yes\" or \"no\" you can justify your response in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 7, 'negative_examples_count': 1, 'score': 28.57142857142857, 'relative_improvement': '100.0%', 'token_len': 883.9473684210526}, {'iteration': 19, 'prompt': 'You can justify your response in 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 7, 'negative_examples_count': 1, 'score': 14.285714285714285, 'relative_improvement': '-50.0%', 'token_len': 883.9473684210526}, {'iteration': 20, 'prompt': 'If you start with \"yes\" or \"no\" you can justify your response in 50 words or less.', 'edit': 'jump_back_to_iteration', 'positive_examples_count': 7, 'negative_examples_count': 1, 'score': 28.57142857142857, 'relative_improvement': '100.0%', 'token_len': 883.9473684210526}]}\n",
      "\n",
      "\n",
      "++++++++++++++ This is RUN 6 of volatility analysis ++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " ################################\n",
      "Optimizing for category:  CH\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 1\n",
      "Complete response: content='reword_prompt because: The initial prompt is quite direct and concise, but rewording it could make it clearer and more specific, which might improve the score.' response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 368, 'total_tokens': 402, 'completion_time': 0.117913729, 'prompt_time': 0.183616327, 'queue_time': None, 'total_time': 0.301530056}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-15875535-bc99-469c-b6e9-ec7a14a8bc6f-0' usage_metadata={'input_tokens': 368, 'output_tokens': 34, 'total_tokens': 402}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 2\n",
      "Complete response: content='reword_prompt because: The previous rewording action did not lead to a significant improvement in the score. I want to try another rewording to see if it can improve the prompt further.' response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 987, 'total_tokens': 1028, 'completion_time': 0.127104721, 'prompt_time': 0.10092854, 'queue_time': None, 'total_time': 0.228033261}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-acf5c85d-e492-4062-84e4-7e5d00bdd8c1-0' usage_metadata={'input_tokens': 987, 'output_tokens': 41, 'total_tokens': 1028}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You should start your answer with \"yes\" or \"no\" and then justify your answer in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 3\n",
      "Complete response: content='reword_prompt because: The score has not improved in the previous iterations, and rewording the prompt again might help to clarify the instructions and improve the classification performance. Additionally, rewording the prompt can help to avoid any potential biases or ambiguities in the current prompt.' response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 1080, 'total_tokens': 1137, 'completion_time': 0.177933017, 'prompt_time': 0.103781781, 'queue_time': None, 'total_time': 0.281714798}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-f23c0dd6-7033-49b5-ba40-db8811a56e69-0' usage_metadata={'input_tokens': 1080, 'output_tokens': 57, 'total_tokens': 1137}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start your answer with \"yes\" or \"no\", you should justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 4\n",
      "Complete response: content=\"reword_prompt because: The score has not improved in the previous iterations, and rewording the prompt might help to clarify the instructions and improve the classification performance. Additionally, rewording the prompt is a gentle modification that is less likely to drastically change the prompt's meaning, making it a safe choice at this stage.\" response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 1176, 'total_tokens': 1242, 'completion_time': 0.208677645, 'prompt_time': 0.142206348, 'queue_time': None, 'total_time': 0.350883993}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-eb33ef97-fcc4-4c3d-9e0c-d5111040b315-0' usage_metadata={'input_tokens': 1176, 'output_tokens': 66, 'total_tokens': 1242}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start your answer with \"yes\" or \"no\" you need to justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 5\n",
      "Complete response: content=\"reword_prompt because: The score has not improved in the previous iterations, and rewording the prompt might help to clarify the instructions and improve the classification performance. Additionally, rewording the prompt has been shown to be effective in previous iterations, and it's worth trying again to see if it can lead to a better score.\" response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 1271, 'total_tokens': 1339, 'completion_time': 0.241991448, 'prompt_time': 0.426009998, 'queue_time': None, 'total_time': 0.668001446}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-07b7e74a-bcaf-4c0e-a8d8-791d263cfc32-0' usage_metadata={'input_tokens': 1271, 'output_tokens': 68, 'total_tokens': 1339}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You need to justify your answer in 50 words or less if you start it with \"yes\" or \"no\". \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 6\n",
      "Complete response: content=\"reword_prompt because: The score has not improved in the previous iterations, and rewording the prompt might help to clarify the instructions and improve the classification performance. Additionally, rewording the prompt has been shown to be effective in previous iterations, and it's worth trying again to see if it can lead to a higher score.\" response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 1366, 'total_tokens': 1434, 'completion_time': 0.240779126, 'prompt_time': 0.425367167, 'queue_time': None, 'total_time': 0.666146293}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-5fd0ca07-1939-472e-8b58-bf72e721da38-0' usage_metadata={'input_tokens': 1366, 'output_tokens': 68, 'total_tokens': 1434}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start your answer with \"yes\" or \"no\", you need to justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 7\n",
      "Complete response: content='reword_prompt because: The score has not improved in the last 6 iterations, and the prompt has been reworded multiple times without significant changes. I want to try a different rewording to see if it can lead to a higher score.' response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 1461, 'total_tokens': 1513, 'completion_time': 0.181325246, 'prompt_time': 0.364192188, 'queue_time': None, 'total_time': 0.545517434}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-adf5aecb-2ddd-417b-ad5e-d5d8cfaa2035-0' usage_metadata={'input_tokens': 1461, 'output_tokens': 52, 'total_tokens': 1513}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You need to justify your answer in 50 words or less if you start it with \"yes\" or \"no\". \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 8\n",
      "Complete response: content=\"reword_prompt because: The score has been plateauing at 11.11111111111111 for the past 7 iterations, and rewording the prompt has been the most consistent action in terms of not decreasing the score. It's possible that rewording the prompt again could lead to a slight improvement in the score. Additionally, since the score has not improved in the past 7 iterations, it's worth trying a different rewording to see if it can break the plateau.\" response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 1556, 'total_tokens': 1657, 'completion_time': 0.35457745, 'prompt_time': 0.352280353, 'queue_time': None, 'total_time': 0.706857803}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-2b382529-24dc-47dc-95e5-7ab25b9ad4f9-0' usage_metadata={'input_tokens': 1556, 'output_tokens': 101, 'total_tokens': 1657}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start your answer with \"yes\" or \"no\", you need to justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 9\n",
      "Complete response: content=\"reword_prompt because: The score has been plateauing at 11.11111111111111 for all previous iterations, and rewording the prompt might help to break this plateau and improve the score. Additionally, rewording the prompt has been a successful action in previous iterations, so it's worth trying again.\" response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 1647, 'total_tokens': 1713, 'completion_time': 0.237193988, 'prompt_time': 0.415619113, 'queue_time': None, 'total_time': 0.652813101}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-ba43ad65-e769-4ad1-94de-5894c6b5b9ac-0' usage_metadata={'input_tokens': 1647, 'output_tokens': 66, 'total_tokens': 1713}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You need to justify it in 50 words or less if you start with \"yes\" or \"no\". \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.76470588235294\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 10\n",
      "Complete response: content=\"add_positive_example because: The current score is still relatively low, and adding a positive example might help the classification LLM to better understand the context and improve the classification accuracy. Additionally, no examples have been added so far, so it's a good opportunity to introduce one.\" response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1744, 'total_tokens': 1800, 'completion_time': 0.198042905, 'prompt_time': 0.362938779, 'queue_time': None, 'total_time': 0.5609816839999999}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-2434c578-3242-4d96-bf46-a83fb84d481a-0' usage_metadata={'input_tokens': 1744, 'output_tokens': 56, 'total_tokens': 1800}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 16.666666666666664\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 11\n",
      "Complete response: content='add_negative_example because: The score has improved significantly in the last iteration by adding a positive example, and I want to see if adding a negative example can further improve the score. Additionally, having both positive and negative examples can help the classification LLM to better understand the context and make more accurate classifications.' response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 1841, 'total_tokens': 1903, 'completion_time': 0.21751373, 'prompt_time': 0.483698669, 'queue_time': None, 'total_time': 0.701212399}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-3b0e1442-0145-4064-b305-08eb8b991bc9-0' usage_metadata={'input_tokens': 1841, 'output_tokens': 62, 'total_tokens': 1903}\n",
      "Chosen Action: add_negative_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 18.181818181818183\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 12\n",
      "Complete response: content=\"I choose `reword_prompt` because: The previous iterations have shown that rewording the prompt can lead to improvements in the score, and we haven't tried a significant rewording in the last few iterations. Additionally, the current prompt is quite similar to the one in iteration 9, which had a lower score, so rewording might help to break the plateau.\" response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 1938, 'total_tokens': 2016, 'completion_time': 0.27357887, 'prompt_time': 0.45707635, 'queue_time': None, 'total_time': 0.73065522}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-4686a6ef-5a03-4675-8b6b-d4d86ca50d57-0' usage_metadata={'input_tokens': 1938, 'output_tokens': 78, 'total_tokens': 2016}\n",
      "Chosen Action: i\n",
      "Invalid chosen action. New chosen action after error handling is: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start with \"yes\" or \"no\", you need to justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................Error during optimization  Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}\n",
      "Retrying the iteration...\n",
      "\n",
      "This is iteration 12\n",
      "Complete response: content=\"I choose `reword_prompt` because: The previous iterations have shown that rewording the prompt can lead to improvements in the score, and we haven't tried a new rewording in a while. Additionally, the current score is still relatively low, and rewording the prompt might help to clarify the instructions for the classification LLM.\" response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 1938, 'total_tokens': 2009, 'completion_time': 0.249217885, 'prompt_time': 1.340911508, 'queue_time': None, 'total_time': 1.590129393}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-52b006b4-973e-47b2-85a7-2450d0e0aac7-0' usage_metadata={'input_tokens': 1938, 'output_tokens': 71, 'total_tokens': 2009}\n",
      "Chosen Action: i\n",
      "Invalid chosen action. New chosen action after error handling is: reword_prompt\n",
      "Starting to paraphrase the following prompt: You need to justify it in 50 words or less if you start with \"yes\" or \"no\". \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 18.181818181818183\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 13\n",
      "Complete response: content=\"reword_prompt because: The previous iteration did not lead to an improvement in score, and rewording the prompt might help to clarify the instructions and improve the classification performance. Additionally, rewording the prompt has been a successful action in previous iterations, and it's worth trying again to see if it can lead to further improvement.\" response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 2031, 'total_tokens': 2099, 'completion_time': 0.242770421, 'prompt_time': 0.512110896, 'queue_time': None, 'total_time': 0.754881317}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-ffa36ff6-a972-4016-a3ba-e8e7eac884d8-0' usage_metadata={'input_tokens': 2031, 'output_tokens': 68, 'total_tokens': 2099}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start with \"yes\" or \"no\", you need to justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 13.333333333333334\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 14\n",
      "Complete response: content=\"reword_prompt because: The score has decreased in the last iteration, and rewording the prompt might help to improve the clarity and coherence of the prompt, which could lead to a better score. Additionally, rewording the prompt has been a successful action in previous iterations, and it's worth trying again to see if it can improve the score.\" response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 2128, 'total_tokens': 2200, 'completion_time': 0.25418301, 'prompt_time': 0.511249442, 'queue_time': None, 'total_time': 0.765432452}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-0aa8ce61-24a1-422f-9acd-c72b236b48fc-0' usage_metadata={'input_tokens': 2128, 'output_tokens': 72, 'total_tokens': 2200}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You need to justify it in 50 words or less if you start with \"yes\" or \"no\". \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      ".......Error during optimization  Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}\n",
      "Retrying the iteration...\n",
      "\n",
      "This is iteration 14\n",
      "Complete response: content=\"reword_prompt because: The previous iteration's score decreased, and rewording the prompt might help to improve the score. Additionally, rewording the prompt has been a successful action in the past, and it's worth trying again to see if it can lead to a higher score.\" response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 2128, 'total_tokens': 2187, 'completion_time': 0.208692941, 'prompt_time': 0.530626489, 'queue_time': None, 'total_time': 0.73931943}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-b7fed367-4470-4d03-afa3-04b7065cbc88-0' usage_metadata={'input_tokens': 2128, 'output_tokens': 59, 'total_tokens': 2187}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start with \"yes\" or \"no\", you need to justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "..Error during optimization  Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}\n",
      "Retrying the iteration...\n",
      "\n",
      "This is iteration 14\n",
      "Complete response: content=\"reword_prompt because: The previous iteration's score decreased, and rewording the prompt might help to improve the score. Additionally, rewording the prompt has been a successful action in the past, and it's worth trying again to see if it can lead to a higher score.\" response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 2128, 'total_tokens': 2187, 'completion_time': 0.209068329, 'prompt_time': 0.532761076, 'queue_time': None, 'total_time': 0.741829405}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-b84f465f-c8a1-4bec-94f9-6ff35f94c442-0' usage_metadata={'input_tokens': 2128, 'output_tokens': 59, 'total_tokens': 2187}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start with \"yes\" or \"no\", you need to justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 13.333333333333334\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 15\n",
      "Complete response: content='reword_prompt because: The current prompt has been reworded multiple times, but the score has not improved significantly. I want to try a different rewording to see if it can lead to a higher score.' response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 2221, 'total_tokens': 2266, 'completion_time': 0.159099279, 'prompt_time': 0.466559581, 'queue_time': None, 'total_time': 0.62565886}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-6b325a8f-54c2-40c5-9871-40a2af24f7aa-0' usage_metadata={'input_tokens': 2221, 'output_tokens': 45, 'total_tokens': 2266}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You need to justify it in 50 words or less if you start with \"yes\" or \"no\". \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      ".............Error during optimization  Error code: 500 - {'error': {'message': 'Internal Server Error', 'type': 'internal_server_error'}}\n",
      "Retrying the iteration...\n",
      "\n",
      "This is iteration 15\n",
      "Complete response: content=\"reword_prompt because: The current prompt has been reworded several times, but the score has not improved significantly. I want to try a different rewording to see if it can lead to a higher score. Additionally, the previous iteration's score was the same as the one before, so it's a good time to try a different approach.\" response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 2221, 'total_tokens': 2293, 'completion_time': 0.254685904, 'prompt_time': 0.563449858, 'queue_time': None, 'total_time': 0.818135762}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-5e9580da-8ca5-465c-8949-5ba8ff105a5e-0' usage_metadata={'input_tokens': 2221, 'output_tokens': 72, 'total_tokens': 2293}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start with \"yes\" or \"no\", you need to justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 13.333333333333334\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 16\n",
      "Complete response: content='reword_prompt because: The score has been plateauing for the last few iterations, and rewording the prompt might help to break this plateau and improve the score. Additionally, rewording the prompt has been a successful action in the past, leading to improvements in the score.' response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 2314, 'total_tokens': 2372, 'completion_time': 0.205973201, 'prompt_time': 0.606276912, 'queue_time': None, 'total_time': 0.8122501129999999}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-b178da9c-683b-4beb-b66d-a9e20568ae7d-0' usage_metadata={'input_tokens': 2314, 'output_tokens': 58, 'total_tokens': 2372}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You need to justify it in 50 words or less if you start with \"yes\" or \"no\". \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 18.181818181818183\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 17\n",
      "Complete response: content=\"reword_prompt because: The current score is 18.181818181818183, and I want to try rewording the prompt to see if it can improve the score further. The previous rewording attempts have shown some improvements, so I'll try it again to see if it can lead to a higher score.\" response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 2411, 'total_tokens': 2478, 'completion_time': 0.234950527, 'prompt_time': 0.851788981, 'queue_time': None, 'total_time': 1.086739508}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-d106b73e-7983-471f-8ad3-c1aa9b30e3e7-0' usage_metadata={'input_tokens': 2411, 'output_tokens': 67, 'total_tokens': 2478}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start with \"yes\" or \"no\", you need to justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 13.333333333333334\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 18\n",
      "Complete response: content=\"reword_prompt because: The current score is 13.333333333333334, which is lower than the previous iteration. I want to try rewording the prompt to see if it can improve the score. Additionally, rewording the prompt has led to improvements in previous iterations, so it's worth trying again.\" response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 2508, 'total_tokens': 2575, 'completion_time': 0.237210239, 'prompt_time': 1.4518667330000001, 'queue_time': None, 'total_time': 1.689076972}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-a0bd0dd1-d249-4b1d-975e-797001387ee2-0' usage_metadata={'input_tokens': 2508, 'output_tokens': 67, 'total_tokens': 2575}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You need to justify it in 50 words or less if you start with \"yes\" or \"no\". \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 18.181818181818183\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 19\n",
      "Complete response: content='reword_prompt because: The current score is 18.181818181818183, and I want to try rewording the prompt to see if it can improve the score further. The previous rewording attempts have shown some improvements, and I want to explore this direction further before considering other actions.' response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 2605, 'total_tokens': 2668, 'completion_time': 0.22020971, 'prompt_time': 0.234681472, 'queue_time': None, 'total_time': 0.454891182}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-5d924b8b-4c33-4497-ae1d-2f86ab280e0f-0' usage_metadata={'input_tokens': 2605, 'output_tokens': 63, 'total_tokens': 2668}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: If you start with \"yes\" or \"no\", you need to justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 13.333333333333334\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 20\n",
      "Complete response: content='jump_back_to_iteration 10 because: The score has been fluctuating and not consistently improving. Iteration 10 had a relatively high score of 16.666666666666664, and I want to revisit that prompt and try a different action to build upon it.' response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 2702, 'total_tokens': 2758, 'completion_time': 0.181903751, 'prompt_time': 0.775967773, 'queue_time': None, 'total_time': 0.957871524}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-845a4c44-b174-4ea1-b32f-ba2151487c7d-0' usage_metadata={'input_tokens': 2702, 'output_tokens': 56, 'total_tokens': 2758}\n",
      "Chosen Action: jump_back_to_iteration\n",
      "jump_back_to_iteration 10\n",
      "Jumped back to the following 'part_of_prompt_to_modify':  If you start with \"yes\" or \"no\", you need to justify it in 50 words or less.\n",
      "If you start with \"yes\" or \"no\", you need to justify it in 50 words or less.\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 16.666666666666664\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "Total time of cat CH is 69 min and 56.69547176361084 sec.\n",
      "Positive example list: \n",
      " [\"yahoo provides the yahoo services -lrb- defined below -rrb- to you subject to the following terms of service -lrb- `` tos '' -rrb- , which may be updated by us from time to time without notice to you .\"]\n",
      "\n",
      "Negative example list: \n",
      " []\n",
      "\n",
      "\n",
      "\n",
      "{'CH': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111}, {'iteration': 1, 'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your answer in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 550.9473684210526}, {'iteration': 2, 'prompt': 'If you start your answer with \"yes\" or \"no\", you should justify it in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 550.9473684210526}, {'iteration': 3, 'prompt': 'If you start your answer with \"yes\" or \"no\" you need to justify it in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 550.9473684210526}, {'iteration': 4, 'prompt': 'You need to justify your answer in 50 words or less if you start it with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 550.9473684210526}, {'iteration': 5, 'prompt': 'If you start your answer with \"yes\" or \"no\", you need to justify it in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 551.9473684210526}, {'iteration': 6, 'prompt': 'You need to justify your answer in 50 words or less if you start it with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 550.9473684210526}, {'iteration': 7, 'prompt': 'If you start your answer with \"yes\" or \"no\", you need to justify it in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 551.9473684210526}, {'iteration': 8, 'prompt': 'You need to justify it in 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 548.9473684210526}, {'iteration': 9, 'prompt': 'If you start with \"yes\" or \"no\", you need to justify it in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.76470588235294, 'relative_improvement': '5.882352941176472%', 'token_len': 549.9473684210526}, {'iteration': 10, 'prompt': 'If you start with \"yes\" or \"no\", you need to justify it in 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 16.666666666666664, 'relative_improvement': '41.66666666666665%', 'token_len': 601.9473684210526}, {'iteration': 11, 'prompt': 'If you start with \"yes\" or \"no\", you need to justify it in 50 words or less.', 'edit': 'add_negative_example', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 18.181818181818183, 'relative_improvement': '9.090909090909104%', 'token_len': 652.9473684210526}, {'iteration': 12, 'prompt': 'If you start with \"yes\" or \"no\", you need to justify it in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 18.181818181818183, 'relative_improvement': '0.0%', 'token_len': 652.9473684210526}, {'iteration': 13, 'prompt': 'You need to justify it in 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 13.333333333333334, 'relative_improvement': '-26.66666666666667%', 'token_len': 651.9473684210526}, {'iteration': 14, 'prompt': 'You need to justify it in 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 13.333333333333334, 'relative_improvement': '0.0%', 'token_len': 651.9473684210526}, {'iteration': 15, 'prompt': 'You need to justify it in 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 13.333333333333334, 'relative_improvement': '0.0%', 'token_len': 651.9473684210526}, {'iteration': 16, 'prompt': 'If you start with \"yes\" or \"no\", you need to justify it in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 18.181818181818183, 'relative_improvement': '36.363636363636374%', 'token_len': 652.9473684210526}, {'iteration': 17, 'prompt': 'You need to justify it in 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 13.333333333333334, 'relative_improvement': '-26.66666666666667%', 'token_len': 651.9473684210526}, {'iteration': 18, 'prompt': 'If you start with \"yes\" or \"no\", you need to justify it in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 18.181818181818183, 'relative_improvement': '36.363636363636374%', 'token_len': 652.9473684210526}, {'iteration': 19, 'prompt': 'You need to justify it in 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 13.333333333333334, 'relative_improvement': '-26.66666666666667%', 'token_len': 651.9473684210526}, {'iteration': 20, 'prompt': 'If you start with \"yes\" or \"no\", you need to justify it in 50 words or less.', 'edit': 'jump_back_to_iteration', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 16.666666666666664, 'relative_improvement': '24.99999999999998%', 'token_len': 601.9473684210526}]}\n",
      "\n",
      "\n",
      "++++++++++++++ This is RUN 7 of volatility analysis ++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " ################################\n",
      "Optimizing for category:  CH\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 1\n",
      "Complete response: content='reword_prompt because: The initial prompt is quite direct and concise, but rewording it could make it clearer and more specific, which might improve the score.' response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 368, 'total_tokens': 402, 'completion_time': 0.109854659, 'prompt_time': 0.070347174, 'queue_time': None, 'total_time': 0.18020183299999998}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-eb01139c-1ac4-4855-ba1f-4fbee1bf9a59-0' usage_metadata={'input_tokens': 368, 'output_tokens': 34, 'total_tokens': 402}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 2\n",
      "Complete response: content='reword_prompt because: The score has not improved in the previous iteration, and rewording the prompt again might help to clarify the instructions and improve the classification performance. Additionally, rewording the prompt can help to avoid any potential biases or ambiguities in the original prompt.' response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 983, 'total_tokens': 1040, 'completion_time': 0.194951055, 'prompt_time': 0.0829138, 'queue_time': None, 'total_time': 0.277864855}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-a65664ac-d2b7-4f74-8e9b-dfe8de39769e-0' usage_metadata={'input_tokens': 983, 'output_tokens': 57, 'total_tokens': 1040}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: Start your answer with 'yes' or 'no' and then justify it in no more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 3\n",
      "Complete response: content=\"add_positive_example because: The current score is plateauing, and adding a positive example might help the classification LLM to better understand the context and improve the score. Additionally, since no examples have been added yet, it's a good opportunity to introduce a positive example to guide the classification.\" response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 1076, 'total_tokens': 1135, 'completion_time': 0.207558431, 'prompt_time': 0.412104938, 'queue_time': None, 'total_time': 0.619663369}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-fa444c10-5eea-47d3-8f8b-0f4ec7ce4d44-0' usage_metadata={'input_tokens': 1076, 'output_tokens': 59, 'total_tokens': 1135}\n",
      "Chosen Action: add_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 0.0\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 4\n",
      "Complete response: content='remove_positive_example because: The score dropped to 0.0 in the previous iteration after adding a positive example, indicating that the added example might be confusing the model. By removing the positive example, we can see if the model can perform better without it.' response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 1165, 'total_tokens': 1218, 'completion_time': 0.171082834, 'prompt_time': 0.15166598, 'queue_time': None, 'total_time': 0.322748814}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-39e37958-e9df-4842-b4a7-4e79b81034e2-0' usage_metadata={'input_tokens': 1165, 'output_tokens': 53, 'total_tokens': 1218}\n",
      "Chosen Action: remove_positive_example\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/xc3t3y5n57jcb763d6d9rksw0000gn/T/ipykernel_56035/2626945926.py:163: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  relative_improvment = str(((score_value/optimization_history[iteration]['score'])-1)*100) + '%'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete response: content=\"reword_prompt because: The previous iterations didn't show significant improvement, and the score is still low. Rewording the prompt might help to clarify the task and improve the classification performance. Additionally, it's a relatively safe action that doesn't add or remove examples, which could potentially disrupt the classification process.\" response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 1256, 'total_tokens': 1318, 'completion_time': 0.198644871, 'prompt_time': 0.090781591, 'queue_time': None, 'total_time': 0.289426462}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-842dbee4-48bf-412a-9728-996a7558d3a0-0' usage_metadata={'input_tokens': 1256, 'output_tokens': 62, 'total_tokens': 1318}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: Start your answer with 'yes' or 'no' and then justify it in no more than 50 words. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 6\n",
      "Complete response: content='reword_prompt because: The previous rewording action in iteration 5 did not lead to a significant improvement, and the score remains the same. I want to try another rewording to see if it can lead to a better score.' response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 1347, 'total_tokens': 1397, 'completion_time': 0.154037855, 'prompt_time': 0.155418294, 'queue_time': None, 'total_time': 0.309456149}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-889b0c41-9488-4413-982c-7093ac3b0dfb-0' usage_metadata={'input_tokens': 1347, 'output_tokens': 50, 'total_tokens': 1397}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: Start your answer with 'yes' or 'no' and then justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 7\n",
      "Complete response: content=\"reword_prompt because: The previous two iterations did not lead to an improvement in the score, and rewording the prompt might help to clarify the instructions and improve the classification performance. Additionally, rewording the prompt has been successful in the past (iteration 1 and 5), so it's worth trying again.\" response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 1439, 'total_tokens': 1505, 'completion_time': 0.233194386, 'prompt_time': 0.11211785, 'queue_time': None, 'total_time': 0.345312236}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-b06e0d43-3d5d-444b-8698-6853e0166c79-0' usage_metadata={'input_tokens': 1439, 'output_tokens': 66, 'total_tokens': 1505}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: Start your answer with 'yes' or 'no' and then justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 11.11111111111111\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 8\n",
      "Complete response: content='reword_prompt because: The previous rewording actions did not lead to a significant improvement in the score, and I want to try another rewording to see if it can improve the prompt. Additionally, the score has been plateauing, and rewording the prompt might help to break this plateau.' response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 1533, 'total_tokens': 1596, 'completion_time': 0.222339757, 'prompt_time': 0.385669281, 'queue_time': None, 'total_time': 0.608009038}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-c41c3f3c-07e2-44b2-adb1-68d7582393c5-0' usage_metadata={'input_tokens': 1533, 'output_tokens': 63, 'total_tokens': 1596}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You should start your answer with \"yes\" or \"no\" and justify it in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 14.285714285714285\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 9\n",
      "Complete response: content=\"reword_prompt because: The previous iteration's score showed a significant improvement, and rewording the prompt again might help to further refine the language and increase the score. Additionally, the token length of the prompt is relatively short, which suggests that rewording might be a good approach to explore.\" response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 1608, 'total_tokens': 1669, 'completion_time': 0.214431239, 'prompt_time': 0.400670961, 'queue_time': None, 'total_time': 0.6151021999999999}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-ea43f6c2-69d0-432b-b15f-577770adacfe-0' usage_metadata={'input_tokens': 1608, 'output_tokens': 61, 'total_tokens': 1669}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You should justify your answer in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 12.5\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 10\n",
      "Complete response: content=\"reword_prompt because: The previous iteration's score decreased compared to iteration 8, and rewording the prompt has shown to be a effective action in improving the score in previous iterations.\" response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 1692, 'total_tokens': 1731, 'completion_time': 0.136817215, 'prompt_time': 0.146016007, 'queue_time': None, 'total_time': 0.282833222}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-41c222f9-9d43-47cd-af20-8fa251a7a84f-0' usage_metadata={'input_tokens': 1692, 'output_tokens': 39, 'total_tokens': 1731}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You have to justify your answer in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 13.333333333333334\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 11\n",
      "Complete response: content=\"reword_prompt because: The previous iteration's score is 13.333333333333334, which is a slight improvement from the previous iteration. To further improve the prompt, I will try rewording the prompt to see if it can lead to a higher score.\" response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1781, 'total_tokens': 1837, 'completion_time': 0.195608208, 'prompt_time': 0.246266082, 'queue_time': None, 'total_time': 0.44187429}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-1cc1d36b-7c0e-4da4-978a-22916ad80d03-0' usage_metadata={'input_tokens': 1781, 'output_tokens': 56, 'total_tokens': 1837}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: In 50 words or less, you have to justify your answer. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 12.5\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 12\n",
      "Complete response: content=\"reword_prompt because: The previous iteration's score was 12.5, which is a decrease from the previous iteration's score of 13.333333333333334. I want to try rewording the prompt to see if it can improve the score. Additionally, rewording the prompt has led to improvements in previous iterations, so it's worth trying again.\" response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 1859, 'total_tokens': 1936, 'completion_time': 0.240895436, 'prompt_time': 0.156307019, 'queue_time': None, 'total_time': 0.39720245499999995}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-f3458aaf-0259-48e6-b016-07c3abcc7461-0' usage_metadata={'input_tokens': 1859, 'output_tokens': 77, 'total_tokens': 1936}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You have to justify your answer in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 13.333333333333334\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 13\n",
      "Complete response: content='reword_prompt because: The current prompt has been reworded several times, and it seems to have a positive effect on the score. I want to try rewording it again to see if it can lead to further improvement. Additionally, the score has been plateauing around 13.33, and rewording the prompt might help to break through this plateau.' response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 1948, 'total_tokens': 2024, 'completion_time': 0.241132235, 'prompt_time': 0.343302344, 'queue_time': None, 'total_time': 0.584434579}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-35393c71-fc50-4749-9cdb-c3d19b1cdafd-0' usage_metadata={'input_tokens': 1948, 'output_tokens': 76, 'total_tokens': 2024}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: In 50 words or less, you have to justify your answer. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 12.5\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 14\n",
      "Complete response: content='reword_prompt because: The previous iterations have shown that rewording the prompt can lead to improvements in the score. The current score has plateaued, and rewording the prompt might help to break through this plateau. Additionally, rewording the prompt can help to clarify the instructions and make them more concise, which can lead to better performance by the classification LLM.' response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 2026, 'total_tokens': 2103, 'completion_time': 0.246964352, 'prompt_time': 0.158315572, 'queue_time': None, 'total_time': 0.405279924}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-24859041-226f-40f1-a634-d37455592089-0' usage_metadata={'input_tokens': 2026, 'output_tokens': 77, 'total_tokens': 2103}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You have to justify your answer in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 13.333333333333334\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 15\n",
      "Complete response: content='reword_prompt because: The current prompt has been reworded several times, but the score has not improved significantly. I want to try a different rewording to see if it can lead to a higher score.' response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 2115, 'total_tokens': 2160, 'completion_time': 0.144670063, 'prompt_time': 0.14891568, 'queue_time': None, 'total_time': 0.29358574299999995}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-8f873126-9edf-429a-b01f-88e80595e420-0' usage_metadata={'input_tokens': 2115, 'output_tokens': 45, 'total_tokens': 2160}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: In 50 words or less, you have to justify your answer. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 12.5\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 16\n",
      "Complete response: content=\"reword_prompt because: The current score is plateauing, and rewording the prompt might help to improve the clarity and coherence of the instruction, leading to a higher score. Additionally, this action has been successful in previous iterations, and it's worth trying again to see if it can lead to further improvement.\" response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 2193, 'total_tokens': 2257, 'completion_time': 0.223703224, 'prompt_time': 0.286832124, 'queue_time': None, 'total_time': 0.510535348}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-5643b113-584f-4e6e-a872-d5b5d5117405-0' usage_metadata={'input_tokens': 2193, 'output_tokens': 64, 'total_tokens': 2257}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You have to justify your answer in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 13.333333333333334\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 17\n",
      "Complete response: content=\"reword_prompt because: The current prompt has been oscillating between two versions, and rewording the prompt might help to break this cycle and explore new possibilities. Additionally, the score has not improved significantly in the last few iterations, so it's a good time to try a different approach.\" response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 2282, 'total_tokens': 2342, 'completion_time': 0.194426799, 'prompt_time': 0.134691819, 'queue_time': None, 'total_time': 0.329118618}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-6e3f3fc2-61f0-4443-99b1-8413d1bf6727-0' usage_metadata={'input_tokens': 2282, 'output_tokens': 60, 'total_tokens': 2342}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: In 50 words or less, you have to justify your answer. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 12.5\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 18\n",
      "Complete response: content=\"reword_prompt because: The current score is plateauing, and rewording the prompt might help to break this plateau and achieve a higher score. Additionally, rewording the prompt has led to improvements in previous iterations, so it's worth trying again.\" response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 2360, 'total_tokens': 2413, 'completion_time': 0.184817553, 'prompt_time': 0.256955485, 'queue_time': None, 'total_time': 0.441773038}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-9107a76d-1e5f-42a1-829f-3724a3b8b8c8-0' usage_metadata={'input_tokens': 2360, 'output_tokens': 53, 'total_tokens': 2413}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You have to justify your answer in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 13.333333333333334\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 19\n",
      "Complete response: content='reword_prompt because: The current prompt has been oscillating between two versions, and rewording the prompt might help to break this cycle and find a new, potentially better formulation. Additionally, rewording has been a successful action in the past, leading to improvements in the score.' response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 2449, 'total_tokens': 2508, 'completion_time': 0.186453979, 'prompt_time': 0.177228688, 'queue_time': None, 'total_time': 0.36368266699999996}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None} id='run-e1686871-618e-4a95-a290-b0dabb356d91-0' usage_metadata={'input_tokens': 2449, 'output_tokens': 59, 'total_tokens': 2508}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: In 50 words or less, you have to justify your answer. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 12.5\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "\n",
      "This is iteration 20\n",
      "Complete response: content=\"reword_prompt because: The current score is plateauing, and rewording the prompt might help to break this plateau and achieve a higher score. Additionally, rewording the prompt has led to improvements in previous iterations, so it's worth trying again.\" response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 2527, 'total_tokens': 2580, 'completion_time': 0.177086019, 'prompt_time': 0.339647903, 'queue_time': None, 'total_time': 0.516733922}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-ad7be955-e5d8-403c-a75c-c256849da539-0' usage_metadata={'input_tokens': 2527, 'output_tokens': 53, 'total_tokens': 2580}\n",
      "Chosen Action: reword_prompt\n",
      "Starting to paraphrase the following prompt: You have to justify your answer in 50 words or less. \n",
      " Using Pegasus:\n",
      "Start getting performance score\n",
      "Start analyzing predicitions:\n",
      "...................\n",
      "Performance score is: 14.285714285714285\n",
      "Start getting length score\n",
      "Lenght score is: 0\n",
      "Total time of cat CH is 51 min and 12.646197080612183 sec.\n",
      "Positive example list: \n",
      " []\n",
      "\n",
      "Negative example list: \n",
      " []\n",
      "\n",
      "\n",
      "\n",
      "{'CH': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111}, {'iteration': 1, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 546.9473684210526}, {'iteration': 2, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 546.9473684210526}, {'iteration': 3, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 0.0, 'relative_improvement': '-100.0%', 'token_len': 589.9473684210526}, {'iteration': 4, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': 'inf%', 'token_len': 546.9473684210526}, {'iteration': 5, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in 50 words or less.\", 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 545.9473684210526}, {'iteration': 6, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in 50 words or less.\", 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 545.9473684210526}, {'iteration': 7, 'prompt': 'You should start your answer with \"yes\" or \"no\" and justify it in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 11.11111111111111, 'relative_improvement': '0.0%', 'token_len': 548.9473684210526}, {'iteration': 8, 'prompt': 'You should justify your answer in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 14.285714285714285, 'relative_improvement': '28.57142857142856%', 'token_len': 537.9473684210526}, {'iteration': 9, 'prompt': 'You have to justify your answer in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 12.5, 'relative_improvement': '-12.49999999999999%', 'token_len': 538.9473684210526}, {'iteration': 10, 'prompt': 'In 50 words or less, you have to justify your answer.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 13.333333333333334, 'relative_improvement': '6.666666666666665%', 'token_len': 539.9473684210526}, {'iteration': 11, 'prompt': 'You have to justify your answer in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 12.5, 'relative_improvement': '-6.25%', 'token_len': 538.9473684210526}, {'iteration': 12, 'prompt': 'In 50 words or less, you have to justify your answer.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 13.333333333333334, 'relative_improvement': '6.666666666666665%', 'token_len': 539.9473684210526}, {'iteration': 13, 'prompt': 'You have to justify your answer in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 12.5, 'relative_improvement': '-6.25%', 'token_len': 538.9473684210526}, {'iteration': 14, 'prompt': 'In 50 words or less, you have to justify your answer.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 13.333333333333334, 'relative_improvement': '6.666666666666665%', 'token_len': 539.9473684210526}, {'iteration': 15, 'prompt': 'You have to justify your answer in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 12.5, 'relative_improvement': '-6.25%', 'token_len': 538.9473684210526}, {'iteration': 16, 'prompt': 'In 50 words or less, you have to justify your answer.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 13.333333333333334, 'relative_improvement': '6.666666666666665%', 'token_len': 539.9473684210526}, {'iteration': 17, 'prompt': 'You have to justify your answer in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 12.5, 'relative_improvement': '-6.25%', 'token_len': 538.9473684210526}, {'iteration': 18, 'prompt': 'In 50 words or less, you have to justify your answer.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 13.333333333333334, 'relative_improvement': '6.666666666666665%', 'token_len': 539.9473684210526}, {'iteration': 19, 'prompt': 'You have to justify your answer in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 12.5, 'relative_improvement': '-6.25%', 'token_len': 538.9473684210526}, {'iteration': 20, 'prompt': 'You need to explain your answer in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 14.285714285714285, 'relative_improvement': '14.28571428571428%', 'token_len': 538.9473684210526}]}\n"
     ]
    }
   ],
   "source": [
    "# Define your model (using your actual API key/setup)\n",
    "model = ChatGroq(\n",
    "    model_name=\"llama3-70b-8192\",\n",
    "    groq_api_key=\"<API KEY>\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Initial prompt to be optimized\n",
    "optimized_prompt_dict = {}\n",
    "#initial_prompt = \"Consider the following online terms of service clause: 'websites & communications terms of use'. Does this clause describe an arbitration dispute resolution process that is not fully optional to the consumer? Begin your answer with 'yes' or 'no' and then justify your response in no more than 50 words. For example, consider these example clauses: <positive, if you are not a consumer in the eea , the exclusive place of jurisdiction for all disputes arising from or in connection with this agreement is san francisco county , california , or the united states district court for the northern district of california and our dispute will bedetermined under california law .'>, <negative, you are prohibited from using any services or facilities provided in connection with this service to compromise security or tamper with system resources and/or accounts .>\"\n",
    "unfairness_categories = ['A', 'CH', 'CR', 'J', 'LAW', 'LTD', 'TER', 'USE']\n",
    "unfairness_categories_green = ['A', 'CH', 'CR', 'J']\n",
    "unfairness_categories_pink = ['LAW', 'LTD', 'TER', 'USE']\n",
    "unfairness_categories_CH = ['CH']\n",
    "\n",
    "\n",
    "for i in range(5,8):\n",
    "\n",
    "    print(f\"\\n\\n++++++++++++++ This is RUN {i} of volatility analysis ++++++++++++++\\n\\n\")\n",
    "\n",
    "    initial_prompt = \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\"\n",
    "    intro_prompt = 'Consider the following online terms of service clause:'\n",
    "    #cat_results = {}\n",
    "    #df_train_sample = sample_equal_distribution(df_train, unfairness_categories, 100, 123)\n",
    "    #score_set_df = sample_equal_distribution(df_train, unfairness_categories, 25, 234)\n",
    "    output = ''\n",
    "    \n",
    "    filename = f\"20240808_volatility_analysis_loop_{i}.txt\"\n",
    "    output_dir = os.path.join('..', 'output')\n",
    "    file_path = os.path.join(output_dir, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        raise FileExistsError(f\"Error: The file '{filename}' already exists in the 'output' directory. \"\n",
    "                                f\"It is not recommended to overwrite an output file. Please specify another name.\")\n",
    "    \n",
    "    # Create and open the file\n",
    "    file_stream = open(file_path, 'w')\n",
    "\n",
    "    \n",
    "    # Buffer for capturing print output\n",
    "    buffer = io.StringIO()\n",
    "    \n",
    "    # MultiLogger setup to write to stdout, buffer, and file\n",
    "    multi_logger = MultiLogger(sys.stdout, buffer, file_stream)\n",
    "    sys.stdout = multi_logger\n",
    "\n",
    "    try:\n",
    "        for cat in unfairness_categories_CH:\n",
    "            examples_instance = tools.ExampleTool.ExampleTool(df_train)\n",
    "            jump_iteration = tools.jump_iteration.jump_iteration(examples_instance)\n",
    "            start_time = time.time()\n",
    "            optimized_prompt_dict[cat] = run_prompt_optimization(intro_prompt, initial_prompt, df_train, df_train_short, model, NUM_ITERATIONS, cat, examples_instance)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            elapse_time = end_time - start_time\n",
    "            elapse_minutes = int(elapse_time // 60)\n",
    "            elapse_seconds = elapse_time % 60\n",
    "    \n",
    "            print(f\"Total time of cat {cat} is {elapse_minutes} min and {elapse_seconds} sec.\")\n",
    "            print(\"Positive example list: \\n\", examples_instance.added_examples[\"positive\"])\n",
    "            print(\"\\nNegative example list: \\n\",examples_instance.added_examples[\"negative\"])\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "    \n",
    "        print(\"\\n\\n\")\n",
    "        print(optimized_prompt_dict)\n",
    "        # Cleanup\n",
    "        sys.stdout = sys.__stdout__  # Reset stdout to default\n",
    "        file_stream.close()\n",
    "    \n",
    "        output = buffer.getvalue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CH': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 11.11111111111111},\n",
       "  {'iteration': 1,\n",
       "   'prompt': \"When you start your answer with 'yes' or 'no', you need to justify it in no more than 50 words.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 14.285714285714285,\n",
       "   'relative_improvement': '28.57142857142856%',\n",
       "   'token_len': 550.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': \"You need to justify it in no more than 50 words when you answer 'yes' or 'no'.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 25.0,\n",
       "   'relative_improvement': '75.00000000000003%',\n",
       "   'token_len': 546.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': \"When you answer 'yes' or 'no', you need to justify it in no more than 50 words.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 16.666666666666664,\n",
       "   'relative_improvement': '-33.33333333333335%',\n",
       "   'token_len': 547.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': \"You need to justify it in no more than 50 words when you answer 'yes' or 'no'.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 25.0,\n",
       "   'relative_improvement': '50.00000000000002%',\n",
       "   'token_len': 546.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': \"When you answer 'yes' or 'no', you need to justify it in no more than 50 words.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 16.666666666666664,\n",
       "   'relative_improvement': '-33.33333333333335%',\n",
       "   'token_len': 547.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': \"You need to justify it in no more than 50 words when you answer 'yes' or 'no'.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 25.0,\n",
       "   'relative_improvement': '50.00000000000002%',\n",
       "   'token_len': 546.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': \"You need to justify it in no more than 50 words when you answer 'yes' or 'no'.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 14.285714285714285,\n",
       "   'relative_improvement': '-42.85714285714286%',\n",
       "   'token_len': 580.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': \"When you answer 'yes' or 'no', you need to justify it in no more than 50 words.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 18.181818181818183,\n",
       "   'relative_improvement': '27.272727272727295%',\n",
       "   'token_len': 581.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': 'You need to justify it in no more than 50 words.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': '-100.0%',\n",
       "   'token_len': 572.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': 'You need to justify it in no more than 50 words.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 13.333333333333334,\n",
       "   'relative_improvement': 'inf%',\n",
       "   'token_len': 600.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': 'You need to justify it in no more than 50 words.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 12.5,\n",
       "   'relative_improvement': '-6.25%',\n",
       "   'token_len': 613.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': 'You must justify it in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 16.666666666666664,\n",
       "   'relative_improvement': '33.3333333333333%',\n",
       "   'token_len': 611.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': 'You need to justify it in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 14.285714285714285,\n",
       "   'relative_improvement': '-14.28571428571428%',\n",
       "   'token_len': 612.9473684210526},\n",
       "  {'iteration': 14,\n",
       "   'prompt': 'You have to justify it in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 14.285714285714285,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 612.9473684210526},\n",
       "  {'iteration': 15,\n",
       "   'prompt': 'You have to explain it in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 14.285714285714285,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 612.9473684210526},\n",
       "  {'iteration': 16,\n",
       "   'prompt': 'You need to explain it in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 15.384615384615385,\n",
       "   'relative_improvement': '7.692307692307709%',\n",
       "   'token_len': 612.9473684210526},\n",
       "  {'iteration': 17,\n",
       "   'prompt': 'You must explain it in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 15.384615384615385,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 611.9473684210526},\n",
       "  {'iteration': 18,\n",
       "   'prompt': 'You have to explain it in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 14.285714285714285,\n",
       "   'relative_improvement': '-7.142857142857151%',\n",
       "   'token_len': 612.9473684210526},\n",
       "  {'iteration': 19,\n",
       "   'prompt': 'You must explain it in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 15.384615384615385,\n",
       "   'relative_improvement': '7.692307692307709%',\n",
       "   'token_len': 611.9473684210526},\n",
       "  {'iteration': 20,\n",
       "   'prompt': 'You have to explain it in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 14.285714285714285,\n",
       "   'relative_improvement': '-7.142857142857151%',\n",
       "   'token_len': 612.9473684210526}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_prompt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfairness_categories = ['A', 'CH', 'CR', 'J', 'LAW', 'LTD', 'TER', 'USE']\n",
    "for cat in unfairness_categories:\n",
    "    print(\"Category : \", cat)\n",
    "    print(optimized_prompt_dict[cat][0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('optimized_prompt_dict_new_metaprompt.pickle', 'wb') as handle:\n",
    "    pickle.dump(optimized_prompt_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_prompt_dict[\"USE\"][0]['iteration']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LAW & LTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LAW': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 33.33333333333333},\n",
       "  {'iteration': 1,\n",
       "   'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 36.36363636363637,\n",
       "   'relative_improvement': '9.090909090909104%',\n",
       "   'token_len': 548.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 33.33333333333333,\n",
       "   'relative_improvement': '-8.333333333333359%',\n",
       "   'token_len': 737.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.',\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 30.76923076923077,\n",
       "   'relative_improvement': '-7.692307692307676%',\n",
       "   'token_len': 784.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': 'You should justify your response in 50 words or less if you start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '62.5%',\n",
       "   'token_len': 782.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': ' - Justify response in 50 words or less\\n - Start with \"yes\" or \"no\"',\n",
       "   'edit': 'to_bulletpoints',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 28.57142857142857,\n",
       "   'relative_improvement': '-42.85714285714286%',\n",
       "   'token_len': 778.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': 'In 50 words or less, start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 26.666666666666668,\n",
       "   'relative_improvement': '-6.666666666666654%',\n",
       "   'token_len': 776.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': '-100.0%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': 'Start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 770.9473684210526},\n",
       "  {'iteration': 14,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 15,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 16,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 17,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 18,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 19,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526},\n",
       "  {'iteration': 20,\n",
       "   'prompt': 'Start with either \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': 'nan%',\n",
       "   'token_len': 771.9473684210526}],\n",
       " 'LTD': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0},\n",
       "  {'iteration': 1,\n",
       "   'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 542.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 586.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.',\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '14.28571428571428%',\n",
       "   'token_len': 620.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': 'Begin your answer with \"yes\" or \"no\" and then explain it in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 40.0,\n",
       "   'relative_improvement': '-29.999999999999993%',\n",
       "   'token_len': 619.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': ' - Answer with \"yes\" or \"no\"\\n - Explain in 50 words or less',\n",
       "   'edit': 'to_bulletpoints',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 36.36363636363637,\n",
       "   'relative_improvement': '-9.090909090909083%',\n",
       "   'token_len': 615.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '57.14285714285712%',\n",
       "   'token_len': 615.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 653.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 36.36363636363637,\n",
       "   'relative_improvement': '-36.36363636363635%',\n",
       "   'token_len': 699.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': 'If you have \"yes\" or \"no\", explain in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 40.0,\n",
       "   'relative_improvement': '9.999999999999986%',\n",
       "   'token_len': 700.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '66.66666666666666%',\n",
       "   'token_len': 696.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 696.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '-24.99999999999999%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 14,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 15,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 16,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 17,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 18,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 19,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526},\n",
       "  {'iteration': 20,\n",
       "   'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 813.9473684210526}],\n",
       " 'TER': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0},\n",
       "  {'iteration': 1,\n",
       "   'prompt': 'If you want to justify your response, start it with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '33.3333333333333%',\n",
       "   'token_len': 548.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.',\n",
       "   'edit': 'to_bulletpoints',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '-24.99999999999999%',\n",
       "   'token_len': 547.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 588.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.',\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 623.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '33.3333333333333%',\n",
       "   'token_len': 623.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '-24.99999999999999%',\n",
       "   'token_len': 676.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 696.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 716.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': 'Start with \"yes\" or \"no\" to justify your response.',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 0.0,\n",
       "   'relative_improvement': '-100.0%',\n",
       "   'token_len': 712.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': 'To justify your response, start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': 'inf%',\n",
       "   'token_len': 713.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': 'To justify your response, start with \"yes\" or \"no\".',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 5,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 827.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': 'To justify your response, start with \"yes\" or \"no\".',\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 5,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 827.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': 'To justify your response, start with \"yes\" or \"no\".',\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 6,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 874.9473684210526}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'LAW': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 33.33333333333333}, {'iteration': 1, 'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 36.36363636363637, 'relative_improvement': '9.090909090909104%', 'token_len': 548.9473684210526}, {'iteration': 2, 'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 33.33333333333333, 'relative_improvement': '-8.333333333333359%', 'token_len': 737.9473684210526}, {'iteration': 3, 'prompt': 'You should start your answer with \"yes\" or \"no\" and then justify your response in 50 words or less.', 'edit': 'add_negative_example', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 30.76923076923077, 'relative_improvement': '-7.692307692307676%', 'token_len': 784.9473684210526}, {'iteration': 4, 'prompt': 'You should justify your response in 50 words or less if you start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '62.5%', 'token_len': 782.9473684210526}, {'iteration': 5, 'prompt': ' - Justify response in 50 words or less\\n - Start with \"yes\" or \"no\"', 'edit': 'to_bulletpoints', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 28.57142857142857, 'relative_improvement': '-42.85714285714286%', 'token_len': 778.9473684210526}, {'iteration': 6, 'prompt': 'In 50 words or less, start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 26.666666666666668, 'relative_improvement': '-6.666666666666654%', 'token_len': 776.9473684210526}, {'iteration': 7, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': '-100.0%', 'token_len': 770.9473684210526}, {'iteration': 8, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 9, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 10, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 11, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 12, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 13, 'prompt': 'Start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 770.9473684210526}, {'iteration': 14, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 15, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 16, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 17, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 18, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 19, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}, {'iteration': 20, 'prompt': 'Start with either \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': 'nan%', 'token_len': 771.9473684210526}], 'LTD': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0}, {'iteration': 1, 'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 542.9473684210526}, {'iteration': 2, 'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.', 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 586.9473684210526}, {'iteration': 3, 'prompt': 'Start your answer with \"yes\" or \"no\" and then justify it in no more than 50 words.', 'edit': 'add_negative_example', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 57.14285714285714, 'relative_improvement': '14.28571428571428%', 'token_len': 620.9473684210526}, {'iteration': 4, 'prompt': 'Begin your answer with \"yes\" or \"no\" and then explain it in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 40.0, 'relative_improvement': '-29.999999999999993%', 'token_len': 619.9473684210526}, {'iteration': 5, 'prompt': ' - Answer with \"yes\" or \"no\"\\n - Explain in 50 words or less', 'edit': 'to_bulletpoints', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 36.36363636363637, 'relative_improvement': '-9.090909090909083%', 'token_len': 615.9473684210526}, {'iteration': 6, 'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 57.14285714285714, 'relative_improvement': '57.14285714285712%', 'token_len': 615.9473684210526}, {'iteration': 7, 'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".', 'edit': 'add_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 1, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 653.9473684210526}, {'iteration': 8, 'prompt': 'Explain in 50 words or less if you have \"yes\" or \"no\".', 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 36.36363636363637, 'relative_improvement': '-36.36363636363635%', 'token_len': 699.9473684210526}, {'iteration': 9, 'prompt': 'If you have \"yes\" or \"no\", explain in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 40.0, 'relative_improvement': '9.999999999999986%', 'token_len': 700.9473684210526}, {'iteration': 10, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '66.66666666666666%', 'token_len': 696.9473684210526}, {'iteration': 11, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '0.0%', 'token_len': 696.9473684210526}, {'iteration': 12, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'add_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '-24.99999999999999%', 'token_len': 813.9473684210526}, {'iteration': 13, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 14, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 15, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 16, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 17, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 18, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 19, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}, {'iteration': 20, 'prompt': 'Explain \"yes\" or \"no\" in 50 words or less.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 813.9473684210526}], 'TER': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0}, {'iteration': 1, 'prompt': 'If you want to justify your response, start it with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 66.66666666666666, 'relative_improvement': '33.3333333333333%', 'token_len': 548.9473684210526}, {'iteration': 2, 'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.', 'edit': 'to_bulletpoints', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '-24.99999999999999%', 'token_len': 547.9473684210526}, {'iteration': 3, 'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.', 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 588.9473684210526}, {'iteration': 4, 'prompt': ' - Start with \"yes\" or \"no\" if you want to justify your response.', 'edit': 'add_negative_example', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 623.9473684210526}, {'iteration': 5, 'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"', 'edit': 'reword_prompt', 'positive_examples_count': 1, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '33.3333333333333%', 'token_len': 623.9473684210526}, {'iteration': 6, 'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"', 'edit': 'add_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '-24.99999999999999%', 'token_len': 676.9473684210526}, {'iteration': 7, 'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"', 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 696.9473684210526}, {'iteration': 8, 'prompt': 'If you want to justify your response, start with \"yes\" or \"no.\"', 'edit': 'add_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 716.9473684210526}, {'iteration': 9, 'prompt': 'Start with \"yes\" or \"no\" to justify your response.', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 0.0, 'relative_improvement': '-100.0%', 'token_len': 712.9473684210526}, {'iteration': 10, 'prompt': 'To justify your response, start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': 'inf%', 'token_len': 713.9473684210526}, {'iteration': 11, 'prompt': 'To justify your response, start with \"yes\" or \"no\".', 'edit': 'add_positive_example', 'positive_examples_count': 5, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 827.9473684210526}, {'iteration': 12, 'prompt': 'To justify your response, start with \"yes\" or \"no\".', 'edit': 'reword_prompt', 'positive_examples_count': 5, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 827.9473684210526}, {'iteration': 13, 'prompt': 'To justify your response, start with \"yes\" or \"no\".', 'edit': 'add_positive_example', 'positive_examples_count': 6, 'negative_examples_count': 1, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 874.9473684210526}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TER': [{'iteration': 0,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\",\n",
       "   'edit': 'inital - no edit',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0},\n",
       "  {'iteration': 1,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 0,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 549.9473684210526},\n",
       "  {'iteration': 2,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 1,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 591.9473684210526},\n",
       "  {'iteration': 3,\n",
       "   'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 628.9473684210526},\n",
       "  {'iteration': 4,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'to_bulletpoints',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 625.9473684210526},\n",
       "  {'iteration': 5,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 0,\n",
       "   'score': 50.0,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 694.9473684210526},\n",
       "  {'iteration': 6,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '33.3333333333333%',\n",
       "   'token_len': 756.9473684210526},\n",
       "  {'iteration': 7,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 1,\n",
       "   'score': 40.0,\n",
       "   'relative_improvement': '-39.99999999999999%',\n",
       "   'token_len': 786.9473684210526},\n",
       "  {'iteration': 8,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '42.85714285714284%',\n",
       "   'token_len': 798.9473684210526},\n",
       "  {'iteration': 9,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_positive_example',\n",
       "   'positive_examples_count': 5,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 40.0,\n",
       "   'relative_improvement': '-29.999999999999993%',\n",
       "   'token_len': 818.9473684210526},\n",
       "  {'iteration': 10,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'remove_positive_example',\n",
       "   'positive_examples_count': 4,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 33.33333333333333,\n",
       "   'relative_improvement': '-16.666666666666675%',\n",
       "   'token_len': 786.9473684210526},\n",
       "  {'iteration': 11,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'remove_positive_example',\n",
       "   'positive_examples_count': 3,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '100.0%',\n",
       "   'token_len': 749.9473684210526},\n",
       "  {'iteration': 12,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'remove_positive_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 2,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 680.9473684210526},\n",
       "  {'iteration': 13,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 3,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '-14.28571428571428%',\n",
       "   'token_len': 719.9473684210526},\n",
       "  {'iteration': 14,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 4,\n",
       "   'score': 66.66666666666666,\n",
       "   'relative_improvement': '16.66666666666665%',\n",
       "   'token_len': 733.9473684210526},\n",
       "  {'iteration': 15,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 5,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '-14.28571428571428%',\n",
       "   'token_len': 750.9473684210526},\n",
       "  {'iteration': 16,\n",
       "   'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\",\n",
       "   'edit': 'add_negative_example',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 767.9473684210526},\n",
       "  {'iteration': 17,\n",
       "   'prompt': \"Start with 'yes' or 'no' and justify in 50 words or less.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 80.0,\n",
       "   'relative_improvement': '40.000000000000014%',\n",
       "   'token_len': 765.9473684210526},\n",
       "  {'iteration': 18,\n",
       "   'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '-28.57142857142858%',\n",
       "   'token_len': 769.9473684210526},\n",
       "  {'iteration': 19,\n",
       "   'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 769.9473684210526},\n",
       "  {'iteration': 20,\n",
       "   'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\",\n",
       "   'edit': 'reword_prompt',\n",
       "   'positive_examples_count': 2,\n",
       "   'negative_examples_count': 6,\n",
       "   'score': 57.14285714285714,\n",
       "   'relative_improvement': '0.0%',\n",
       "   'token_len': 769.9473684210526}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'TER': [{'iteration': 0, 'prompt': \"Start your answer with 'yes' or 'no' and then justify your response in no more than 50 words.\", 'edit': 'inital - no edit', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0}, {'iteration': 1, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'reword_prompt', 'positive_examples_count': 0, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 549.9473684210526}, {'iteration': 2, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 1, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 591.9473684210526}, {'iteration': 3, 'prompt': \"Start your answer with 'yes' or 'no' and then justify it in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 628.9473684210526}, {'iteration': 4, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'to_bulletpoints', 'positive_examples_count': 2, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 625.9473684210526}, {'iteration': 5, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 0, 'score': 50.0, 'relative_improvement': '0.0%', 'token_len': 694.9473684210526}, {'iteration': 6, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 3, 'negative_examples_count': 1, 'score': 66.66666666666666, 'relative_improvement': '33.3333333333333%', 'token_len': 756.9473684210526}, {'iteration': 7, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 1, 'score': 40.0, 'relative_improvement': '-39.99999999999999%', 'token_len': 786.9473684210526}, {'iteration': 8, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 4, 'negative_examples_count': 2, 'score': 57.14285714285714, 'relative_improvement': '42.85714285714284%', 'token_len': 798.9473684210526}, {'iteration': 9, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_positive_example', 'positive_examples_count': 5, 'negative_examples_count': 2, 'score': 40.0, 'relative_improvement': '-29.999999999999993%', 'token_len': 818.9473684210526}, {'iteration': 10, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 4, 'negative_examples_count': 2, 'score': 33.33333333333333, 'relative_improvement': '-16.666666666666675%', 'token_len': 786.9473684210526}, {'iteration': 11, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 3, 'negative_examples_count': 2, 'score': 66.66666666666666, 'relative_improvement': '100.0%', 'token_len': 749.9473684210526}, {'iteration': 12, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'remove_positive_example', 'positive_examples_count': 2, 'negative_examples_count': 2, 'score': 66.66666666666666, 'relative_improvement': '0.0%', 'token_len': 680.9473684210526}, {'iteration': 13, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 3, 'score': 57.14285714285714, 'relative_improvement': '-14.28571428571428%', 'token_len': 719.9473684210526}, {'iteration': 14, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 4, 'score': 66.66666666666666, 'relative_improvement': '16.66666666666665%', 'token_len': 733.9473684210526}, {'iteration': 15, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 5, 'score': 57.14285714285714, 'relative_improvement': '-14.28571428571428%', 'token_len': 750.9473684210526}, {'iteration': 16, 'prompt': \" - Start with 'yes' or 'no' and justify in no more than 50 words.\", 'edit': 'add_negative_example', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 767.9473684210526}, {'iteration': 17, 'prompt': \"Start with 'yes' or 'no' and justify in 50 words or less.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 80.0, 'relative_improvement': '40.000000000000014%', 'token_len': 765.9473684210526}, {'iteration': 18, 'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '-28.57142857142858%', 'token_len': 769.9473684210526}, {'iteration': 19, 'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 769.9473684210526}, {'iteration': 20, 'prompt': \"If you want to justify in 50 words or less, start with 'yes' or 'no'.\", 'edit': 'reword_prompt', 'positive_examples_count': 2, 'negative_examples_count': 6, 'score': 57.14285714285714, 'relative_improvement': '0.0%', 'token_len': 769.9473684210526}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
